"""

Main entry point for all applications that use shim. Provides a wrapper for the
shim stack object for easy instantiation. Also catches any exceptions that are
not consistant with the API semantics. Provides logging capabilities.


"""

#begin include ShimSocketWrapper.repy

# Wrapper class of the socket object we're redefining within EmptyShim. This
# class should never be referenced, redefined or overridden by the shim
# programmer. If he wishes to redefine the three socket operations, he
# should do so within the socket_* methods in the subclasses of BaseShim.
class ShimSocketWrapper:

  mycontext['ShimSocketWrapperLock'] = getlock()
  mycontext['ShimSocketWrapperInstanceCounter'] = 0

  # We are passing the original socket to wrap around, along with the shim
  # instance that uses our wrapper socket. This facilitates the exchange of
  # information between the socket and the caller shim.
  def __init__(self, socket, shim):
    if shim is None:
      raise Exception("Null reference to shim provided at constructor of ShimSocketWrapper.")

    self._socket = socket
    self._shim = shim

    # Obtain the id this this instance
    mycontext['ShimSocketWrapperLock'].acquire()
    self._id = mycontext['ShimSocketWrapperInstanceCounter']
    mycontext['ShimSocketWrapperInstanceCounter'] += 1
    mycontext['ShimSocketWrapperLock'].release()


  def close(self):
    return self._shim.socket_close(self._socket)


  def recv(self, bytes):
    return self._shim.socket_recv(self._socket, bytes)


  def send(self, message):
    return self._shim.socket_send(self._socket, message)


  # Provides compatibility to the counterpart in the repy socket. Shim creators
  # cannot override this method.
  def willblock(self):
    return self._socket.willblock()


  # Returns the instance id.
  def getid(self):
    return self._id

  
  # # Used if we ever set an instance of this class as the key of a dictionary. In
  # # this case, we simply set the instance id as the hash value.
  # def __hash__(self):
  #   return self.getid()


  def __str__(self):
    #TODO debug only
    return ("(@ %d Shim: %s. Socket: %s)" % 
            (self.getid(), self._shim, self._socket))

#end include ShimSocketWrapper.repy
#begin include ShimStack.repy
"""

<Program Name>
  ShimStack.repy

<Author>
  Eric Kimbrel, kimbrl@cs.washington.edu

<Date Started>
  Jun 2009

<Purpose>
  Provide a wrapper for network shims with conveient methods for composing
  shims together into a stack
 

"""




# a dictionary to store refrences to each layers class
_SHIMSTACK_LAYER_DICT = {}


### REGISTRATION USED FOR LAYERS TO REGISTER WITH THE FRAMEWORK  ###

# Provides a wrapper for the legacy shimstack_reg_layer method
def register_shim(shim_name, shim_class, is_private_shim=False):
  # if shim_name in _SHIMSTACK_LAYER_DICT.keys():
  #   raise Exception('You cannot register an existing shim "%s" more than once.' % shim_name)
  _SHIMSTACK_LAYER_DICT[shim_name] = {'class': shim_class, 
                                      'is_private_shim': is_private_shim}

                      

# TODO Legacy. Used for debugging and backward compatibility.
def shimstack_reg_layer(layer_name,layer_info_dict):
  """
  <Purpose>
    Allows layers to register their information inside of the service
    comp framework

  <Arguments>
    layer_name:
      the name of the layer being registered

    layer_info_dict:
      a dictionary of the form {'class':LayerClass,'type':'LayerType'}

  <Exceptions>
    Exception if a previously registered name is registered

  <Side Effects>
     None

  <Returns>
    None
  """

  # provides a way for T_layers to register themselves with the framework
  if layer_name in _SHIMSTACK_LAYER_DICT:
    raise Exception('Attempt to register previously existing h-layer' +str(layer_name_))
  _SHIMSTACK_LAYER_DICT[layer_name] = layer_info_dict




class ShimStack:
# Each Shim stack implements the networking API
# Each shim has a reference to the ShimStack beneath it

# a Shim stack string (for the constructor) is of the form
# (LayerName,arg1,arg2,arg3,...)(..)....
# The first item in a () is the name of the Shim to be instantiated,
# each following item is convered to a list of strings and passed to
# the Shim constructor as optional_args

  mycontext['ShimStackInstanceCount'] = 0
  mycontext['ShimStackInstanceCountLock'] = getlock()


  def __init__(self,shim_stack_string=None):
    # create a new shim stack
    if shim_stack_string is not None: 
      self.top_shim = self.make_stack(shim_stack_string)
    else:
      self.top_shim = None

    mycontext['ShimStackInstanceCountLock'].acquire()
    self._instance_id = mycontext['ShimStackInstanceCount']
    mycontext['ShimStackInstanceCount'] += 1
    mycontext['ShimStackInstanceCountLock'].release()


  def getid(self):
    return self._instance_id

  
  def push(self,shim):
    # give the new shim a shim stack that is the same as this one
    shim.shim_stack = ShimStack()
    shim.shim_stack.top_shim = self.top_shim
    
    # change this shim stack to include the new shim
    self.top_shim = shim
    
      

  def pop(self):
    # remove and return the top shim
    shim = self.top_shim
    if shim is None:
      raise Exception('You cannot pop an empty shim stack.')
    self.top_shim = self.top_shim.shim_stack.top_shim
    shim.shim_stack = None 
    return shim


  # TODO Legacy. Used for debugging only.
  def get_names(self):
    # return a list of names that can be used to create compatible 
    # shim stacks
    return self.top_shim.get_names()


  def copy(self):
    if self.top_shim is None:
      return ShimStack()

    stackcopy = self.top_shim.shim_stack.copy()
    stackcopy.push(self.top_shim.copy())
    return stackcopy

  def get_advertisement_string(self):
    if self.top_shim is None:
      return ""
    else:
      return self.top_shim.get_advertisement_string()


  # TODO Legacy. Used for debugging only.
  def get_shims(self, get_all_shims=False):
    if self.top_shim is None:
      return ""
    else:
      return self.top_shim.get_shims(get_all_shims)


  def __repr__(self):
    return self.__str__()


  def __str__(self):
    return "Stack #%d: %s" % (self.getid(), self.get_shims(True))


  def make_stack(self,shim_stack_str):
    # private method used only by the ShimStack constructor

    # takes a string of the form '(a)(b,c,d)'
    # the first item in each (..) is the name of the shim
    # following items are optional args that will be understood
    # by the shims constructor  


    temp_str = shim_stack_str.replace('(','')
    stack_list = temp_str.split(')')
    del stack_list[len(stack_list)-1]

  
    # make objects for each layer in the list
    top = None # the top of this stack
    previous = None
    for comma_seperated_str in stack_list:
     
      shim_list = comma_seperated_str.split(',')
    
      shim_name = shim_list[0]
    

      shim_args = shim_list[1:]
      if len(shim_args) == 0:
        shim_args = None

    
    
      # first arguemnt is always for the next shim, second argument is optional args
      new_shim = _SHIMSTACK_LAYER_DICT[shim_name]['class'](None,shim_args)

    
      if top == None: top = new_shim
    
      if previous !=None:
        # link in the shim stack to the above shim
        # traverse to the bottom of the previous shim stack
        # you would expect there to only be one shim, but a shim
        # constructor might have called push()
        while previous.shim_stack.top_shim is not None:
          previous = previous.shim_stack.top_shim
        previous.shim_stack.top_shim = new_shim
      
      previous = new_shim

    return top 

  


  # ===========================================================================
  # Public methods that interface with the application
  # ===========================================================================


  def _shim_stack_waitforconn_callback_wrapper(self,sock,rip,rport,th,lh):
    self._shim_stack_waitforconn_callback(sock,rip,rport,th,lh)


  def waitforconn(self,host,port,callback):
    self._shim_stack_waitforconn_callback = callback

    if self.top_shim is None:
      self._shim_stack_waitforconn_callback = callback
      return waitforconn(DummyDNSLookup(host,True), port, self._shim_stack_waitforconn_callback_wrapper)

    else:
      return self.top_shim.waitforconn(host,port,self._shim_stack_waitforconn_callback_wrapper)


  def openconn(self,host,port,localhost=None,localport=None,timeout=5):
    if self.top_shim is None:
      return openconn(DummyDNSLookup(host),port,localhost,localport,timeout)

    else:
      return self.top_shim.openconn(host,port,localhost,localport,timeout)



  def recvmess(self,host,port,callback):
    if self.top_shim is None:
      return recvmess(host, port, callback)
    else:
      return self.top_shim.recvmess(host,port,callback)


  def sendmess(self,host,port,msg,localhost=None,localport=None):
    if self.top_shim is None:
      return sendmess(host,port,msg,localhost,localport)
    else:
      return self.top_shim.sendmess(host,port,msg,localhost,localport)

  def stopcomm(self,handle):
    if self.top_shim is None:
      return stopcomm(handle)
    else:
      return self.top_shim.stopcomm(handle)

  def socket_close(self, socket):
    return socket.close()


  def socket_send(self, socket, msg):
    return socket.send(msg)


  def socket_recv(self, socket, bytes):
    return socket.recv(bytes)













#end include ShimStack.repy
#begin include ShimException.repy
class ShimException(Exception):
  pass


class ShimExceptionStackRejected(ShimException):
  pass

#end include ShimException.repy
#begin include DummyDNS.repy
#begin include advertise.repy
"""
Author: Justin Cappos

Start Date: October 14, 2008

Description:
A stub that allows different announcement types.   I'd make this smarter, but
the user won't configure it, right?


Raises an AdvertiseError exception if there is a problem advertising with either service

"""

#begin include listops.repy
""" 
Author: Justin Cappos

Module: A simple library of list commands that allow the programmer
        to do list composition operations

Start date: November 11th, 2008

This is a really simple module, only broken out to avoid duplicating 
functionality.

This was adopted from previous code in seash.   

I really should be using sets instead I think.   These are merely for 
convenience when you already have lists.

"""


def listops_difference(list_a,list_b):
  """
   <Purpose>
      Return a list that has all of the items in list_a that are not in list_b
      Duplicates are removed from the output list

   <Arguments>
      list_a, list_b:
        The lists to operate on

   <Exceptions>
      TypeError if list_a or list_b is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing list_a - list_b
  """

  retlist = []
  for item in list_a:
    if item not in list_b:
      retlist.append(item)

  # ensure that a duplicated item in list_a is only listed once
  return listops_uniq(retlist)


def listops_union(list_a,list_b):
  """
   <Purpose>
      Return a list that has all of the items in list_a or in list_b.   
      Duplicates are removed from the output list

   <Arguments>
      list_a, list_b:
        The lists to operate on

   <Exceptions>
      TypeError if list_a or list_b is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing list_a union list_b
  """

  retlist = list_a[:]
  for item in list_b: 
    if item not in list_a:
      retlist.append(item)

  # ensure that a duplicated item in list_a is only listed once
  return listops_uniq(retlist)


def listops_intersect(list_a,list_b):
  """
   <Purpose>
      Return a list that has all of the items in both list_a and list_b.   
      Duplicates are removed from the output list

   <Arguments>
      list_a, list_b:
        The lists to operate on

   <Exceptions>
      TypeError if list_a or list_b is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing list_a intersect list_b
  """

  retlist = []
  for item in list_a:
    if item in list_b:
      retlist.append(item)

  # ensure that a duplicated item in list_a is only listed once
  return listops_uniq(retlist)
      

def listops_uniq(list_a):
  """
   <Purpose>
      Return a list that has no duplicate items

   <Arguments>
      list_a
        The list to operate on

   <Exceptions>
      TypeError if list_a is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing the unique items in list_a
  """
  retlist = []
  for item in list_a:
    if item not in retlist:
      retlist.append(item)

  return retlist



#end include listops.repy
#begin include openDHTadvertise.repy
"""
Author: Justin Cappos

Start Date: July 8, 2008

Description:
Advertises availability to openDHT...

This code is partially adapted from the example openDHT code.

"""

#begin include random.repy
""" 
<Program Name>
  random.repy

<Author>
  Justin Cappos: random_sample

  Modified by Anthony Honstain
    random_nbit_int and random_long_to_bytes is modified from 
    Python Cryptography Toolkit and was part of pycrypto which 
    is maintained by Dwayne C. Litzenberger
    
    random_range, random_randint, and random_int_below are modified 
    from the Python 2.6.1 random.py module. Which was:
    Translated by Guido van Rossum from C source provided by
    Adrian Baddeley.  Adapted by Raymond Hettinger for use with
    the Mersenne Twister  and os.urandom() core generators.  

<Purpose>
  Random routines (similar to random module in Python)
  
  
<Updates needed when emulmisc.py adds randombytes function>
  TODO-
    random_nbit_int currently uses random_randombytes as a source 
    of random bytes, this is not a permanent fix (the extraction 
    of random bytes from the float is not portable). The change will
    likely be made to random_randombytes (since calls os.urandom will
    likely be restricted to a limited number of bytes).  
  TODO - 
    random_randombytes will remained but serve as a helper function
    to collect the required number of bytes. Calls to randombytes
    will be restricted to a set number of bytes at a time, since
    allowing an arbitrary request to os.urandom would circumvent 
    performance restrictions. 
  TODO - 
    _random_long_to_bytes will no longer be needed.  
      
"""

#begin include math.repy
""" Justin Cappos -- substitute for a few python math routines"""

def math_ceil(x):
  xint = int(x)
  
  # if x is positive and not equal to itself truncated then we should add 1
  if x > 0 and x != xint:
    xint = xint + 1

  # I return a float because math.ceil does
  return float(xint)



def math_floor(x):
  xint = int(x)
  
  # if x is negative and not equal to itself truncated then we should subtract 1
  if x < 0 and x != xint:
    xint = xint - 1

  # I return a float because math.ceil does
  return float(xint)



math_e = 2.7182818284590451
math_pi = 3.1415926535897931

# stolen from a link off of wikipedia (http://en.literateprograms.org/Logarithm_Function_(Python)#chunk use:logN.py)
# MIT license
#
# hmm, math_log(4.5,4)      == 1.0849625007211561
# Python's math.log(4.5,4)  == 1.0849625007211563
# I'll assume this is okay.
def math_log(X, base=math_e, epsilon=1e-16):
  # log is logarithm function with the default base of e
  integer = 0
  if X < 1 and base < 1:
    # BUG: the cmath implementation can handle smaller numbers...
    raise ValueError, "math domain error"
  while X < 1:
    integer -= 1
    X *= base
  while X >= base:
    integer += 1
    X /= base
  partial = 0.5               # partial = 1/2 
  X *= X                      # We perform a squaring
  decimal = 0.0
  while partial > epsilon:
    if X >= base:             # If X >= base then a_k is 1 
      decimal += partial      # Insert partial to the front of the list
      X = X / base            # Since a_k is 1, we divide the number by the base
    partial *= 0.5            # partial = partial / 2
    X *= X                    # We perform the squaring again
  return (integer + decimal)


#end include math.repy

def random_randombytes(num_bytes, random_float=None):
  """
   <Purpose>
     Return a string of length num_bytes, made of random bytes 
     suitable for cryptographic use (because randomfloat draws
     from a os provided random source).
      
     *WARNING* If python implements float as a C single precision
     floating point number instead of a double precision then
     there will not be 53 bits of data in the coefficient.

   <Arguments>
     num_bytes:
               The number of bytes to request from os.urandom. 
               Must be a positive integer value.
     random_float:
                  Should not be used, available only for testing
                  so that predetermined floats can be provided.
    
   <Exceptions>
     None

   <Side Effects>
     This function results in one or more calls to randomfloat 
     which uses a OS source of random data which is metered.

   <Returns>
     A string of num_bytes random bytes suitable for cryptographic use.
  """
  # To ensure accurate testing, this allows the source
  # of random floats to be supplied.
  if random_float is None: 
    random_float = randomfloat()
  
  randombytes = ''
  
  # num_bytes/6 + 1 is used because at most a single float
  # can only result in 6 bytes of random data. So an additional
  # 6 bytes is added and them trimmed to the desired size.
  for byte in range(num_bytes/6 + 1):
    
    # Convert the float back to a integer by multiplying
    # it by 2**53, 53 is used because the expected precision
    # of a python float will be a C type double with a 53 bit 
    # coefficient, this will still depend on the implementation
    # but the standard is to expect 53 bits.
    randomint = int(random_float * (2**53)) 
    # 53 bits trimmed down to 48bits
    # and 48bits is equal to 6 bytes
    randomint = randomint >> 5  
    
    # Transform the randomint into a byte string, 6 bytes were
    # used to create this integer, but several of the leading 
    # bytes could have been trimmed off in the process.
    sixbytes = _random_long_to_bytes(randomint)
    
    # Add on the zeroes that should be there.
    if len(sixbytes) < 6: 
      # pad additions binary zeroes that were lost during 
      # the floats creation.
      sixbytes = '\x00'*(6-len(sixbytes)) + sixbytes 
    randombytes += sixbytes
  
  return randombytes[6 - num_bytes % 6:]
  
  
  
def _random_long_to_bytes(long_int):
  """
  <Purpose>
    Convert a long integer to a byte string.   
    Used by random_randombytes to convert integers recovered
    from random floats into its byte representation.
    Used by random_randombytes, random_randombytes is responsible
    for padding any required binary zeroes that are lost in the
    conversion process.     
  """

  long_int = long(long_int)
  byte_string = ''
  temp_int = 0
  
  # Special case to ensure that a non-empty string
  # is always returned.
  if long_int == 0:
    return '\000'
  
  while long_int > 0:
    # Use a bitwise AND to get the last 8 bits from the long.
    #    long_int  -->   1010... 010000001 (base 2)
    #    0xFF      -->            11111111
    #              _______________________
    #  Bitwise AND result -->     10000001
    tmp_int = long_int & 0xFF
    # Place the new character at the front of the string.
    byte_string = "%s%s" % (chr(tmp_int), byte_string)
    # Bitshift the long because the trailing 8 bits have just been read.
    long_int = long_int >> 8
      
  return byte_string



def random_nbit_int(num_bits):  
  """
  <Purpose>
    Returns an random integer that was constructed with
    num_bits many random bits. The result will be an
    integer [0, 2**(num_bits) - 1] inclusive.
     
    For Example:
     If a 10bit number is needed, random_nbit_int(10).
     Min should be greater or equal to 0
     Max should be less than or equal to 1023

    TODO-
      This function currently uses random_randombytes as a source 
      of random bytes, this is not a permanent fix (the extraction 
      of random bytes from the float is not portable). The change will
      likely be made to random_randombytes (since calls os.urandom will
      likely be restricted to a limited number of bytes).

  <Arguments>
    num_bits:
             The number of random bits to be used for construction
             of the random integer to be returned.

  <Exceptions>
    TypeError if non-integer values for num_bits.
      Will accept floats of the type 1.0, 2.0, ...
    
    ValueError if the num_bits is negative or 0.

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of random data which is metered.

  <Returns>
    Returns a random integer between [0, 2**(num_bits) - 1] inclusive.
  
  <Walkthrough of functions operation>
    This will be a step by step walk through of the key operations
    defined in this function, with the largest possible
    10 bit integer returned.
    
    num_bits = 10
    
    randstring = random_randombytes(10/8)  for our example we
    will suppose that the byte returned was '\xff' (which is the
    same as chr(255)).
    
    odd_bits = 10 % 8 = 2
    Once again we assume that random_randombytes(1) returns the
    maximum possible, which is '\xff'  
    chr = ord('\xff') >> (8 - odd_bits)
    -> chr = 255 >> (8 - 2)
    -> chr = 255 >> 6 = 3   Note 3 is the largest 2 bit number
    chr(3) is appended to randstring resulting in
    randstring = '\x03\xff' 
    
    value = 0
    length = 2
    
    STEP 1 (i = 0):
      value = value << 8 
      -> value = 0
      value = value + ord(randstring[0])
      -> value = 3
    
    STEP 2 (i = 1):
      value = value << 8
      -> value = 768
      value = value + ord(randstring[1])
      -> value = 1023
    
    return 1023
    This is the maximum possible 10 bit integer.
  """
  if num_bits <= 0:
    raise ValueError('number of bits must be greater than zero')
  if num_bits != int(num_bits):
    raise TypeError('number of bits should be an integer')
  
  # The number of bits requested may not be a multiple of
  # 8, then an additional byte will trimmed down.
  randstring = random_randombytes(num_bits/8)

  odd_bits = num_bits % 8
  # A single random byte be converted to an integer (which will
  # be an element of [0,255]) it will then be shifted to the required
  # number of bits.
  # Example: if odd_bits = 3, then the 8 bit retrieved from the 
  # single byte will be shifted right by 5.
  if odd_bits != 0:
    char = ord(random_randombytes(1)) >> (8 - odd_bits)
    randstring = chr(char) + randstring
  
  # the random bytes in randstring will be read from left to right
  result = 0L
  length = len(randstring)
  for i in range(0, length):
    # While result = 0, the bitshift left will still result in 0
    # Since we are dealing with integers, this does not result
    # in the loss of any information.
    result = (result << 8) 
    result = result + ord(randstring[i]) 
  
  assert(result < (2 ** num_bits))
  assert(result >= 0)

  return result



def random_int_below(upper_bound):
  """
  <Purpose>
    Returns an random integer in the range [0,upper_bound)
    
    Handles the case where upper_bound has more bits than returned
    by a single call to the underlying generator.
     
    For Example:
     For a 10bit number, random_int_below(10).
     results would be an element in of the set 0,1,2,..,9.
     
    NOTE: This function is a port from the random.py file in 
    python 2.6.2. For large numbers I have experienced inconsistencies
    when using a naive logarithm function to determine the
    size of a number in bits.  

  <Arguments>
    upper_bound:
           The random integer returned will be in [0, upper_bound).
           Results will be integers less than this argument.

  <Exceptions>
    TypeError if non-integer values for upper_bound.
    ValueError if the upper_bound is negative or 0.

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of random data which is metered.

  <Returns>
    Returns a random integer between [0, upper_bound).
  
  """
  if upper_bound <= 0:
    raise ValueError('number must be greater than zero')
  if upper_bound != int(upper_bound):
    raise TypeError('number should be an integer')
  
  k = int(1.00001 + math_log(upper_bound - 1, 2.0))   # 2**k > n-1 > 2**(k-2)
  r = random_nbit_int(k)
  while r >= upper_bound:
    r = random_nbit_int(k)
  return r

 

def random_randrange(start, stop=None, step=1):
  """
  <Purpose>
    Choose a random item from range(start, stop[, step]).
    
  <Arguments>
    start:
      The random integer returned will be greater than
      or equal to start. 
  
    stop:
      The random integer returned will be less than stop.
      Results will be integers less than this argument.

    step:
      Determines which elements from the range will be considered.
     
  <Exceptions>
    ValueError:
      Non-integer for start or stop argument
      Empty range, if start < 0 and stop is None
      Empty range
      Zero or non-integer step for range

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of randomdata which is metered.
  
  <Returns>
    Random item from (start, stop[, step]) 'exclusive'
    
  <Notes on port>
    This fixes the problem with randint() which includes the
    endpoint; in Python this is usually not what you want.
    
    Anthony -I removed these since they do not apply
      int=int, default=None, maxwidth=1L<<BPF
      Do not supply the 'int', 'default', and 'maxwidth' arguments.
  """
  maxwidth = 1L<<53

  # This code is a bit messy to make it fast for the
  # common case while still doing adequate error checking.
  istart = int(start)
  if istart != start:
    raise ValueError, "non-integer arg 1 for randrange()"
  if stop is None:
    if istart > 0:
      if istart >= maxwidth:
        return random_int_below(istart)
      return int(randomfloat() * istart)
    raise ValueError, "empty range for randrange()"

  # stop argument supplied.
  istop = int(stop)
  if istop != stop:
    raise ValueError, "non-integer stop for randrange()"
  width = istop - istart
  if step == 1 and width > 0:
    # Note that
    #     int(istart + self.random()*width)
    # instead would be incorrect.  For example, consider istart
    # = -2 and istop = 0.  Then the guts would be in
    # -2.0 to 0.0 exclusive on both ends (ignoring that random()
    # might return 0.0), and because int() truncates toward 0, the
    # final result would be -1 or 0 (instead of -2 or -1).
    #     istart + int(self.random()*width)
    # would also be incorrect, for a subtler reason:  the RHS
    # can return a long, and then randrange() would also return
    # a long, but we're supposed to return an int (for backward
    # compatibility).

    if width >= maxwidth:
      return int(istart + random_int_below(width))
    return int(istart + int(randomfloat()*width))
  if step == 1:
    raise ValueError, "empty range for randrange() (%d,%d, %d)" % (istart, istop, width)

  # Non-unit step argument supplied.
  istep = int(step)
  if istep != step:
    raise ValueError, "non-integer step for randrange()"
  if istep > 0:
    n = (width + istep - 1) // istep
  elif istep < 0:
    n = (width + istep + 1) // istep
  else:
    raise ValueError, "zero step for randrange()"

  if n <= 0:
    raise ValueError, "empty range for randrange()"

  if n >= maxwidth:
    return istart + istep*random_int_below(n)
  return istart + istep*int(randomfloat() * n)



def random_randint(lower_bound, upper_bound):
  """
  <Purpose>
    Return random integer in range [lower_bound, upper_bound], 
    including both end points.
    
  <Arguments>
    upper_bound:
      The random integer returned will be less than upper_bound.
    lower_bound:
      The random integer returned will be greater than
      or equal to the lower_bound.

  <Exceptions>
    None

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of randomdata which is metered.
  
  <Returns>
    Random integer from [lower_bound, upper_bound] 'inclusive'  
  """
  return random_randrange(lower_bound, upper_bound+1)



def random_sample(population, k):
  """
  <Purpose>
    To return a list containing a random sample from the population.
    
  <Arguments>
    population:
               The elements to be sampled from.
    k: 
      The number of elements to sample
      
  <Exceptions>
    ValueError is sampler larger than population.
    
  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of randomdata which is metered.
    
  <Returns>
    A list of len(k) with random elements from the population.
    
  """
  
  newpopulation = population[:]
  if len(population) < k:
    raise ValueError, "sample larger than population"

  retlist = []
  populationsize = len(population)-1

  for num in range(k):
    pos = random_randint(0,populationsize-num)
    retlist.append(newpopulation[pos])
    del newpopulation[pos]

  return retlist

#end include random.repy
#begin include sha.repy
#!/usr/bin/env python
# -*- coding: iso-8859-1

"""A sample implementation of SHA-1 in pure Python.

   Adapted by Justin Cappos from the version at: http://codespeak.net/pypy/dist/pypy/lib/sha.py

   Framework adapted from Dinu Gherman's MD5 implementation by
   J. Hall`en and L. Creighton. SHA-1 implementation based directly on
   the text of the NIST standard FIPS PUB 180-1.

date    = '2004-11-17'
version = 0.91 # Modernised by J. Hall`en and L. Creighton for Pypy
"""



# ======================================================================
# Bit-Manipulation helpers
#
#   _long2bytes() was contributed by Barry Warsaw
#   and is reused here with tiny modifications.
# ======================================================================

def _sha_long2bytesBigEndian(n, thisblocksize=0):
    """Convert a long integer to a byte string.

    If optional blocksize is given and greater than zero, pad the front
    of the byte string with binary zeros so that the length is a multiple
    of blocksize.
    """

    # Justin: I changed this to avoid using pack. I didn't test performance, etc
    s = ''
    while n > 0:
        #original: 
        # s = struct.pack('>I', n & 0xffffffffL) + s
        # n = n >> 32
        s = chr(n & 0xff) + s
        n = n >> 8

    # Strip off leading zeros.
    for i in range(len(s)):
        if s[i] <> '\000':
            break
    else:
        # Only happens when n == 0.
        s = '\000'
        i = 0

    s = s[i:]

    # Add back some pad bytes. This could be done more efficiently
    # w.r.t. the de-padding being done above, but sigh...
    if thisblocksize > 0 and len(s) % thisblocksize:
        s = (thisblocksize - len(s) % thisblocksize) * '\000' + s

    return s


def _sha_bytelist2longBigEndian(list):
    "Transform a list of characters into a list of longs."

    imax = len(list)/4
    hl = [0L] * imax

    j = 0
    i = 0
    while i < imax:
        b0 = long(ord(list[j])) << 24
        b1 = long(ord(list[j+1])) << 16
        b2 = long(ord(list[j+2])) << 8
        b3 = long(ord(list[j+3]))
        hl[i] = b0 | b1 | b2 | b3
        i = i+1
        j = j+4

    return hl


def _sha_rotateLeft(x, n):
    "Rotate x (32 bit) left n bits circularly."

    return (x << n) | (x >> (32-n))


# ======================================================================
# The SHA transformation functions
#
# ======================================================================

# Constants to be used
sha_K = [
    0x5A827999L, # ( 0 <= t <= 19)
    0x6ED9EBA1L, # (20 <= t <= 39)
    0x8F1BBCDCL, # (40 <= t <= 59)
    0xCA62C1D6L  # (60 <= t <= 79)
    ]

class sha:
    "An implementation of the MD5 hash function in pure Python."

    def __init__(self):
        "Initialisation."
        
        # Initial message length in bits(!).
        self.length = 0L
        self.count = [0, 0]

        # Initial empty message as a sequence of bytes (8 bit characters).
        self.inputdata = []

        # Call a separate init function, that can be used repeatedly
        # to start from scratch on the same object.
        self.init()


    def init(self):
        "Initialize the message-digest and set all fields to zero."

        self.length = 0L
        self.inputdata = []

        # Initial 160 bit message digest (5 times 32 bit).
        self.H0 = 0x67452301L
        self.H1 = 0xEFCDAB89L
        self.H2 = 0x98BADCFEL
        self.H3 = 0x10325476L
        self.H4 = 0xC3D2E1F0L

    def _transform(self, W):

        for t in range(16, 80):
            W.append(_sha_rotateLeft(
                W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16], 1) & 0xffffffffL)

        A = self.H0
        B = self.H1
        C = self.H2
        D = self.H3
        E = self.H4

        """
        This loop was unrolled to gain about 10% in speed
        for t in range(0, 80):
            TEMP = _sha_rotateLeft(A, 5) + sha_f[t/20] + E + W[t] + sha_K[t/20]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL
        """

        for t in range(0, 20):
            TEMP = _sha_rotateLeft(A, 5) + ((B & C) | ((~ B) & D)) + E + W[t] + sha_K[0]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL

        for t in range(20, 40):
            TEMP = _sha_rotateLeft(A, 5) + (B ^ C ^ D) + E + W[t] + sha_K[1]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL

        for t in range(40, 60):
            TEMP = _sha_rotateLeft(A, 5) + ((B & C) | (B & D) | (C & D)) + E + W[t] + sha_K[2]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL

        for t in range(60, 80):
            TEMP = _sha_rotateLeft(A, 5) + (B ^ C ^ D)  + E + W[t] + sha_K[3]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL


        self.H0 = (self.H0 + A) & 0xffffffffL
        self.H1 = (self.H1 + B) & 0xffffffffL
        self.H2 = (self.H2 + C) & 0xffffffffL
        self.H3 = (self.H3 + D) & 0xffffffffL
        self.H4 = (self.H4 + E) & 0xffffffffL
    

    # Down from here all methods follow the Python Standard Library
    # API of the sha module.

    def update(self, inBuf):
        """Add to the current message.

        Update the md5 object with the string arg. Repeated calls
        are equivalent to a single call with the concatenation of all
        the arguments, i.e. m.update(a); m.update(b) is equivalent
        to m.update(a+b).

        The hash is immediately calculated for all full blocks. The final
        calculation is made in digest(). It will calculate 1-2 blocks,
        depending on how much padding we have to add. This allows us to
        keep an intermediate value for the hash, so that we only need to
        make minimal recalculation if we call update() to add more data
        to the hashed string.
        """

        leninBuf = long(len(inBuf))

        # Compute number of bytes mod 64.
        index = (self.count[1] >> 3) & 0x3FL

        # Update number of bits.
        self.count[1] = self.count[1] + (leninBuf << 3)
        if self.count[1] < (leninBuf << 3):
            self.count[0] = self.count[0] + 1
        self.count[0] = self.count[0] + (leninBuf >> 29)

        partLen = 64 - index

        if leninBuf >= partLen:
            self.inputdata[index:] = list(inBuf[:partLen])
            self._transform(_sha_bytelist2longBigEndian(self.inputdata))
            i = partLen
            while i + 63 < leninBuf:
                self._transform(_sha_bytelist2longBigEndian(list(inBuf[i:i+64])))
                i = i + 64
            else:
                self.inputdata = list(inBuf[i:leninBuf])
        else:
            i = 0
            self.inputdata = self.inputdata + list(inBuf)


    def digest(self):
        """Terminate the message-digest computation and return digest.

        Return the digest of the strings passed to the update()
        method so far. This is a 16-byte string which may contain
        non-ASCII characters, including null bytes.
        """

        H0 = self.H0
        H1 = self.H1
        H2 = self.H2
        H3 = self.H3
        H4 = self.H4
        inputdata = [] + self.inputdata
        count = [] + self.count

        index = (self.count[1] >> 3) & 0x3fL

        if index < 56:
            padLen = 56 - index
        else:
            padLen = 120 - index

        padding = ['\200'] + ['\000'] * 63
        self.update(padding[:padLen])

        # Append length (before padding).
        bits = _sha_bytelist2longBigEndian(self.inputdata[:56]) + count

        self._transform(bits)

        # Store state in digest.
        digest = _sha_long2bytesBigEndian(self.H0, 4) + \
                 _sha_long2bytesBigEndian(self.H1, 4) + \
                 _sha_long2bytesBigEndian(self.H2, 4) + \
                 _sha_long2bytesBigEndian(self.H3, 4) + \
                 _sha_long2bytesBigEndian(self.H4, 4)

        self.H0 = H0 
        self.H1 = H1 
        self.H2 = H2
        self.H3 = H3
        self.H4 = H4
        self.inputdata = inputdata 
        self.count = count 

        return digest


    def hexdigest(self):
        """Terminate and return digest in HEX form.

        Like digest() except the digest is returned as a string of
        length 32, containing only hexadecimal digits. This may be
        used to exchange the value safely in email or other non-
        binary environments.
        """
        return ''.join(['%02x' % ord(c) for c in self.digest()])

    def copy(self):
        """Return a clone object. (not implemented)

        Return a copy ('clone') of the md5 object. This can be used
        to efficiently compute the digests of strings that share
        a common initial substring.
        """
        raise Exception, "not implemented"


# ======================================================================
# Mimic Python top-level functions from standard library API
# for consistency with the md5 module of the standard library.
# ======================================================================

# These are mandatory variables in the module. They have constant values
# in the SHA standard.

sha_digest_size = sha_digestsize = 20
sha_blocksize = 1

def sha_new(arg=None):
    """Return a new sha crypto object.

    If arg is present, the method call update(arg) is made.
    """

    crypto = sha()
    if arg:
        crypto.update(arg)

    return crypto


# gives the hash of a string
def sha_hash(string):
    crypto = sha()
    crypto.update(string)
    return crypto.digest()


# gives the hash of a string
def sha_hexhash(string):
    crypto = sha()
    crypto.update(string)
    return crypto.hexdigest()

#end include sha.repy
#begin include xmlrpc_client.repy
"""
<Program Name>
  xmlrpc_client.py

<Started>
  May 3, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Implements the client-side XML-RPC protocol.

"""


#begin include urlparse.repy
"""
<Program Name>
  urlparse.repy

<Started>
  May 15, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Provides utilities for parsing URLs, based on the Python 2.6.1 module urlparse.

"""


def urlparse_urlsplit(urlstring, default_scheme="", allow_fragments=True):
  """
  <Purpose>
    Parse a URL into five components, returning a dictionary.  This corresponds
    to the general structure of a URL:
    scheme://netloc/path;parameters?query#fragment.  The parameters are not
    split from the URL and individual componenets are not separated.

    Only absolute server-based URIs are currently supported (all URLs will be
    parsed into the components listed, regardless of the scheme).

  <Arguments>
    default_scheme:
      Optional: defaults to the empty string.  If specified, gives the default
      addressing scheme, to be used only if the URL does not specify one.

    allow_fragments:
      Optional: defaults to True.  If False, fragment identifiers are not
      allowed, even if the URL's addressing scheme normally does support them.

  <Exceptions>
    ValueError on parsing a non-numeric port value.

  <Side Effects>
    None.

  <Returns>
    A dictionary containing:

    Key         Value                               Value if not present
    ============================================================================
    scheme      URL scheme specifier                empty string
    netloc      Network location part               empty string
    path        Hierarchical path                   empty string
    query       Query component                     empty string
    fragment    Fragment identifier                 empty string
    username    User name                           None
    password    Password                            None
    hostname    Host name (lower case)              None
    port        Port number as integer, if present  None

  """

  components = {"scheme": default_scheme, "netloc": "", "path": "", "query": "",
    "fragment": "", "username": None, "password": None, "hostname": None,
    "port": None }

  # Extract the scheme, if present.
  (lpart, rpart) = _urlparse_splitscheme(urlstring)
  if lpart:
    components["scheme"] = lpart

  # Extract the server information, if present.
  if rpart.startswith("//"):
    (lpart, rpart) = _urlparse_splitnetloc(rpart, 2)
    components["netloc"] = lpart

    (components["username"], components["password"], components["hostname"],
      components["port"]) = _urlparse_splitauthority(lpart)

  # Extract the fragment.
  if allow_fragments:
    (rpart, components["fragment"]) = _urlparse_splitfragment(rpart)


  # Extract the query.
  (components["path"], components["query"]) = _urlparse_splitquery(rpart)

  return components


def _urlparse_splitscheme(url):
  """Parse the scheme portion of the URL"""
  # The scheme is valid only if it contains these characters.
  scheme_chars = \
    "abcdefghijklmnopqrstuvwxyz0123456789+-."

  scheme = ""
  rest = url

  spart = url.split(":", 1)
  if len(spart) == 2:

    # Normalize the scheme.
    spart[0] = spart[0].lower()

    # A scheme is valid only if it starts with an alpha character.
    if spart[0] and spart[0][0].isalpha():
      for char in spart[0]:
        if char not in scheme_chars:
          break
      (scheme, rest) = spart

  return scheme, rest


def _urlparse_splitnetloc(url, start=0):
  """Parse the netloc portion of the URL"""

  # By default, the netloc is delimited by the end of the URL.
  delim = len(url)

  # Find the left-most delimiter.
  for char in "/?#":
    xdelim = url.find(char, start)
    if xdelim >= 0:
      delim = min(delim, xdelim)

  # Return the netloc and the rest of the URL.
  return url[start:delim], url[delim:]


def _urlparse_splitauthority(netloc):
  """Parse the authority portion of the netloc"""

  # The authority can have a userinfo portion delimited by "@".
  authority = netloc.split("@", 1)

  # Default values.
  username = None
  password = None
  hostname = None
  port = None

  # Is there a userinfo portion?
  if len(authority) == 2:

    # userinfo can be split into username:password
    userinfo = authority[0].split(":", 1)

    # hostport can be split into hostname:port
    hostport = authority[1].split(":", 1)

    if userinfo[0]:
      username = userinfo[0]
    if len(userinfo) == 2:
      password = userinfo[1]

  # No userinfo portion found.
  else:

    # hostport can be split into hostname:port
    hostport = netloc.split(":", 1)

  # Is there a port value?
  if hostport[0]:
    hostname = hostport[0]
  if len(hostport) == 2:
    port = int(hostport[1], 10)

  # Return the values.
  return username, password, hostname, port


def _urlparse_splitquery(url):
  """Parse the query portion of the url"""

  qpart = url.split("?", 1)
  if len(qpart) == 2:
    query = qpart[1]
  else:
    query = ""

  return qpart[0], query


def _urlparse_splitfragment(url):
  """Parse the query portion of the url"""

  fpart = url.split("#", 1)
  if len(fpart) == 2:
    fragment = fpart[1]
  else:
    fragment = ""

  return fpart[0], fragment

#end include urlparse.repy
#begin include httpretrieve.repy
"""
<Program Name>
  httpretrieve.repy

<Started>
  August 19, 2009

<Authors>
  Yafete Yemuru
  Conrad Meyer
  
<Purpose>
  Provides a method for retrieving content from web servers using the HTTP
  protocol. The content can be accessed as a file like object, or saved to
  a file or returned as a string.
"""



#begin include urlparse.repy
#already included urlparse.repy
#end include urlparse.repy
#begin include sockettimeout.repy
"""
<Author>
  Justin Cappos, Armon Dadgar
  This is a rewrite of the previous version by Richard Jordan

<Start Date>
  26 Aug 2009

<Description>
  A library that causes sockets to timeout if a recv / send call would
  block for more than an allotted amount of time.

"""


class SocketTimeoutError(Exception):
  """The socket timed out before receiving a response"""


class _timeout_socket():
  """
  <Purpose>
    Provides a socket like object which supports custom timeouts
    for send() and recv().
  """

  # Initialize with the socket object and a default timeout
  def __init__(self,socket,timeout=10, checkintv=0.1):
    """
    <Purpose>
      Initializes a timeout socket object.

    <Arguments>
      socket:
              A socket like object to wrap. Must support send,recv,close, and willblock.

      timeout:
              The default timeout for send() and recv().

      checkintv:
              How often socket operations (send,recv) should check if
              they can run. The smaller the interval the more time is
              spent busy waiting.
    """
    # Store the socket, timeout and check interval
    self.socket = socket
    self.timeout = timeout
    self.checkintv = checkintv


  # Allow changing the default timeout
  def settimeout(self,timeout=10):
    """
    <Purpose>
      Allows changing the default timeout interval.

    <Arguments>
      timeout:
              The new default timeout interval. Defaults to 10.
              Use 0 for no timeout. Given in seconds.

    """
    # Update
    self.timeout = timeout
  
  
  # Wrap willblock
  def willblock(self):
    """
    See socket.willblock()
    """
    return self.socket.willblock()


  # Wrap close
  def close(self):
    """
    See socket.close()
    """
    return self.socket.close()


  # Provide a recv() implementation
  def recv(self,bytes,timeout=None):
    """
    <Purpose>
      Allows receiving data from the socket object with a custom timeout.

    <Arguments>
      bytes:
          The maximum amount of bytes to read

      timeout:
          (Optional) Defaults to the value given at initialization, or by settimeout.
          If provided, the socket operation will timeout after this amount of time (sec).
          Use 0 for no timeout.

    <Exceptions>
      As with socket.recv(), socket.willblock(). Additionally, SocketTimeoutError is
      raised if the operation times out.

    <Returns>
      The data received from the socket.
    """
    # Set the timeout if None
    if timeout is None:
      timeout = self.timeout

    # Get the start time
    starttime = getruntime()

    # Block until we can read
    rblock, wblock = self.socket.willblock()
    while rblock:
      # Check if we should break
      if timeout > 0:
        # Get the elapsed time
        diff = getruntime() - starttime

        # Raise an exception
        if diff > timeout:
          raise SocketTimeoutError,"recv() timed out!"

      # Sleep
      sleep(self.checkintv)

      # Update rblock
      rblock, wblock = self.socket.willblock()

    # Do the recv
    return self.socket.recv(bytes)


  # Provide a send() implementation
  def send(self,data,timeout=None):
    """
    <Purpose>
      Allows sending data with the socket object with a custom timeout.

    <Arguments>
      data:
          The data to send

      timeout:
          (Optional) Defaults to the value given at initialization, or by settimeout.
          If provided, the socket operation will timeout after this amount of time (sec).
          Use 0 for no timeout.

    <Exceptions>
      As with socket.send(), socket.willblock(). Additionally, SocketTimeoutError is
      raised if the operation times out.

    <Returns>
      The number of bytes sent.
    """
    # Set the timeout if None
    if timeout is None:
      timeout = self.timeout

    # Get the start time
    starttime = getruntime()

    # Block until we can write
    rblock, wblock = self.socket.willblock()
    while wblock:
      # Check if we should break
      if timeout > 0:
        # Get the elapsed time
        diff = getruntime() - starttime

        # Raise an exception
        if diff > timeout:
          raise SocketTimeoutError,"send() timed out!"

      # Sleep
      sleep(self.checkintv)

      # Update rblock
      rblock, wblock = self.socket.willblock()

    # Do the recv
    return self.socket.send(data) 




def timeout_openconn(desthost, destport, localip=None, localport=None, timeout=5):
  """
  <Purpose> 
    Wrapper for openconn.   Very, very similar

  <Args>
    Same as Repy openconn

  <Exception>
    Raises the same exceptions as openconn.

  <Side Effects>
    Creates a socket object for the user

  <Returns>
    socket obj on success
  """

  realsocketlikeobject = openconn(desthost, destport, localip, localport, timeout)

  thissocketlikeobject = _timeout_socket(realsocketlikeobject, timeout)
  return thissocketlikeobject





def timeout_waitforconn(localip, localport, function, timeout=5):
  """
  <Purpose> 
    Wrapper for waitforconn.   Essentially does the same thing...

  <Args>
    Same as Repy waitforconn with the addition of a timeout argument.

  <Exceptions> 
    Same as Repy waitforconn

  <Side Effects>
    Sets up event listener which calls function on messages.

  <Returns>
    Handle to listener.
  """

  # We use a closure for the callback we pass to waitforconn so that we don't
  # have to map mainch's to callback functions or deal with potential race
  # conditions if we did maintain such a mapping. 
  def _timeout_waitforconn_callback(localip, localport, sockobj, ch, mainch):
    # 'timeout' is the free variable 'timeout' that was the argument to
    #  timeout_waitforconn.
    thissocketlikeobject = _timeout_socket(sockobj, timeout)

    # 'function' is the free variable 'function' that was the argument to
    #  timeout_waitforconn.
    return function(localip, localport, thissocketlikeobject, ch, mainch)

  return waitforconn(localip, localport, _timeout_waitforconn_callback)

  
  


# a wrapper for stopcomm
def timeout_stopcomm(commhandle):
  """
    Wrapper for stopcomm.   Does the same thing...
  """

  return stopcomm(commhandle)
  
    


#end include sockettimeout.repy
#begin include urllib.repy
def urllib_quote(inputstring, safestring="/"):
  """
  <Purpose>
    Encode an inputstring such that it can be used safely in a URL or XML
    document.

  <Arguments>
    inputstring:
           The string to urlencode.

    safestring (optional):
           Specifies additional characters that should not be quoted --
           defaults to "/".

  <Exceptions>
    TypeError if the inputstring or safestring parameters aren't strings.

  <Side Effects>
    None.

  <Returns>
    Urlencoded version of the passed string.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_quote's inputstring parameter must be a string, not '"+str(type(inputstring))+"'")
  if type(safestring) is not str:
    raise TypeError("urllib_quote's safestring parameter must be a string, not '"+str(type(safestring))+"'")
  

  resultstr = ""

  # We go through each character in the string; if it's not in [0-9a-zA-Z]
  # we wrap it.

  safeset = set(safestring)

  for char in inputstring:
    asciicode = ord(char)
    if (asciicode >= ord("0") and asciicode <= ord("9")) or \
        (asciicode >= ord("A") and asciicode <= ord("Z")) or \
        (asciicode >= ord("a") and asciicode <= ord("z")) or \
        asciicode == ord("_") or asciicode == ord(".") or \
        asciicode == ord("-") or char in safeset:
      resultstr += char
    else:
      resultstr += "%%%02X" % asciicode

  return resultstr




def urllib_quote_plus(inputstring, safestring=""):
  """
  <Purpose>
    Encode a string to go in the query fragment of a URL.

  <Arguments>
    inputstring:
           The string to urlencode.

    safestring (optional):
           Specifies additional characters that should not be quoted --
           defaults to the empty string.

  <Exceptions>
    TypeError if the inputstring or safestring parameters aren't strings.

  <Side Effects>
    None.

  <Returns>
    Urlencoded version of the passed string.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_quote_plus' inputstring parameter must be a string, not '"+str(type(inputstring))+"'")
  if type(safestring) is not str:
    raise TypeError("urllib_quote_plus' safestring parameter must be a string, not '"+str(type(safestring))+"'")
  

  return urllib_quote(inputstring, safestring + " ").replace(" ", "+")




def urllib_unquote(inputstring):
  """
  <Purpose>
    Unquote a urlencoded string.

  <Arguments>
    inputstring:
           The string to unquote.

  <Exceptions>
    TypeError if the inputstring isn't a string
    ValueError thrown if the last wrapped octet isn't a valid wrapped octet
    (i.e. if the string ends in "%" or "%x" rather than "%xx". Also throws
    ValueError if the nibbles aren't valid hex digits.

  <Side Effects>
    None.

  <Returns>
    The decoded string.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_unquote's inputstring parameter must be a string, not '"+str(type(inputstring))+"'")
  

  resultstr = ""

  # We go through the inputstring from end to beginning, looking for wrapped
  # octets. When one is found we add it (unwrapped) and the following
  # string to the resultant string, and shorten the original inputstring.

  while True:
    lastpercentlocation = inputstring.rfind("%")
    if lastpercentlocation < 0:
      break

    wrappedoctetstr = inputstring[lastpercentlocation+1:lastpercentlocation+3]
    if len(wrappedoctetstr) != 2:
      raise ValueError("Quoted string is poorly formed")

    resultstr = \
        chr(int(wrappedoctetstr, 16)) + \
        inputstring[lastpercentlocation+3:] + \
        resultstr
    inputstring = inputstring[:lastpercentlocation]

  resultstr = inputstring + resultstr
  return resultstr




def urllib_unquote_plus(inputstring):
  """
  <Purpose>
    Unquote the urlencoded query fragment of a URL.

  <Arguments>
    inputstring:
           The string to unquote.

  <Exceptions>
    TypeError if the inputstring isn't a string
    ValueError thrown if the last wrapped octet isn't a valid wrapped octet
    (i.e. if the inputstring ends in "%" or "%x" rather than "%xx". Also throws
    ValueError if the nibbles aren't valid hex digits.

  <Side Effects>
    None.

  <Returns>
    The decoded string.
  """
  if type(inputstring) is not str:
    raise TypeError("urllib_unquote_plus' inputstring parameter must be a string, not '"+str(type(inputstring))+"'")

  return urllib_unquote(inputstring.replace("+", " "))




def urllib_quote_parameters(inputdictionary):
  """
  <Purpose>
    Encode a dictionary of (key, value) pairs into an HTTP query string or
    POST body (same form).

  <Arguments>
    dictionary:
           The dictionary to quote.

  <Exceptions>
    TypeError if the inputdictionary isn't a dict.

  <Side Effects>
    None.

  <Returns>
    The quoted dictionary.
  """
  if type(inputdictionary) is not dict:
    raise TypeError("urllib_quote_parameters' inputstringdictionary parameter must be a dict, not '"+str(type(inputstring))+"'")

  quoted_keyvals = []
  for key, val in inputdictionary.items():
    quoted_keyvals.append("%s=%s" % (urllib_quote(key), urllib_quote(val)))

  return "&".join(quoted_keyvals)




def urllib_unquote_parameters(inputstring):
  """
  <Purpose>
    Decode a urlencoded query string or POST body.

  <Arguments>
    inputstring:
           The string to decode.

  <Exceptions>
    TypeError if the inputstring isn't a string
    ValueError if the inputstring is poorly formed.

  <Side Effects>
    None.

  <Returns>
    A dictionary mapping keys to values.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_unquote_parameters' inputstring parameter must be a string, not '"+str(type(inputstring))+"'")

  keyvalpairs = inputstring.split("&")
  res = {}

  for quotedkeyval in keyvalpairs:
    # Throw ValueError if there is more or less than one '='.
    quotedkey, quotedval = quotedkeyval.split("=")
    key = urllib_unquote_plus(quotedkey)
    val = urllib_unquote_plus(quotedval)
    res[key] = val

  return res

#end include urllib.repy



class HttpConnectionError(Exception):
  """
  Error indicating that the web server has unexpectedly dropped the
  connection.
  """




class HttpBrokenServerError(Exception):
  """
  Error indicating that the web server has sent us complete garbage instead
  of something resembling HTTP.
  """




def httpretrieve_open(url, querydata=None, postdata=None,\
    httpheaders=None, proxy=None, timeout=None):
  """
  <Purpose>
     Returns a file-like object that can be used to read the content from
     an HTTP server. Follows 3xx redirects.

  <Arguments>
    url:
           The URL to perform a GET or POST request on.
    postdata (optional):
           A dictionary of form data or a string to POST to the server.
           Passing a non-None value results in a POST request being sent
           to the server.
    querydata (optional):
           A dictionary of form data or a string to send as the query
           string to the server.

           If postdata is omitted, the URL is retrieved with GET. If
           both postdata and querydata are omitted, there is no query
           string sent in the request.

           For both querydata and postdata, strings are sent *unmodified*.
           This means you probably should encode them first, with
           urllib_quote().
    httpheaders (optional):
           A dictionary of supplemental HTTP request headers to add to the
           request.
    proxy (optional):
           A proxy server 2-tuple to bind to: ('host', port).       
    timeout (optional):
           A timeout for establishing a connection to the web server,
           sending headers, and reading the response headers.

           If excluded or None, never times out.

  <Exceptions>
    ValueError if given an invalid URL, or malformed limit or timeout
      values. This is also raised if the user attempts to call a method
      on the file-like object after closing it.

    HttpConnectionError if opening the connection fails, or if the
      connection is closed by the server before we expect.

    SocketTimeoutError if the timeout is exceeded.

    HttpBrokenServerError if the response or the Location response header
      is malformed.

  <Side Effects>
    None

  <Returns>
    Returns a file-like object which can be used to read the body of
    the response from the web server. The protocol version spoken by the
    server, status code, and response headers are available as members of
    the object.
  """

  starttimefloat = getruntime()

  # Check if the URL is valid and get host, path, port and query
  parsedurldict = urlparse_urlsplit(url)
  hoststr = parsedurldict['hostname']
  pathstr = parsedurldict['path']
  portint = parsedurldict.get('port')
  portint = portint or 80

  if parsedurldict['scheme'] != 'http':
    raise ValueError("URL doesn't seem to be for the HTTP protocol.")
  if hoststr is None:
    raise ValueError("Missing hostname.")
  if parsedurldict['query'] is not None and parsedurldict['query'] != "":
    raise ValueError("URL cannot include a query string.")

  # Typical HTTP sessions consist of (optionally, a series of pairs of) HTTP
  # requests followed by HTTP responses. These happen serially.

  # Open connection to the web server
  try:
    if proxy is not None:
      # if there is a proxy, open a connection with the proxy instead of the actual server
      # use the timeout we are given (or none)
      sockobj = timeout_openconn(proxy[0], proxy[1], timeout=timeout)  
    else:
      # if there is no proxy open a connection with server directly
      # use the timeout we are given (or none)
      sockobj = timeout_openconn(hoststr, portint, timeout=timeout)

  except Exception, e:
    if repr(e).startswith("timeout("):
      raise HttpConnectionError("Socket timed out connecting to host/port.")
    raise

  # Builds the HTTP request:
  httprequeststr = _httpretrieve_build_request(hoststr, portint, pathstr, \
      querydata, postdata, httpheaders, proxy)

  # Send the full HTTP request to the web server.
  _httpretrieve_sendall(sockobj, httprequeststr)

  # Now, we're done with the HTTP request part of the session, and we need
  # to get the HTTP response.

  # Check if we've timed out (if the user requested a timeout); update the
  # socket timeout to reflect the time taken sending the request.
  if timeout is None:
    sockobj.settimeout(0)
  elif getruntime() - starttimefloat >= timeout:
    raise SocketTimeoutError("Timed out")
  else:
    sockobj.settimeout(timeout - (getruntime() - starttimefloat))

  # Receive the header lines from the web server (a series of CRLF-terminated
  # lines, terminated by an empty line, or by the server closing the
  # connection.
  headersstr = ""
  while not headersstr.endswith("\r\n\r\n"):
    try:
      # This should probably be replaced with page-sized reads in the future,
      # but for now, the behavior is at least correct.
      headersstr += sockobj.recv(1)
    except Exception, e:
      if str(e) == "Socket closed":
        break
      else:
        raise

  httpheaderlist = headersstr.split("\r\n")
  # Ignore (a) trailing blank line(s) (for example, the response header-
  # terminating blank line).
  while len(httpheaderlist) > 0 and httpheaderlist[-1] == "":
    httpheaderlist = httpheaderlist[:-1]

  # Get the status code and status message from the HTTP response.
  statuslinestr, httpheaderlist = httpheaderlist[0], httpheaderlist[1:]

  # The status line should be in the form: "HTTP/1.X NNN SSSSS", where
  # X is 0 or 1, NNN is a 3-digit status code, and SSSSS is a 'user-friendly'
  # string representation of the status code (may contain spaces).
  statuslinelist = statuslinestr.split(' ', 2)

  if len(statuslinelist) < 3:
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (status line missing one or more fields).")

  if not statuslinelist[0].startswith('HTTP'):
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (invalid response protocol in status line).")

  friendlystatusstr = statuslinelist[2]
  try:
    statusint = int(statuslinelist[1])
  except ValueError, e:
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (status code isn't integer).")

  httpheaderdict = _httpretrieve_parse_responseheaders(httpheaderlist)

  # If we got any sort of redirect response, follow the redirect. Note: we
  # do *not* handle the 305 status code (use the proxy as specified in the
  # Location header) at all; I think this is best handled at a higher layer
  # anyway.
  if statusint in (301, 302, 303, 307):
    sockobj.close()
    try:
      redirecturlstr = httpheaderdict["Location"][0]
    except (KeyError, IndexError), ke:
      # When a server returns a redirect status code (3xx) but no Location
      # header, some clients, e.g. Firefox, just show the response body
      # as they would normally for a 2xx or 4xx response. So, I think we
      # should ignore a missing Location header and just return the page
      # to the caller.
      pass
    else:
      # If the server did send a redirect location, let's go there.
      return httpretrieve_open(redirecturlstr)

  # If we weren't requested to redirect, and we didn't, return a read-only
  # file-like object (representing the response body) to the caller.
  return _httpretrieve_filelikeobject(sockobj, httpheaderdict, \
      (statuslinelist[0], statusint, friendlystatusstr))




def httpretrieve_save_file(url, filename, querydata=None, postdata=None, \
    httpheaders=None, proxy=None, timeout=None):
  """
  <Purpose>
    Perform an HTTP request, and save the content of the response to a
    file.

  <Arguments>
    filename:
           The file name to save the response to.
    Other arguments:
           See documentation for httpretrieve_open().

  <Exceptions>
    This function will raise any exception raised by Repy file objects
    in opening, writing to, and closing the file.

    This function will all also raise any exception raised by
    httpretrieve_open(), for the same reasons.

  <Side Effects>
    Writes the body of the response to 'filename'.

  <Returns>
    None
  """

  # Open the output file object and http file-like object.
  outfileobj = open(filename, 'w')
  httpobj = httpretrieve_open(url, querydata=querydata, postdata=postdata, \
      httpheaders=httpheaders, proxy=proxy, timeout=timeout)

  # Repeatedly read from the file-like HTTP object into our file, until the
  # response is finished.
  responsechunkstr = None
  while responsechunkstr != '':
    responsechunkstr = httpobj.read(4096)
    outfileobj.write(responsechunkstr)

  outfileobj.close()
  httpobj.close()




def httpretrieve_get_string(url, querydata=None, postdata=None, \
    httpheaders=None, proxy=None, timeout=30):
  """
  <Purpose>
    Performs an HTTP request on the given URL, using POST or GET,
    returning the content of the response as a string. Uses
    httpretrieve_open.

  <Arguments>
    See httpretrieve_open.

  <Exceptions>
    See httpretrieve_open.

  <Side Effects>
    None.

  <Returns>
    Returns the body of the HTTP response (no headers).
  """

  # Open a read-only file-like object for the HTTP request.
  httpobj = httpretrieve_open(url, querydata=querydata, postdata=postdata, \
      httpheaders=httpheaders, proxy=proxy, timeout=timeout)

  # Read all of the response and return it.
  try:
    return httpobj.read()
  finally:
    httpobj.close()




class _httpretrieve_filelikeobject:
  # This class implements a file-like object used for performing HTTP
  # requests and retrieving responses.

  def __init__(self, sock, headers, httpstatus):
    # The socket-like object connected to the HTTP server. Headers have
    # already been read.
    self._sockobj = sock

    # If this is set, the close() method has already been called, so we
    # don't accept future reads.
    self._fileobjclosed = False

    # This flag is set if we've finished recieving the entire response
    # from the server.
    self._totalcontentisreceived = False

    # This integer represents the number of bytes read so far.
    self._totalread = 0

    # This is the dictionary of HTTP response headers associated with this
    # file-like object.
    self.headers = headers

    # The HTTP status tuple of this response, e.g. ("HTTP/1.0", 200, "OK")
    self.httpstatus = httpstatus



  def read(self, limit=None, timeout=None):
    """
    <Purpose>
      Behaves like Python's file.read(), with the potential to raise
      additional informative exceptions.

    <Arguments>
      limit (optional):
            The maximum amount of data to read. If omitted or None, this
            reads all available data.

    <Exceptions>
      See file.read()'s documentation, as well as that of
      httpretrieve_open().

    <Side Effects>
      None.

    <Returns>
      See file.read().
    """

    # Raise an error if the caller has already close()d this object.
    if self._fileobjclosed:
      raise ValueError("I/O operation on closed file")

    # If we've finished reading everything we can from the server, return the
    # empty string.
    if self._totalcontentisreceived:
      return ''

    lefttoread = None
    if limit is not None:
      lefttoread = limit

      # Sanity check type/value of limit.
      if type(limit) is not int:
        raise TypeError("Expected an integer or None for read() limit")
      elif limit < 0:
        raise ValueError("Expected a non-negative integer for read() limit")

    if timeout is None:
      self._sockobj.settimeout(0)
    else:
      self._sockobj.settimeout(timeout)

    # Try to read up to limit, or until there is nothing left.
    httpcontentstr = ''
    while True:
      try:
        contentchunkstr = self._sockobj.recv(lefttoread or 4096)
      except Exception, e:
        if str(e) == "Socket closed":
          self._totalcontentisreceived = True
          break
        else:
          raise
      
      httpcontentstr += contentchunkstr
      self._totalread += len(contentchunkstr)
      if limit is not None:
        if len(contentchunkstr) == lefttoread:
          break
        else:
          lefttoread -= len(contentchunkstr)
      if contentchunkstr == "":
        self._totalcontentisreceived = True
        break

    return httpcontentstr



  def close(self):
    """
    <Purpose>
      Close the file-like object.

    <Arguments>
      None

    <Exceptions>
      None

    <Side Effects>
      Disconnects from the HTTP server.

    <Returns>
      Nothing
    """
    self._fileobjclosed = True
    self._sockobj.close()




def _httpserver_put_in_headerdict(res, lastheader, lastheader_str):
  # Helper function that tries to put the header into a dictionary of lists,
  # 'res'.
  if lastheader is not None:
    if lastheader not in res:
      res[lastheader] = []
    res[lastheader].append(lastheader_str.strip())




def _httpretrieve_parse_responseheaders(headerlines):
  # Parse rfc822-style headers (this could be abstracted out to an rfc822
  # library that would be quite useful for internet protocols). Returns
  # a dictionary mapping headers to arrays of values. E.g.:
  #
  # Foo: a
  # Bar:
  #   b
  # Bar: c
  #
  # Becomes: {"Foo": ["a"], "Bar": ["b", "c"]}

  # These variables represent the key and value of the last header we found,
  # unless we are parsing the very first header. E.g., if we've just read:
  #   Content-Type: text/html
  # Then, lastheaderkeystr == "Content-Type",
  # lastheadervaluestr == "text/html"

  lastheaderkeystr = None
  lastheadervaluestr = ""

  resdict = {}
  
  if len(headerlines) == 0:
    return {}

  try:
    # Iterate over the request header lines:
    for i in range(len(headerlines)):
      # Lines with leading non-CRLF whitespace characters are part of the
      # previous line (see rfc822 for details).
      if headerlines[i][0] in (" ", "\t") and lastheaderkeystr is not None:
        lastheadervaluestr += headerlines[i]
      else:
        _httpserver_put_in_headerdict(resdict, lastheaderkeystr, lastheadervaluestr)
        lastheaderkeystr, lastheadervaluestr = headerlines[i].split(":", 1)

    # Add the last line to the result dictionary.
    _httpserver_put_in_headerdict(resdict, lastheaderkeystr, lastheadervaluestr)

    return resdict

  except IndexError, idx:
    raise HttpBrokenServerError("Server returned garbage for HTTP" + \
        " response. Bad headers.")




def _httpretrieve_build_request(host, port, path, querydata, postdata, \
    httpheaders, proxy):
  # Builds an HTTP request from these parameters, returning it as
  # a string.

  # Sanity checks:
  if path == "":
    raise ValueError("Invalid path -- empty string.")
  if postdata is not None and type(postdata) not in (str, dict):
    raise TypeError("Postdata should be a dict of form-data or a string")
  if querydata is not None and type(querydata) not in (str, dict):
    raise TypeError("Querydata should be a dict of form-data or a string")
  if httpheaders is not None and type(httpheaders) is not dict:
    raise TypeError("Expected HTTP headers as a dictionary.")

  # Type-conversions:
  if type(querydata) is dict:
    querydata = urllib_quote_parameters(querydata)
  elif querydata is None:
    querydata = ""

  if type(postdata) is dict:
    postdata = urllib_quote_parameters(postdata)

  # Default to GET, unless the caller specifies a message body to send.
  methodstr = "GET"
  if postdata is not None:
    methodstr = "POST"

  # Encode the path and querystring part of the request.
  resourcestr = querydata
  if querydata != "":
    resourcestr = "?" + resourcestr

  # Encode the HTTP request line and headers:
  if proxy is not None:
    # proxy exists thus the request header should include the original requested url  
    requeststr = methodstr + ' http://' + host + ':' + str(port) + path + resourcestr + ' HTTP/1.0\r\n'
  else:
    # there is no proxy; send normal http request   
    requeststr = methodstr + ' ' + path + resourcestr + ' HTTP/1.0\r\n'
    
  if httpheaders is not None:
    # Most servers require a 'Host' header for normal functionality
    # (especially in the case of multiple domains being hosted on a
    # single server).
    if "Host" not in httpheaders:
      requeststr += "Host: " + host + ':' + str(port) + "\r\n"

    for key, val in httpheaders.items():
      requeststr += key + ": " + val + '\r\n'

  # Affix post-data related headers and content:
  if methodstr == "POST":
    requeststr += 'Content-Length: ' + str(len(postdata)) + '\r\n'

  # The empty line terminates HTTP headers.
  requeststr += '\r\n'

  # If we're a POST request, affix any requested data to the message body.
  if methodstr == "POST":
    requeststr += postdata

  return requeststr




def _httpretrieve_sendall(sockobj, datastr):
  # Helper function that attempts to dump all of the data in datastr to the
  # socket sockobj (data is any arbitrary bytes).
  while len(datastr) > 0:
    datastr = datastr[sockobj.send(datastr):]

#end include httpretrieve.repy
#begin include xmlrpc_common.repy
"""
<Program Name>
  $Id: xmlrpc_common.repy 3260 2009-12-09 18:26:31Z cemeyer $

<Started>
  April 26, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Provides common methods related to XML-RPC.

  Encoding dateTime.iso8601 are not currently supported.

<Changes>

  2009-04-26  Michael Phan-Ba  <mdphanba@gmail.com>

  * Initial release

  2009-05-24  Michael Phan-Ba  <mdphanba@gmail.com>

  * Added change log
  * Fixed base64 name error
  * Set property svn:keyword to "Id" 

"""


#begin include base64.repy
"""
<Program Name>
  $Id: base64.repy 2527 2009-07-26 22:48:38Z cemeyer $

<Started>
  April 12, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Provides data encoding and decoding as specified in RFC 3548. This
  module implements a subset of the Python module base64 interface.

  b32encode(), b32decode(), b16encode(), b16decode(), decode(),
  decodestring(), encode(), and encodestring() are not currently
  implemented.

<Changes>

  2009-04-12  Michael Phan-Ba  <mdphanba@gmail.com>

  * Initial release

  2009-05-23  Michael Phan-Ba  <mdphanba@gmail.com>

  * (b64encode, b64decode, standard_b64encode, standard_b64decode,
    urlsafe_encode, urlsafe_decode): Renamed functions with base64 prefix

  2009-05-24  Michael Phan-Ba  <mdphanba@gmail.com>

  * Set property svn:keyword to "Id" 

"""

# The Base64 for use in encoding
BASE64_ALPHABET = \
  "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"

def base64_b64encode(s, altchars=None):
  """
  <Purpose>
    Encode a string using Base64.

  <Arguments>
    s:
      The string to encode.

    altchars:
      An optional string of at least length 2 (additional characters are
      ignored) which specifies an alternative alphabet for the + and /
      characters.  The default is None, for which the standard Base64
      alphabet is used.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The encoded string.

  """
  # Build the local alphabet.
  if altchars is None:
    base64_alphabet = BASE64_ALPHABET
  else:
    base64_alphabet = BASE64_ALPHABET[:62] + altchars

  # Change from characters to integers for binary operations.
  bytes = []
  for x in s:
    bytes.append(ord(x))

  # Encode the 8-bit words into 6-bit words.
  x6bit_words = []
  index = 0
  while True:

    # Encode the first 6 bits from three 8-bit values.
    try:
      x8bits = bytes[index]
    except IndexError:
      break
    else:
      x6bits = x8bits >> 2
      leftover_bits = x8bits & 3
      x6bit_words.append(base64_alphabet[x6bits])

    # Encode the next 8 bits.
    try:
      x8bits = bytes[index + 1]
    except IndexError:
      x6bits = leftover_bits << 4
      x6bit_words.extend([base64_alphabet[x6bits], "=="])
      break
    else:
      x6bits = (leftover_bits << 4) | (x8bits >> 4)
      leftover_bits = x8bits & 15
      x6bit_words.append(base64_alphabet[x6bits])

    # Encode the final 8 bits.
    try:
      x8bits = bytes[index + 2]
    except IndexError:
      x6bits = leftover_bits << 2
      x6bit_words.extend([base64_alphabet[x6bits], "="])
      break
    else:
      x6bits = (leftover_bits << 2) | (x8bits >> 6)
      x6bit_words.append(base64_alphabet[x6bits])
      x6bits = x8bits & 63
      x6bit_words.append(base64_alphabet[x6bits])

    index += 3

  return "".join(x6bit_words)

def base64_b64decode(s, altchars=None):
  """
  <Purpose>
    Decode a Base64 encoded string.  The decoder ignores all non
    characters not in the Base64 alphabet for compatibility with the
    Python library.  However, this introduces a security loophole in
    which covert or malicious data may be passed.

  <Arguments>
    s:
      The string to decode.

    altchars:
      An optional string of at least length 2 (additional characters are
      ignored) which specifies an alternative alphabet for the + and /
      characters.  The default is None, for which the standard Base64
      alphabet is used.

  <Exceptions>
    None.

  <Side Effects>
    TypeError on decoding error.

  <Returns>
    The decoded string.

  """
  # Build the local alphabet.
  if altchars is None:
    base64_alphabet = BASE64_ALPHABET
  else:
    base64_alphabet = BASE64_ALPHABET[:62] + altchars

  # Generate the translation maps for decoding a Base64 string.
  translate_chars = []
  for x in xrange(256):
    char = chr(x)
    translate_chars.append(char)

  # Build the strings of characters to delete.
  delete_chars = []
  for x in translate_chars:
    if x not in base64_alphabet:
      delete_chars.append(x)
  delete_chars = "".join(delete_chars)

  # Insert the 6-bit Base64 values into the translation string.
  k = 0
  for v in base64_alphabet:
    translate_chars[ord(v)] = chr(k)
    k += 1
  translate_chars = "".join(translate_chars)

  # Count the number of padding characters at the end of the string.
  num_pad = 0
  i = len(s) - 1
  while i >= 0:
    if s[i] == "=":
      num_pad += 1
    else:
      break
    i -= 1

  # Translate the string into 6-bit characters and delete extraneous
  # characters.
  s = s.translate(translate_chars, delete_chars)

  # Determine correct alignment by calculating the number of padding
  # characters needed for compliance to the specification.
  align = (4 - (len(s) & 3)) & 3
  if align == 3:
    raise TypeError("Incorrectly encoded base64 data (has 6 bits of trailing garbage)")
  if align > num_pad:
    # Technically, this isn't correctly padded. But it's recoverable, so let's
    # not care.
    pass

  # Change from characters to integers for binary operations.
  x6bit_words = []
  for x in s:
    x6bit_words.append(ord(x))
  for x in xrange(align):
    x6bit_words.append(-1)

  # Decode the 6-bit words into 8-bit words.
  bytes = []
  index = 0
  while True:

    # Work on four 6-bit quantities at a time.  End when no more data is
    # available.
    try:
      (x6bits1, x6bits2, x6bits3, x6bits4) = x6bit_words[index:index + 4]
    except ValueError:
      break

    # Save an 8-bit quantity.
    bytes.append((x6bits1 << 2) | (x6bits2 >> 4))

    # End of valid data.
    if x6bits3 < 0:
      break

    # Save an 8-bit quantity.
    bytes.append(((x6bits2 & 15) << 4) | (x6bits3 >> 2))

    # End of valid data.
    if x6bits4 < 0:
      break

    # Save an 8-bit quantity.
    bytes.append(((x6bits3 & 3) << 6) | x6bits4)

    # Next four 6-bit quantities.
    index += 4

  return "".join([chr(x) for x in bytes])

def base64_standard_b64encode(s):
  """
  <Purpose>
    Encode a string using the standard Base64 alphabet.

  <Arguments>
    s:
      The string to encode.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The encoded string.

  """
  return base64_b64encode(s)

def base64_standard_b64decode(s):
  """
  <Purpose>
    Decode a Base64 encoded string using the standard Base64 alphabet.

  <Arguments>
    s:
      The string to decode.

  <Exceptions>
    None.

  <Side Effects>
    TypeError on decoding error.

  <Returns>
    The decoded string.

  """
  return base64_b64decode(s)


def base64_urlsafe_b64encode(s):
  """
  <Purpose>
    Encode a string using a URL-safe alphabet, which substitutes -
    instead of + and _ instead of / in the standard Base64 alphabet.

  <Arguments>
    s:
      The string to encode.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The encoded string.

  """
  return base64_b64encode(s, "-_")


def base64_urlsafe_b64decode(s):
  """
  <Purpose>
    Decode a Base64 encoded string using a URL-safe alphabet, which
    substitutes - instead of + and _ instead of / in the standard Base64
    alphabet.

  <Arguments>
    s:
      The string to decode.

  <Exceptions>
    None.

  <Side Effects>
    TypeError on decoding error.

  <Returns>
    The decoded string.

  """
  return base64_b64decode(s, "-_")

#end include base64.repy
#begin include xmlparse.repy
"""
<Program Name>
  xmlparse.repy

<Started>
  April 2009

<Author>
  Conrad Meyer <cemeyer@u.washington.edu>

<Purpose>
  Provide a relatively simplistic but usable xml parsing library for
  RePy.
"""

class xmlparse_XMLParseError(Exception):
  """Exception raised when an error is encountered parsing the XML."""
  pass




class xmlparse_XMLTreeNode:
  """
  <Purpose>
    Provide a simple tree structure for XML data.

  <Exceptions>
    None.

  <Example Use>
    node = xmlparse_parse("<Some><xml><data></data></xml></Some>")
  """   


  def __init__(self, tag_name):
    self.tag_name = tag_name
    self.children = None
    self.content = None
    self.attributes = {}


  def __repr__(self):
    """Provide a pretty representation of an XML tree."""

    if self.content is not None:
      return "%s:\"%s\"" % (self.tag_name, self.content)
    else:
      return "%s:%s" % (self.tag_name, str(self.children))


  def to_string(self):
    result = "<" + self.tag_name
    for attribute_name in self.attributes.keys():
      attribute_value_escaped = \
          self.attributes[attribute_name].replace("\"", "\\\"")
      result += " " + attribute_name + "=\"" + attribute_value_escaped + "\""
    
    if self.content is None:
      result += ">"
      for childnode in self.children:
        result += childnode.to_string()
      result += "</" + self.tag_name + ">"
    else:
      if len(self.content) == 0:
        result += "/>"
      else:
        result += ">" + self.content + "</" + self.tag_name + ">"

    return result




def xmlparse_parse(data):
  """
  <Purpose>
    Parses an XML string into an xmlparse_XMLTreeNode containing the root
    item.

  <Arguments>
    data:
           The data to parse.

  <Exceptions>
    xmlparse_XMLParseError if parsing fails.

  <Side Effects>
    None.

  <Returns>
    An xmlparse_XMLTreeNode tree.
  """

  data = data.lstrip()
  if data.startswith("<?xml"):
    data = data[data.find("?>")+2:]
  
  # Well-formed XML Documents have exactly one root node
  parsed_elements = _xmlparse_parse(data)
  if len(parsed_elements) != 1:
    raise xmlparse_XMLParseError("XML response from server contained more than one root node")

  return parsed_elements[0]




def _xmlparse_read_attributes(string):
  # Returns a pair containing the dictionary of attributes and remainder
  # of the string on success; excepts on failure.

  # Q_n corresponds to the state_* constant of the same value. The starting
  # node is Q_1.
  #
  #  [ Done ]
  #     ^
  #     |
  #     | (>, /)
  #     |
  #     \--------\ 
  #              |
  #        ,-.   | v-----------------------------------\
  # space (   [ Q_1 ]                                  |
  #        `->   | ^-----------------------\ (')       |
  #              |                         |           |
  #              |                (')      |   <-.     | (")
  #              | non-space   /------->[ Q_4 ]   )    |
  #              |             |               `-'     |
  #  (space)     v     (=)     |             (other)   |
  #     /-----[ Q_2 ]------>[ Q_3 ]-------->[ Q_5 ]----/
  #     |      ^   )           |      (")    ^   )
  #     |       `-'            |              `-'
  #     |     (other)   (other)|             (other)
  #     |                      |
  #     v                      |
  #[Exception]<----------------/

  # Basically the state machine is used to read a list of attribute-pairs,
  # terminated by a '/' or '>'. Attribute pairs either look like:
  #   name='value'
  # or:
  #   name="value"
  # Single-quoted attributes can contain double-quotes, and vice-versa, but
  # single-quotes in single-quoted attributes must be escaped.
  # 
  # To do this we start in Q_1, which consumes input until we arrive at
  # something that looks like an attribute name. In Q_2 we consume characters
  # for the attribute name until it looks like the attribute name is finished.
  # In Q_3 we read a single character to determine what type of quoting is
  # used for the attribute value. In Q_4 or Q_5, we read the attribute's value
  # until the string is closed, then go back to Q_1 (saving the attribute name
  # and value into the dictionary). We decide we are done when we encounter a
  # '>' or '/' in Q_1.

  # Constant states:
  state_EXPECTING_ATTRNAME = 1
  state_READING_ATTRNAME = 2
  state_EXPECTING_ATTRVALUE = 3
  state_READING_ATTRVALUE_SINGLEQUOTE = 4
  state_READING_ATTRVALUE_DOUBLEQUOTE = 5

  current_position = 0
  current_state = 1
  current_attrname = ""
  current_attrvalue = ""
  attributes = {}

  while True:
    if current_position >= len(string):
      raise xmlparse_XMLParseError(
          "Failed to parse element attribute list -- input ran out " + \
              "before we found a closing '>' or '/'")

    current_character = string[current_position]

    if current_state == state_EXPECTING_ATTRNAME:
      if current_character.isspace():
        pass    # We stay in this state
      elif current_character == '>' or current_character == '/':
        # We're finished reading attributes
        return (attributes, string[current_position:])
      else:
        current_attrname += current_character
        current_state = state_READING_ATTRNAME

    elif current_state == state_READING_ATTRNAME:
      if current_character.isspace():
        raise xmlparse_XMLParseError(
            "Failed to parse element attribute list -- attribute " + \
                "ended unexpectedly with a space")
      elif current_character == "=":
        current_state = state_EXPECTING_ATTRVALUE
      else:
        current_attrname += current_character

    elif current_state == state_EXPECTING_ATTRVALUE:
      if current_character == '\'':
        current_state = state_READING_ATTRVALUE_SINGLEQUOTE
      elif current_character == '"':
        current_state = state_READING_ATTRVALUE_DOUBLEQUOTE
      else:
        raise xmlparse_XMLParseError(
            "Failed to parse element attribute list -- attribute " + \
                "values must be quoted")

    elif current_state == state_READING_ATTRVALUE_SINGLEQUOTE:
      if current_character == '\'':
        attributes[current_attrname] = current_attrvalue
        current_state = state_EXPECTING_ATTRNAME
        current_attrname = ""
        current_attrvalue = ""
      else:
        current_attrvalue += current_character

    elif current_state == state_READING_ATTRVALUE_DOUBLEQUOTE:
      if current_character == '"':
        attributes[current_attrname] = current_attrvalue
        current_state = state_EXPECTING_ATTRNAME
        current_attrname = ""
        current_attrvalue = ""
      else:
        current_attrvalue += current_character

    current_position += 1




def _xmlparse_node_from_string(string):
  # string:
  #   <tag attr1="value" attr2='value'>content</tag>
  # Content may be a string or a list of children nodes depending on if the
  # first non-space character is a '<' or not.

  string = string.lstrip()
  if not string.startswith("<"):
    raise xmlparse_XMLParseError("Error parsing XML -- doesn't " + \
        "start with '<'")

  string = string[1:]

  read_pos = 0
  while True:
    if read_pos >= len(string):
      raise xmlparse_XMLParseError("Error parsing XML -- parser " + \
          "ran out of input trying to read a tag")

    # The tag name is ended with a space or a closing angle-brace or
    # a "/".
    curchar = string[read_pos]
    if curchar.isspace() or curchar == ">" or curchar == "/":
      break

    read_pos += 1

  tag = string[0:read_pos]
  string = string[read_pos:]

  # Get the attribute dictionary and remaining string (which will be
  # "> ... [ inner stuff ] </[tag_name]>" or "/>" for well-formed XML).
  attributes, string = _xmlparse_read_attributes(string)

  # "Empty" elements look like: "<[tag_name] [... maybe attributes] />" and
  # not "Empty" elements look like:
  # "<[tag_name] [... maybe attributes]> [inner content] </[tag_name]>".
  empty_element = False
  if string.startswith(">"):
    string = string[1:]
  elif string.startswith("/>"):
    string = string[2:]
    empty_element = True

  xmlnode = xmlparse_XMLTreeNode(tag)
  xmlnode.attributes = attributes

  if empty_element:
    xmlnode.content = ""

  else:
    # Locate the end-boundary of the inner content of this element.
    ending_tag_position = string.rfind("</")
    if ending_tag_position < 0:
      raise xmlparse_XMLParseError("XML parse error -- could not " + \
          "locate closing tag")

    # If this elements starting and closing tag names do not match, this XML
    # is not well-formed.
    if not string.startswith("</" + tag, ending_tag_position):
      raise xmlparse_XMLParseError("XML parse error -- different " + \
          "opening / closing tags at the same nesting level")

    # If the inner content starts with another element, this element has
    # children.  Otherwise, it has content, which is just a string containing
    # the inner content.
    tag_body = string[:ending_tag_position]
    if tag_body.lstrip().startswith("<"):
      xmlnode.children = _xmlparse_parse(tag_body.lstrip())
    else:
      xmlnode.content = tag_body

  return xmlnode




def _xmlparse_find_next_tag(xmldata):
  # Finds the position of the start of the next same-level tag in this XML
  # document.

  read_position = 0
  nested_depth = 0

  original_length = len(xmldata)
  xmldata = xmldata.lstrip()
  length_difference = original_length - len(xmldata)

  # Seek to another XML tag at the same depth.
  while True:
    if xmldata.startswith("</", read_position) or \
        xmldata.startswith("/>", read_position):
      nested_depth -= 1
    elif xmldata.startswith("<", read_position):
      nested_depth += 1

    read_position += 1

    if read_position >= len(xmldata):
      return read_position + length_difference

    if nested_depth == 0:
      nexttagposition = xmldata.find("<", read_position)

      if nexttagposition < 0:
        return original_length
      else:
        return nexttagposition + length_difference




def _xmlparse_parse(xmldata):
  # Takes a raw XML stream and returns a list of XMLTreeNodes.

  nodelist = []

  while True:
    # Whitespace between tags isn't important to the content of
    # an XML document.
    xmldata = xmldata.strip()

    # Strip out XML comments.
    if xmldata.startswith("<!--"):
      commentendloc = xmldata.find("-->", 4)
      if commentendloc < 0:
        raise xmlparse_XMLParseError("XML parse error -- comment " + \
            "missing close tag ('-->')")
      xmldata = xmldata[commentendloc+3:]
      continue

    # Find the end of the current tag.
    nexttagend = _xmlparse_find_next_tag(xmldata)

    thisnode_str = xmldata[0:nexttagend]
    xmldata = xmldata[nexttagend:]

    # Parse a tag out of the string we just found.
    thisnode = _xmlparse_node_from_string(thisnode_str)
    nodelist.append(thisnode)

    if not xmldata.strip().startswith("<"):
      break

  return nodelist

#end include xmlparse.repy





class xmlrpc_common_Binary(object):
  """
  <Purpose>
    Wrapper class for base64-encoded binary data in XML-RPC requests and
    responses.  This class is used when sending and receiving binary
    data through XML-RPC.

  <Side Effects>
    None.

  <Example Use>
    blob = xmlrpc_common_Binary("\x00\x01\x00")

  """

  def __init__(self, data=""):
    """
    <Purpose>
      Create a new Binary wrapper object for use with the XML-RPC
      libraries.

    <Arguments>
      data:
        The unencoded binary data.

    <Exceptions>
      None.

    """
    self.data = data





class xmlrpc_common_Fault(ValueError):
  """
  <Purpose>
    Exception representing a XML-RPC Fault.  The exception is returned
    by the parsing functions when a XML-RPC server returns a fault.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_Fault("An error occurred", -1)

  """

  def __init__(self, message, code):
    """
    <Purpose>
      Create a new Fault exception.

    <Arguments>
      message:
        A string describing the fault.

      code:
        The integer code associated with the fault.

    <Exceptions>
      None.

    """
    self.strerror = message
    self.code = code
    ValueError.__init__(self, message)





class xmlrpc_common_Timeout(Exception):
  """
  <Purpose>
    Exception representing a normal timeout occuring.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_Timeout()

  """





class xmlrpc_common_XMLParseError(ValueError):
  """
  <Purpose>
    Exception representing an error in parsing XML-RPC data.  The
    exception is thrown when bad XML data is encountered.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_XMLParseError()

  """





class xmlrpc_common_ConnectionError(ValueError):
  """
  <Purpose>
    Exception representing an error in the connection to an XMLRPC server.
    Thrown when the server closes the connection unexpectedly.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_ConnectionError()

  """





def xmlrpc_common_call2xml(method_name, params):
  """
  <Purpose>
    Build a XML-RPC method call to send to a XML-RPC server.

  <Arguments>
    method_name:
      The method name.

    params:
      A sequence type of XML-RPC parameters.  A dictionary may also be
      passed, but the keys are ignored.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC method call string.

  """
  xml_string = ['<?xml version="1.0"?>',
    "<methodCall><methodName>%s</methodName>" % method_name,
    _xmlrpc_common_params2xml(params),
    "</methodCall>"]

  return "".join(xml_string)


def xmlrpc_common_response2xml(param):
  """
  <Purpose>
    Build a XML-RPC method response to send to a XML-RPC client.  This
    is the XML document that represents the return values or fault from
    a XML-RPC call.

  <Arguments>
    param:
      The value to be returned.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC method response string.

  """
  xml_string = ['<?xml version="1.0"?><methodResponse>',
    _xmlrpc_common_params2xml((param,)),
    "</methodResponse>"]

  return "".join(xml_string)


def xmlrpc_common_fault2xml(message, code):
  """
  <Purpose>
    Build a XML-RPC fault response to send to a XML-RPC client.  A fault
    response can occur from a server failure, an incorrectly generated
    XML request, or bad program arguments.

  <Arguments>
    message:
      A string describing the fault.

    code:
      The integer code associated with the fault.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC fault response string.

  """
  struct = {"faultCode": code, "faultString": message}
  xml_string = ['<?xml version="1.0"?><methodResponse><fault>',
    _xmlrpc_common_value2xml(struct),
    "</fault></methodResponse>"]

  return "".join(xml_string)


def _xmlrpc_common_params2xml(params):
  """
  <Purpose>
    Translate Python parameter values to XML-RPC for use in building a
    XML-RPC request or response.

  <Arguments>
    params:
      A sequence type of XML-RPC parameters.  A dictionary may also be
      passed, but the keys are ignored.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC parameters string.

  """
  if params is None or params is ():
    return ""

  xml_string = ["<params>"]

  for param in params:
    xml_string.append("<param>%s</param>" % _xmlrpc_common_value2xml(param))

  xml_string.append("</params>")

  return "".join(xml_string)


def _xmlrpc_common_value2xml(obj):
  """
  <Purpose>
    Translate a Python value to XML-RPC for use in building the params
    portion of a request or response.

  <Arguments>
    obj:
      The Python object to convert.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC value string.

  """
  object_type = type(obj)

  xml_string = ["<value>"]

  if obj is None:
    xml_string.append("<nil/>")

  elif object_type is bool:
    xml_string.append("<boolean>%d</boolean>" % int(obj))

  elif object_type in (int, long):
    xml_string.append("<int>%d</int>" % obj)

  elif object_type is float:
    xml_string.append("<double>%f</double>" % obj)

  elif object_type in (str, unicode, basestring):
    xml_string.append("<string>%s</string>" % obj)

  elif object_type in (list, tuple, xrange, set, frozenset):
    xml_string.append("<array><data>")
    for value in obj:
      xml_string.append(_xmlrpc_common_value2xml(value))
    xml_string.append("</data></array>")

  elif object_type is dict:
    xml_string.append("<struct>")
    for key, value in obj.iteritems():
      xml_string.append("<member><name>%s</name>" % key)
      xml_string.append(_xmlrpc_common_value2xml(value))
      xml_string.append("</member>")
    xml_string.append("</struct>")

  # This requires the new object inheritance model to be used. e.g. do
  #   class Foo(object): pass
  # rather than
  #   class Foo: pass
  elif object_type is xmlrpc_common_Binary:
    xml_string.append("<base64>%s</base64>" % base64_standard_b64encode(obj.data))

  else:
    raise ValueError("Marshaller: Unsupported type '%s'" % type(obj))

  xml_string.append("</value>")

  return "".join(xml_string)


def xmlrpc_common_call2python(xml):
  """
  <Purpose>
    Convert a XML-RPC method call to its Python equivalent.

    The request from a XML-RPC client is parsed into native Python
    types so that the server may use the data to execute a method, as
    appropriate.

  <Arguments>
    xml:
      The XML-RPC string to convert.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.
    xmlparse_XMLParseError on a general XML parse error.

  <Side Effects>
    None.

  <Returns>
    A tuple containing (1) the method name and (2) a list of the
    parameters.

  """
  xml_node = xmlparse_parse(xml)

  if xml_node.tag_name != "methodCall":
    message = "Unexpected root node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)
  elif xml_node.children is None:
    raise xmlrpc_common_XMLParseError("No parameters found")
  elif len(xml_node.children) > 2:
    raise xmlrpc_common_XMLParseError("Too many children for 'methodCall'")

  try:
    method_name_node = xml_node.children[0]
    if method_name_node.tag_name != "methodName":
      message = "Unexpected XML node: %s" % method_name_node.tag_name
      raise xmlrpc_common_XMLParseError(message)
    method_name = method_name_node.content
  except IndexError:
    raise xmlrpc_common_XMLParseError("No method name found")

  try:
    params = _xmlrpc_common_params2python(xml_node.children[1])
  except IndexError:
    return (method_name, ())

  if not params:
    raise xmlrpc_common_XMLParseError("No parameters found")

  return (method_name, params)


def xmlrpc_common_response2python(xml):
  """
  <Purpose>
    Convert a XML-RPC method response to its Python equivalent.

    The response from a XML-RPC server is parsed into native Python
    types so that the client may use the data as appropriate.

  <Arguments>
    xml:
      The XML-RPC string to convert.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.
    xmlparse_XMLParseError on a general XML parse error.

  <Side Effects>
    None.

  <Returns>
    The method results or a xmlrpc_common_Fault on reading a fault.

  """
  xml_node = xmlparse_parse(xml)

  if xml_node.tag_name != "methodResponse":
    message = "Unexpected root node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)
  elif xml_node.children is None:
    raise xmlrpc_common_XMLParseError("No parameters found")
  elif len(xml_node.children) > 1:
    raise xmlrpc_common_XMLParseError("Too many children for 'methodCall'")

  fault_node = xml_node.children[0]
  if fault_node.tag_name == "fault":
    if fault_node.children is None:
      raise xmlrpc_common_XMLParseError("No children found for 'fault'")
    elif len(fault_node.children) != 1:
      raise xmlrpc_common_XMLParseError("Too many children for 'fault'")
    params = _xmlrpc_common_value2python(fault_node.children[0])
    try:
      return xmlrpc_common_Fault(params["faultString"], params["faultCode"])
    except KeyError:
      raise xmlrpc_common_XMLParseError("Invalid fault object")

  try:
    params = _xmlrpc_common_params2python(xml_node.children[0])
  except KeyError:
    raise xmlrpc_common_XMLParseError("No parameters found")

  if len(params) != 1:
    raise xmlrpc_common_XMLParseError("Too many children for 'params'")

  return params[0]


def _xmlrpc_common_params2python(xml_node):
  """
  <Purpose>
    Convert XML-RPC params the Python equivalent.

    The parameters portion of a XML-RPC request or response is parsed
    into Python equivalents so that the method request and response
    parsing functions can return the relevant data.

  <Arguments>
    xml_node:
      The XML node to consider.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.

  <Side Effects>
    None.

  <Returns>
    The method results.

  """
  if xml_node.tag_name != "params":
    message = "Unexpected XML node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)

  if xml_node.children is None or len(xml_node.children) < 1:
    return []

  params = []

  for param_node in xml_node.children:
    if param_node.tag_name != "param":
      message = "Unexpected XML node: %s" % param_node.tag_name
      raise xmlrpc_common_XMLParseError(message)
    elif param_node.children is None:
      raise xmlrpc_common_XMLParseError("Unexpected empty param node")
    elif len(param_node.children) > 1:
      raise xmlrpc_common_XMLParseError("Too many children for 'param'")
    params.append(_xmlrpc_common_value2python(param_node.children[0]))

  return params


def _xmlrpc_common_value2python(xml_node):
  """
  <Purpose>
    Convert a XML-RPC value the Python equivalent.

    A XML-RPC value is converted to its Python equivalent for use in the
    parameters parser.

  <Arguments>
    xml_node:
      The XML node to consider.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.

  <Side Effects>
    None.

  <Returns>
    The method results.

  """

  if xml_node.tag_name not in ("value",):
    message = "Unexpected XML node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)

  # The values that XMLRPC can encode have an optional type-specifier.
  # If the type-specifier is not included, the data is simply a string
  # and doesn't need any other special interpretation. Additionally, there
  # is an optional <string> type specifier, but e.g. openDHT doesn't use
  # it. If xml_node.children is None here, the data lacks a type-specifying
  # tag, so it is to be interpreted as a string.
  elif xml_node.children is not None and len(xml_node.children) > 1:
    raise xmlrpc_common_XMLParseError("Too many children for 'value'")

  value_node = xml_node

  # Assume string by default, as explained earlier.
  tag = "string"
  if xml_node.children is not None:
    # If the xml specifies a type, override the default.
    value_node = xml_node.children[0]
    tag = value_node.tag_name

  # The string contents of the <value> tag (or of the type-specifying tag
  # inside <value>, if one exists).
  value = value_node.content

  if tag == "nil":
    return None

  elif tag == "boolean":
    return bool(int(value))

  elif tag in ("i4", "int"):
    return int(value)

  elif tag == "double":
    return float(value)

  elif tag == "string":
    return value

  elif tag == "array":
    if len(value_node.children) > 1:
      raise xmlrpc_common_XMLParseError("Too many children for 'array'")
    # Arrays are encoded as:  <array><data>
    #                           <value>...</value>
    #                           ...
    #                         </data></array>
    data_node = value_node.children[0]
    result = []
    if data_node.children:
      for item_node in data_node.children:
        result.append(_xmlrpc_common_value2python(item_node))
    return result

  elif tag == "struct":
    result = {}

    # Structs are encoded as: <struct>
    #                           <member><name>...</name><value>...</value></member>
    #                           ...
    #                         </struct>
    # Keys (<name>) do not contain type information, so they are strings
    # as far as XMLRPC is concerned.
    for member_node in value_node.children:
      if len(member_node.children) != 2:
        message = "Incorrect number of children for 'member'"
        raise xmlrpc_common_XMLParseError(message)

      key = member_node.children[0].content
      value = _xmlrpc_common_value2python(member_node.children[1])

      result[key] = value

    return result

  elif tag == "base64":
    return xmlrpc_common_Binary(base64_standard_b64decode(value_node.content))

  else:
    message = "Demarshaller: Unsupported value type: %s" % value_node.tag_name
    raise xmlrpc_common_XMLParseError(message)

#end include xmlrpc_common.repy


class xmlrpc_client_Client(object):
  """
  <Purpose>
    XML-RPC client implementation.

  <Side Effects>
    None.

  <Example Use>
    client = xmlrpc_client_Client("http://phpxmlrpc.sourceforge.net/server.php")
    print client.send_request("examples.getStateName", (1,))

  """


  USER_AGENT = "seattlelib/1.0.0"


  def __init__(self, url):
    """
    <Purpose>
      Create a new XML-RPC Client object to do RPC calls to the given
      server.

    <Arguments>
      url:
        A url containing the hostname, port, and path of the xmlrpc
        server. For example, "http://phpxmlrpc.soureforge.net/server.php".

    <Exceptions>
      None.

    """

    if not isinstance(url, (str, unicode)):
      raise ValueError("Invalid argument: url must be a URL string")

    urlcomponents = urlparse_urlsplit(url, "http", False)

    self.server_host = urlcomponents["hostname"]
    self.server_port = urlcomponents["port"] or 80
    self.server_path = urlcomponents["path"] or "/"
    if urlcomponents["query"]:
      self.server_path += "?" + urlcomponents["query"]

    if not self.server_host:
      raise ValueError("Invalid argument: url must have a valid host")


  def send_request(self, method_name, params, timeout=None):
    """
    <Purpose>
      Send a XML-RPC request to a XML-RPC server to do a RPC call.

    <Arguments>
      method_name:
        The method name.

      params:
        The method parameters.

    <Exceptions>
      socket.error on socket errors, including server timeouts.
      xmlrpc_common_Fault on a XML-RPC response fault.
      xmlrpc_common_XMLParseError on a XML-RPC structural parse error.
      xmlparse_XMLParseError on a general XML parse error.
      xmlrpc_common_ConnectionError on unexpected disconnects.
      xmlrpc_common_Timeout if the time limit is exceeded.

    <Side Effects>
      None.

    <Returns>
      The XML-RPC method return values.

    """

    starttime = getruntime()

    # Prepare the XML request.
    request_xml = xmlrpc_common_call2xml(method_name, params)

    response = httpretrieve_get_string("http://%s:%s%s" % (self.server_host, \
        self.server_port, self.server_path), postdata=request_xml, \
        timeout=timeout, httpheaders={\
        "User-Agent": self.USER_AGENT, "Content-Type": "text/xml"})

    # Timeout if the POST took too long.
    if timeout is not None and getruntime() - starttime > timeout:
      raise xmlrpc_common_Timeout()

    # Parse the XML response body into Python values.
    response_value = xmlrpc_common_response2python(response)

    # If a fault was decoded, raise the exception.
    if isinstance(response_value, xmlrpc_common_Fault):
      raise response_value

    # Otherwise, return the results.
    return response_value

#end include xmlrpc_client.repy
#begin include parallelize.repy
""" 
Author: Justin Cappos

Module: A parallelization module.   It performs actions in parallel to make it
        easy for a user to call a function with a list of tasks.

Start date: November 11th, 2008

This module is adapted from code in seash which had similar functionality.

NOTE (for the programmer using this module).   It's really important to 
write concurrency safe code for the functions they provide us.  It will not 
work to write:

def foo(...):
  mycontext['count'] = mycontext['count'] + 1

YOU MUST PUT A LOCK AROUND SUCH ACCESSES.

"""


# I use this to get unique identifiers. 
#begin include uniqueid.repy
""" 
Author: Justin Cappos

Module: A simple library that provides a unique ID for each call

Start date: November 11th, 2008

This is a really, really simple module, only broken out to avoid duplicating 
functionality.

NOTE: This will give unique ids PER FILE.   If you have multiple python 
modules that include this, they will have the potential to generate the
same ID.

"""

# This is a list to prevent using part of the user's mycontext dict
uniqueid_idlist = [0]
uniqueid_idlock = getlock()

def uniqueid_getid():
  """
   <Purpose>
      Return a unique ID in a threadsafe way

   <Arguments>
      None

   <Exceptions>
      None

   <Side Effects>
      None.

   <Returns>
      The ID (an integer)
  """

  uniqueid_idlock.acquire()

  # I'm using a list because I need a global, but don't want to use the 
  # programmer's dict
  myid = uniqueid_idlist[0]
  uniqueid_idlist[0] = uniqueid_idlist[0] + 1

  uniqueid_idlock.release()

  return myid



#end include uniqueid.repy



class ParallelizeError(Exception):
  """An error occurred when operating on a parallelized task"""


# This has information about all of the different parallel functions.
# The keys are unique integers and the entries look like this:
# {'abort':False, 'callfunc':callfunc, 'callargs':callargs,
# 'targetlist':targetlist, 'availabletargetpositions':positionlist,
# 'runninglist':runninglist, 'result':result}
#
# abort is used to determine if future events should be aborted.
# callfunc is the function to call
# callargs are extra arguments to pass to the function
# targetlist is the list of items to call the function with
# runninglist is used to track which events are executing
# result is a dictionary that contains information about completed function.
#    The format of result is:
#      {'exception':list of tuples with (target, exception string), 
#       'aborted':list of targets,
#       'returned':list of tuples with (target, return value)}
# 
parallelize_info_dict = {}



def parallelize_closefunction(parallelizehandle):
  """
   <Purpose>
      Clean up the state created after calling parallelize_initfunction.

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          

   <Exceptions>
      None

   <Side Effects>
      Will try to abort future functions if possible

   <Returns>
      True if the parallelizehandle was recognized or False if the handle is
      invalid or already closed.
  """

  # There is no sense trying to check then delete, since there may be a race 
  # with multiple calls to this function.
  try:
    del parallelize_info_dict[parallelizehandle]
  except KeyError:
    return False
  else:
    return True

    



def parallelize_abortfunction(parallelizehandle):
  """
   <Purpose>
      Cause pending events for a function to abort.   Events will finish 
      processing their current event.

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          

   <Exceptions>
      ParallelizeError is raised if the handle is unrecognized

   <Side Effects>
      None

   <Returns>
      True if the function was not previously aborting and is now, or False if 
      the function was already set to abort before the call.
  """

  
  try:
    if parallelize_info_dict[parallelizehandle]['abort'] == False:
      parallelize_info_dict[parallelizehandle]['abort'] = True
      return True
    else:
      return False
  except KeyError:
    raise ParallelizeError("Cannot abort the parallel execution of a non-existent handle:"+str(parallelizehandle))



def parallelize_isfunctionfinished(parallelizehandle):
  """
   <Purpose>
      Indicate if a function is finished

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          

   <Exceptions>
      ParallelizeError is raised if the handle is unrecognized

   <Side Effects>
      None

   <Returns>
      True if the function has finished, False if it is still has events running
  """

  
  try:
    if parallelize_info_dict[parallelizehandle]['runninglist']:
      return False
    else:
      return True
  except KeyError:
    raise ParallelizeError("Cannot get status for the parallel execution of a non-existent handle:"+str(parallelizehandle))





def parallelize_getresults(parallelizehandle):
  """
   <Purpose>
      Get information about a parallelized function

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          
   <Exceptions>
      ParallelizeError is raised if the handle is unrecognized

   <Side Effects>
      None

   <Returns>
      A dictionary with the results.   The format is
        {'exception':list of tuples with (target, exception string), 
         'aborted':list of targets, 'returned':list of tuples with (target, 
         return value)}
  """

  
  try:
    # I copy so that the user doesn't have to deal with the fact I may still
    # be modifying it
    return parallelize_info_dict[parallelizehandle]['result'].copy()
  except KeyError:
    raise ParallelizeError("Cannot get results for the parallel execution of a non-existent handle:"+str(parallelizehandle))



      



      


def parallelize_initfunction(targetlist, callerfunc,concurrentevents=5, *extrafuncargs):
  """
   <Purpose>
      Call a function with each argument in a list in parallel

   <Arguments>
      targetlist:
          The list of arguments the function should be called with.   Each
          argument is passed once to the function.   Items may appear in the
          list multiple times

      callerfunc:
          The function to call
 
      concurrentevents:
          The number of events to issue concurrently (default 5).   No more 
          than len(targetlist) events will be concurrently started.

      extrafuncargs:
          Extra arguments the function should be called with (every function
          is passed the same extra args).

   <Exceptions>
      ParallelizeError is raised if there isn't at least one free event.   
      However, if there aren't at least concurrentevents number of free events,
      this is not an error (instead this is reflected in parallelize_getstatus)
      in the status information.

   <Side Effects>
      Starts events, etc.

   <Returns>
      A handle used for status information, etc.
  """

  parallelizehandle = uniqueid_getid()

  # set up the dict locally one line at a time to avoid a ginormous line
  handleinfo = {}
  handleinfo['abort'] = False
  handleinfo['callfunc'] = callerfunc
  handleinfo['callargs'] = extrafuncargs
  # make a copy of target list because 
  handleinfo['targetlist'] = targetlist[:]
  handleinfo['availabletargetpositions'] = range(len(handleinfo['targetlist']))
  handleinfo['result'] = {'exception':[],'returned':[],'aborted':[]}
  handleinfo['runninglist'] = []

  
  parallelize_info_dict[parallelizehandle] = handleinfo

  # don't start more threads than there are targets (duh!)
  threads_to_start = min(concurrentevents, len(handleinfo['targetlist']))

  for workercount in range(threads_to_start):
    # we need to append the workercount here because we can't return until 
    # this is scheduled without having race conditions
    parallelize_info_dict[parallelizehandle]['runninglist'].append(workercount)
    try:
      settimer(0.0, parallelize_execute_function, (parallelizehandle,workercount))
    except:
      # If I'm out of resources, stop
      # remove this worker (they didn't start)
      parallelize_info_dict[parallelizehandle]['runninglist'].remove(workercount)
      if not parallelize_info_dict[parallelizehandle]['runninglist']:
        parallelize_closefunction(parallelizehandle)
        raise Exception, "No events available!"
      break
  
  return parallelizehandle
    


def parallelize_execute_function(handle, myid):
  # This is internal only.   It's used to execute the user function...

  # No matter what, an exception in me should not propagate up!   Otherwise,
  # we might result in the program's termination!
  try:

    while True:
      # separate this from below functionality to minimize scope of try block
      thetargetlist = parallelize_info_dict[handle]['targetlist']
      try:
        mytarget = thetargetlist.pop()
      except IndexError:
        # all items are gone, let's return
        return

      # if they want us to abort, put this in the aborted list
      if parallelize_info_dict[handle]['abort']:
        parallelize_info_dict[handle]['result']['aborted'].append(mytarget)

      else:
        # otherwise process this normally

        # limit the scope of the below try block...
        callfunc = parallelize_info_dict[handle]['callfunc']
        callargs = parallelize_info_dict[handle]['callargs']

        try:
          retvalue = callfunc(mytarget,*callargs)
        except Exception, e:
          # always log on error.   We need to report what happened
          parallelize_info_dict[handle]['result']['exception'].append((mytarget,str(e)))
        else:
          # success, add it to the dict...
          parallelize_info_dict[handle]['result']['returned'].append((mytarget,retvalue))


  except KeyError:
    # A KeyError is normal if they've closed the handle
    return

  except Exception, e:
    print 'Internal Error: Exception in parallelize_execute_function',e

  finally:
    # remove my entry from the list of running worker threads...
    try:
      parallelize_info_dict[handle]['runninglist'].remove(myid)
    except (ValueError, KeyError):
      pass
    

    


#end include parallelize.repy


openDHTadvertise_context = {}
openDHTadvertise_context["proxylist"] = []
openDHTadvertise_context["currentproxy"] = None
openDHTadvertise_context["serverlist"] = []
openDHTadvertise_context["serverlistlock"] = getlock()

def openDHTadvertise_announce(key, value, ttlval, concurrentevents=5, proxiestocheck=5, timeout=None):
  """
  <Purpose>
    Announce a (key, value) pair to openDHT.

  <Arguments>
    key:
            The new key the value should be stored under.

    value:
            The value to associate with the given key.

    ttlval:
            The length of time (in seconds) to persist this key <-> value
            association in DHT.

    concurrentevents:
            The number of concurrent events to use when checking for
            functional openDHT proxies. Defaults to 5.

    proxiestocheck:
            The number of openDHT proxies to check. Defaults to 5.

  <Exceptions>
    Exception if the xmlrpc server behaves erratically.

  <Side Effects>
    The key <-> value association gets stored in openDHT for a while.

  <Returns>
    None.
  """

  # JAC: Copy value because it seems that Python may otherwise garbage collect
  # it in some circumstances.   This seems to fix the problem
  value = str(value)[:]

  # convert ttl to an int
  ttl = int(ttlval)

  # If no timeout was specified, choose 10 seconds (completely arbitrary).
  if timeout is None:
    timeout = 10.0

#  print "Announce key:",key,"value:",value, "ttl:",ttl
  while True:
    # if we have an empty proxy list and no proxy, get more
    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] == []:
      openDHTadvertise_context["proxylist"] = openDHTadvertise_get_proxy_list( \
          concurrentevents=concurrentevents, maxnumberofattempts=proxiestocheck)
      # we couldn't get any proxies
      if openDHTadvertise_context["proxylist"] == []:
        return False


    # if there isn't a proxy we should use, get one from our list
    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] != []:
      openDHTadvertise_context["currentproxy"] = openDHTadvertise_context["proxylist"][0]
      del openDHTadvertise_context["proxylist"][0]


    # This code block is adopted from put.py from OpenDHT
    pxy = xmlrpc_client_Client(openDHTadvertise_context["currentproxy"])
    keytosend = xmlrpc_common_Binary(sha_new(str(key)).digest())
    valtosend = xmlrpc_common_Binary(value)

    try:
      pxy.send_request("put", (keytosend, valtosend, ttl, "put.py"), timeout=timeout)
      # if there isn't an exception, we succeeded
      break
    except (xmlrpc_common_ConnectionError, xmlrpc_common_Timeout):
      # Let's avoid this proxy.   It seems broken
      openDHTadvertise_context["currentproxy"] = None

  return True




def openDHTadvertise_lookup(key, maxvals=100, concurrentevents=5, proxiestocheck=5, timeout=None):
  """
  <Purpose>
    Retrieve a stored value from openDHT.

  <Arguments>
    key:
            The key the value is stored under.

    maxvals:
            The maximum number of values stored under this key to
            return to the caller.

    concurrentevents:
            The number of concurrent events to use when checking for
            functional openDHT proxies. Defaults to 5.

    proxiestocheck:
            The number of openDHT proxies to check. Defaults to 5.

  <Exceptions>
    Exception if the xmlrpc server behaves erratically.

  <Side Effects>
    None.

  <Returns>
    The value stored in openDHT at key.
  """

  # if no timeout is specified, pick 10 seconds (arbitrary value).
  if timeout is None:
    timeout = 10.0

  while True:
    # if we have an empty proxy list and no proxy, get more
    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] == []:
      openDHTadvertise_context["proxylist"] = openDHTadvertise_get_proxy_list( \
          concurrentevents=concurrentevents, maxnumberofattempts=proxiestocheck)
      # we couldn't get any proxies
      if openDHTadvertise_context["proxylist"] == []:
        raise Exception, "Lookup failed"


    # if there isn't a proxy we should use, get one from our list
    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] != []:
      openDHTadvertise_context["currentproxy"] = openDHTadvertise_context["proxylist"][0]
      del openDHTadvertise_context["proxylist"][0]


    # This code block is adopted from get.py from OpenDHT
    pxy = xmlrpc_client_Client(openDHTadvertise_context["currentproxy"])
    maxvalhash = int(maxvals)
    # I don't know what pm is for but I assume it's some sort of generator / 
    # running counter
    pm = xmlrpc_common_Binary("")
    keyhash = xmlrpc_common_Binary(sha_new(str(key)).digest())


    listofitems = []
    # If the proxy fails, then we will go to the next one...
    while openDHTadvertise_context["currentproxy"]:
      try:
        vals, pm = pxy.send_request("get", (keyhash, maxvalhash, pm, "get.py"), timeout=timeout)
        # if there isn't an exception, we succeeded

        # append the .data part of the items, the other bits are:
        # the ttl and hash / hash algorithm.
        for item in vals:
          listofitems.append(item.data)

        # reached the last item.  We're done!
        if pm.data == "":
          return listofitems

      except (xmlrpc_common_ConnectionError, xmlrpc_common_Timeout):
        # Let's avoid this proxy.   It seems broken
        openDHTadvertise_context["currentproxy"] = None




# check to see if a server is up and ready for OpenDHT...
def openDHTadvertise_checkserver(servername):
  # try three times.   Why three?   Arbitrary value
  for junkcount in range(3):
    s = openconn(servername, 5851, timeout=2.0)
    s.close()

  # this list is the "return value".   Add ourselves if no problems...
  openDHTadvertise_context["serverlistlock"].acquire()
  try:
    openDHTadvertise_context["serverlist"].append(servername)
  finally:
    openDHTadvertise_context["serverlistlock"].release()




# Loosely based on find-gateway.py from the OpenDHT project...
def openDHTadvertise_get_proxy_list(maxnumberofattempts=5, concurrentevents=5):
  """
  <Purpose>
    Gets a list of active openDHT proxies.

  <Arguments>
    maxnumberofattemps:
            Maximum number of servers to attempt to connect to.

    concurrentevents:
            Maximum number of events to use.

  <Exceptions>
    Exception if there are no servers in the server list.

  <Side Effects>
    Tries to connect to several proxies to see if they are online.

  <Returns>
    A list of openDHT approxies that appear to be up.
  """

  # populate server list
  socket = openconn('www.cs.washington.edu', 80)
  try: 
    socket.send("GET /homes/arvind/servers.txt HTTP/1.0\r\nHost: www.cs.washington.edu\r\n\r\n")
  
    body = ""
    while True:
      try:
        newdata = socket.recv(4096)
      except:
        # Server decided it is done.
        break
      if len(newdata) == 0:
        break   # Server finished sending us the response.
      body += newdata
  finally:
    socket.close()

  try:
    socket.close()
  except:
    pass

  headers, payload = body.split("\r\n\r\n", 1)
  lines = payload.split("\n")
  # throw away the header line
  lines = lines[1:]
  # get the server list
  servers = []
  for line in lines:
    if line.strip() == "":
      continue
    # The lines look like:
    # 4:	134.121.64.7:5850	planetlab2.eecs.wsu.edu
    # The third field is the server name
    servers.append(line.split()[2])

  if len(servers) == 0:
    raise Exception, "No servers in server list"

  numberofattempts = min(len(servers), maxnumberofattempts)
  serverstocheck = random_sample(servers, numberofattempts)

  # empty the server list
  openDHTadvertise_context["serverlist"] = []

  # start checking...
  parhandle = parallelize_initfunction(serverstocheck, openDHTadvertise_checkserver, concurrentevents=concurrentevents)

  # wait until all are finished
  while not parallelize_isfunctionfinished(parhandle):
    sleep(0.2)

  parallelize_closefunction(parhandle)


  retlist = []
  for serverip in openDHTadvertise_context["serverlist"]:
    # make it look like the right sort of url...
    retlist.append("http://"+serverip+":5851/")


  return retlist

#end include openDHTadvertise.repy
#begin include centralizedadvertise.repy
""" 
Author: Justin Cappos

Start Date: July 8, 2008

Description:
Advertisements to a central server (similar to openDHT)


"""

#begin include session.repy
# This module wraps communications in a signaling protocol.   The purpose is to
# overlay a connection-based protocol with explicit message signaling.   
#
# The protocol is to send the size of the message followed by \n and then the
# message itself.   The size of a message must be able to be stored in 
# sessionmaxdigits.   A size of -1 indicates that this side of the connection
# should be considered closed.
#
# Note that the client will block while sending a message, and the receiver 
# will block while recieving a message.   
#
# While it should be possible to reuse the connectionbased socket for other 
# tasks so long as it does not overlap with the time periods when messages are 
# being sent, this is inadvisable.

class SessionEOF(Exception):
  pass

sessionmaxdigits = 20

# get the next message off of the socket...
def session_recvmessage(socketobj):

  messagesizestring = ''
  # first, read the number of characters...
  for junkcount in range(sessionmaxdigits):
    currentbyte = socketobj.recv(1)

    if currentbyte == '\n':
      break
    
    # not a valid digit
    if currentbyte not in '0123456789' and messagesizestring != '' and currentbyte != '-':
      raise ValueError, "Bad message size"
     
    messagesizestring = messagesizestring + currentbyte

  else:
    # too large
    raise ValueError, "Bad message size"

  messagesize = int(messagesizestring)
  
  # nothing to read...
  if messagesize == 0:
    return ''

  # end of messages
  if messagesize == -1:
    raise SessionEOF, "Connection Closed"

  if messagesize < 0:
    raise ValueError, "Bad message size"

  data = ''
  while len(data) < messagesize:
    chunk =  socketobj.recv(messagesize-len(data))
    if chunk == '': 
      raise SessionEOF, "Connection Closed"
    data = data + chunk

  return data

# a private helper function
def session_sendhelper(socketobj,data):
  sentlength = 0
  # if I'm still missing some, continue to send (I could have used sendall
  # instead but this isn't supported in repy currently)
  while sentlength < len(data):
    thissent = socketobj.send(data[sentlength:])
    sentlength = sentlength + thissent



# send the message 
def session_sendmessage(socketobj,data):
  header = str(len(data)) + '\n'
  session_sendhelper(socketobj,header)

  session_sendhelper(socketobj,data)




#end include session.repy
# I'll use socket timeout to prevent hanging when it takes a long time...
#begin include sockettimeout.repy
#already included sockettimeout.repy
#end include sockettimeout.repy
servername = "satya.cs.washington.edu"
serverport = 10101

def centralizedadvertise_announce(key, value, ttlval):
  # Escape commas because they have a special meaning. Encoding scheme:
  # , -> \c
  # \ -> \\
  value = value.replace("\\", "\\\\")
  value = value.replace(",", "\\c")

  sockobj = timeout_openconn(servername,serverport, timeout=10)
  try:
    session_sendmessage(sockobj, "PUT|"+str(key)+"|"+str(value)+"|"+str(ttlval))
    response = session_recvmessage(sockobj)
    if response != 'OK':
      raise Exception, "Centralized announce failed '"+response+"'"
  finally:
    # BUG: This raises an error right now if the call times out ( #260 )
    # This isn't a big problem, but it is the "wrong" exception
    sockobj.close()
  
  return True
      



def centralizedadvertise_lookup(key, maxvals=100):
  sockobj = timeout_openconn(servername,serverport, timeout=10)
  try:
    session_sendmessage(sockobj, "GET|"+str(key)+"|"+str(maxvals))
    recvdata = session_recvmessage(sockobj)
    # worked
    if recvdata.endswith('OK'):
      # Decode the values (unescape commas).
      encoded_values = recvdata[:-len('OK')].split(',')
      values = []
      for encoded_value in encoded_values:
        value = encoded_value.replace("\\c", ",")
        value = value.replace("\\\\", "\\")
        values.append(value)

      return values
    raise Exception, "Centralized lookup failed"
  finally:
    # BUG: This raises an error right now if the call times out ( #260 )
    # This isn't a big problem, but it is the "wrong" exception
    sockobj.close()
      



#end include centralizedadvertise.repy
#begin include DORadvertise.repy
"""
Author: Conrad Meyer

Start Date: Wed Dec 9 2009

Description:
Advertisements to the Digital Object Registry run by CNRI.

"""




#begin include sockettimeout.repy
#already included sockettimeout.repy
#end include sockettimeout.repy
#begin include httpretrieve.repy
#already included httpretrieve.repy
#end include httpretrieve.repy
#begin include xmlparse.repy
#already included xmlparse.repy
#end include xmlparse.repy




DORadvertise_FORM_LOCATION = "http://geni.doregistry.org/SeattleGENI/HashTable"




class DORadvertise_XMLError(Exception):
  """
  Exception raised when the XML recieved from the Digital Object Registry
  server does not match the structure we expect.
  """
  pass




class DORadvertise_BadRequest(Exception):
  """
  Exception raised when the Digital Object Registry interface indigates we
  have made an invalid request.
  """


  def __init__(self, errno, errstring):
    self.errno = errno
    self.errstring = errstring
    Exception.__init__(self, "Bad DOR request (%s): '%s'" % (str(errno), errstring))




def DORadvertise_announce(key, value, ttlval, timeout=None):
  """
  <Purpose>
    Announce a (key, value) pair to the Digital Object Registry.

  <Arguments>
    key:
            The new key the value should be stored under.

    value:
            The value to associate with the given key.

    ttlval:
            The length of time (in seconds) to persist this key <-> value
            association in DHT.

    timeout:
            The number of seconds to spend on this operation before failing
            early.

  <Exceptions>
    xmlparse_XMLParseError if the xml returned isn't parseable by xmlparse.
    DORadvertise_XMLError if the xml response structure does not correspond
      to what we expect.
    DORadvertise_BadRequest if the response indicates an error.
    Any exception httpretrieve_get_string() throws (including timeout errors).

  <Side Effects>
    The key <-> value association gets stored in openDHT for a while.

  <Returns>
    None.
  """

  post_params = {'command': 'announce', 'key': key, 'value': value,
      'lifetime': str(int(ttlval))}

  _DORadvertise_command(post_params, timeout=timeout)

  return None





def DORadvertise_lookup(key, maxvals=100, timeout=None):
  """
  <Purpose>
    Retrieve a stored value from the Digital Object Registry.

  <Arguments>
    key:
            The key the value is stored under.

    maxvals:
            The maximum number of values stored under this key to
            return to the caller.

    timeout:
            The number of seconds to spend on this operation before failing
            early.   If not specified, the default is set to the default
            timeout value for the http library (30 seconds).

  <Exceptions>
    xmlparse_XMLParseError if the xml returned isn't parseable by xmlparse.
    DORadvertise_XMLError if the xml response structure does not correspond
      to what we expect.
    DORadvertise_BadRequest if the response indicates an error.
    Any exception httpretrieve_get_string() throws (including timeout errors).

  <Side Effects>
    None.

  <Returns>
    The value stored in the Digital Object Registry at key.
  """

  post_params = {'command': 'lookup', 'key': key, 'maxvals': str(maxvals)}

  return _DORadvertise_command(post_params, timeout=timeout)



def _DORadvertise_command(parameters, timeout=None):
  # Internal helper function; calls the remote command, and returns
  # the results we can glean from it.

  # If there is a timeout, use it!
  if timeout != None:
    post_result = httpretrieve_get_string(DORadvertise_FORM_LOCATION, \
        postdata=parameters, timeout=timeout, \
        httpheaders={"Content-Type": "application/x-www-form-urlencoded"})
  else:
    post_result = httpretrieve_get_string(DORadvertise_FORM_LOCATION, \
        postdata=parameters, \
        httpheaders={"Content-Type": "application/x-www-form-urlencoded"})


  # Parse the result to check for success. Throw several exceptions to
  # ensure the XML we're reading makes sense.
  xmltree = xmlparse_parse(post_result)

  if xmltree.tag_name != "HashTableService":
    raise DORadvertise_XMLError(
        "Root node error. Expected: 'HashTableService', " +
        "got: '%s'" % xmltree.tag_name)

  if xmltree.children is None:
    raise DORadvertise_XMLError("Root node contains no children nodes.")

  # We expect to get an error code, an error string, and possibly some
  # values from the server.
  error_msg = None
  error = None
  values = None

  numxmlchildren = len(xmltree.children)
  if numxmlchildren not in [2, 3]:
    raise DORadvertise_XMLError("Root XML node contains inappropriate " + \
        "number of child nodes.")

  for xmlchild in xmltree.children:
    # Read the numeric error code.
    if xmlchild.tag_name == "status" and xmlchild.content is not None:
      if error is not None:
        raise DORadvertise_XMLError("XML contains multiple status tags")
      error = int(xmlchild.content.strip())

    # String error message (description:status as strerror:errno).
    elif xmlchild.tag_name == "description":
      if error_msg is not None:
        raise DORadvertise_XMLError("XML contains multiple description tags")
      error_msg = xmlchild.content

    # We found a <values> tag. Let's try and get some values.
    elif xmlchild.tag_name == "values" and xmlchild.children is not None:
      if values is not None:
        raise DORadvertise_XMLError("XML contains multiple values tags")

      values = []
      for valuenode in xmlchild.children:
        if valuenode.tag_name != "value":
          raise DORadvertise_XMLError(
              "Child tag of <values>; expected: '<value>', got: '<%s>'" % \
                  valuenode.tag_name)

        content = valuenode.content
        if content is None:
          content = ""

        values.append(content)

    # Check for tags we do not expect.
    elif xmlchild.tag_name not in ("status", "description", "values"):
      raise DORadvertise_XMLError("Unexpected tag '" + \
          str(xmlchild.tag_name) + "' while parsing response.")

  if error is not 0:
    raise DORadvertise_BadRequest(error, error_msg)

  # This happens when the server returns <values></values>
  if values is None:
    return []

  return values

#end include DORadvertise.repy
#begin include parallelize.repy
#already included parallelize.repy
#end include parallelize.repy


# All the names of services we can support.
_advertise_all_services = ("central", "DHT", "DOR")


nodemanager_announce_context = {}
for service in _advertise_all_services:
  nodemanager_announce_context["skip" + service] = 0
  nodemanager_announce_context["previous" + service + "skip"] = 1
nodemanager_announce_context_lock = getlock()


# an exception to indicate an error occured while advertising
class AdvertiseError(Exception):
  pass




def _try_advertise_announce(args):
  # Helper function used by advertise_announce(). This is the worker process
  # run in parallel for DHT and central announces.
  which_service, key, value, ttlval, exceptions, finishedref = args

  if which_service not in _advertise_all_services:
    raise AdvertiseError("Incorrect service type used in internal function _try_advertise_announce.")

  try:
    if which_service == "central":
      centralizedadvertise_announce(key, value, ttlval)
    elif which_service == "DOR":
      DORadvertise_announce(key, value, ttlval)
    else:
      openDHTadvertise_announce(key, value, ttlval)

    finishedref[0] = True     # Signal that at least one service has finished.
    
    nodemanager_announce_context_lock.acquire()
    try:
      nodemanager_announce_context["previous" + which_service + "skip"] = 1
    finally:
      nodemanager_announce_context_lock.release()

  except Exception, e:
    nodemanager_announce_context_lock.acquire()
    try:
      exceptions[0] += 'announce error (type: ' + which_service + '): ' + str(e)
      nodemanager_announce_context["skip" + which_service] = \
          nodemanager_announce_context["previous" + which_service + "skip"] + 1
      nodemanager_announce_context["previous" + which_service + "skip"] = \
          min(nodemanager_announce_context["previous" + which_service + "skip"] * 2, 16)
    finally:
      nodemanager_announce_context_lock.release()





def advertise_announce(key, value, ttlval, concurrentevents=2, \
    graceperiod=10, timeout=60):
  """
  <Purpose>
    Announce (PUT) a value at the given key in the central advertise service,
    openDHT, or both.

  <Arguments>
    key:
            The key to store the value at.

    value:
            The value to store.

    ttlval:
            Time in seconds to persist the associated key<->value pair.
    
    concurrentevents (optional, defaults to 2):
            How many services to announce on in parallel.

    graceperiod (optional, defaults to 10):
            After this many seconds (can be a float or int type), if we have
            successfully announced on at least one service, return.

    timeout (optional, defaults to 60):
            After this many seconds (can be a float or int type), give up.

  <Exceptions>
    AdvertiseError if something goes wrong.

  <Side Effects>
    Spawns as many worker events as concurrentevents specifies, limited by the
    number of services available (currently 2).

  <Returns>
    None.
  """

  # convert different types to strings to avoid type conversion errors #874
  key = str(key)
  value = str(value)

  # Wrapped in an array so we can modify the reference (python strings are immutable).
  exceptions = [''] # track exceptions that occur and raise them at the end

  parallize_worksets = []
  start_time = getruntime()

  onefinished = [False]

  for service_type in _advertise_all_services:
    if nodemanager_announce_context["skip" + service_type] == 0:
      parallize_worksets.append((service_type, key, value, ttlval, \
          exceptions, onefinished))

    else:
      nodemanager_announce_context_lock.acquire()
      try:
        nodemanager_announce_context["skip" + service_type] = \
            nodemanager_announce_context["skip" + service_type] - 1
      finally:
        nodemanager_announce_context_lock.release()

  ph = parallelize_initfunction(parallize_worksets, _try_advertise_announce, \
      concurrentevents=concurrentevents)

  while not parallelize_isfunctionfinished(ph):
    sleep(0.1)
    if getruntime() - start_time > timeout or \
        (getruntime() - start_time > graceperiod and onefinished[0]):
      parallelize_abortfunction(ph)
      break

  # Note: closefunction() doesn't actually abort future functions like
  # it says it will.
  parallelize_closefunction(ph)

  if exceptions[0] != '':
    raise AdvertiseError(str(exceptions))

  return None




def _try_advertise_lookup(args):
  # Helper function used by advertise_lookup(). This is the worker process
  # run in parallel for DHT and central lookups.
  which_service, key, maxvals, finishedref = args

  if which_service not in _advertise_all_services:
    raise AdvertiseError("Incorrect service type used in internal function _try_advertise_lookup.")

  try:
    if which_service == "central":
      results = centralizedadvertise_lookup(key, maxvals)
    elif which_service == "DOR":
      results = DORadvertise_lookup(key, maxvals=maxvals)
    else:
      results = openDHTadvertise_lookup(key, maxvals)

    finishedref[0] = True
    return results
  
  except Exception, e:
    return []




def advertise_lookup(key, maxvals=100, lookuptype=None, \
    concurrentevents=2, graceperiod=10, timeout=60):
  """
  <Purpose>
    Lookup (GET) (a) value(s) stored at the given key in the central advertise
    server, openDHT, or both.

  <Arguments>
    key:
            The key used to lookup values.

    maxvals (optional, defaults to 100):
            Maximum number of values to return.

    lookuptype (optional, defaults to ['central', 'opendht', 'DOR']):
            Which services to employ looking up values.
    
    concurrentevents (optional, defaults to 2):
            How many services to lookup on in parallel.

    graceperiod (optional, defaults to 10):
            After this many seconds (can be a float or int type), return the
            results if one service was reached successfully.

    timeout (optional, defaults to 60):
            After this many seconds (can be a float or int type), give up.

  <Exceptions>
    AdvertiseError if something goes wrong.

  <Side Effects>
    Spawns as many worker events as concurrentevents specifies, limited by the
    number of services in lookuptype.

  <Returns>
    All unique values stored at the key.
  """

  # convert different types to strings to avoid type conversion errors #874
  key = str(key)

  if lookuptype is None:
    lookuptype = ['central','opendht','DOR']

  parallel_worksets = []
  start_time = getruntime()

  onefinished = [False]

  for type in lookuptype:
    if type == "central":
      parallel_worksets.append(("central", key, maxvals, onefinished))
    elif type == "DOR":
      parallel_worksets.append(("DOR", key, maxvals, onefinished))
    elif type == "opendht":
      parallel_worksets.append(("DHT", key, maxvals, onefinished))
    else:
      raise AdvertiseError("Incorrect service type '" + type + "' passed to advertise_lookup().")

  ph = parallelize_initfunction(parallel_worksets, _try_advertise_lookup, \
      concurrentevents=concurrentevents)

  while not parallelize_isfunctionfinished(ph):
    sleep(0.1)
    if getruntime() - start_time > timeout or \
        (getruntime() - start_time > graceperiod and onefinished[0]):
      parallelize_abortfunction(ph)
      break

  parallel_results = parallelize_getresults(ph)['returned']
  results = []

  for parallel_result in parallel_results:
    _, return_value = parallel_result
    results += return_value

  parallelize_closefunction(ph)

  return listops_uniq(results)

#end include advertise.repy

"""
Temporary naming service to emulate the behaviors of a real DNS server.

"""


class DummyDNSException(Exception):
  pass

def _DummyDNSInitialize():
  if not mycontext.has_key('dummy_dns_lock'):
    mycontext['dummy_dns_lock'] = getlock()
    mycontext['dummy_dns_lock'].acquire()
    mycontext['dummy_dns_cache'] = {}
    mycontext['dummy_dns_log_lock'] = getlock()
    mycontext['dummy_dns_active'] = True
    mycontext['dummy_dns_lock'].release()
    settimer(0, _DummyDNSAdvertiseThread, [])


def _DummyDNSAdvertiseThread():
  if mycontext.has_key('dummy_dns_advertise_thread_started'):
    return
  else:
    mycontext['dummy_dns_advertise_thread_started'] = True
  
  prevCacheStr = ''

  while True:
    mycontext['dummy_dns_lock'].acquire()
    cache = mycontext['dummy_dns_cache'].copy()
    mycontext['dummy_dns_lock'].release()

    if not mycontext['dummy_dns_active']:
      break
    
    for name in cache.keys():
      try:
        advertise_announce(str(name), str(cache[name]), 100)
      except Exception, e:
        # Excuse the flaky adv service
        pass
      
    if str(cache) == prevCacheStr:
      _DummyDNSLog('')
    else:
      _DummyDNSLog('advertised local cache = %s' % cache)
      prevCacheStr = str(cache)

    for i in range(50):
      sleep(1)

      if not mycontext['dummy_dns_active']:
        break

      try:
        if mycontext['wakeup'] == True:
          mycontext['wakeup'] = False
          break
      except KeyError, e:
        mycontext['wakeup'] = False

  # end while



def _DummyDNSLog(logstr):
  _DummyDNSInitialize()
  mycontext['dummy_dns_log_lock'].acquire()
  try:
    logfile = open("DummyDNS.log", "a")
    logfile.write("%s\n" % logstr)
  except Exception, e:
    print "DummyDNS: Unable to log: '%s'" % e
  finally:
    logfile.close()
    mycontext['dummy_dns_log_lock'].release()


def is_ip_address(ipstr):
  ip_segment_list = ipstr.split('.')
  if len(ip_segment_list) != 4:
    return False

  for ip_segment_str in ip_segment_list:
    try:
      ip_segment_int = int(ip_segment_str)
    except ValueError, e:
      return False
    if not (0 <= ip_segment_int < 256):
      return False

  return True

  

def DummyDNSStop():
  mycontext['dummy_dns_active'] = False



def DummyDNSLookup(name, create=False):
  """
  Looks up a name and returns the IP address. If 'create' is True, then my
  current IP will be added to the host record if the corresponding name cannot
  be resolved.

  """
  useRealDNS = True

  # No need to resolve if it is already an IP address
  if is_ip_address(name):
    return name

  # Try using real DNS first if the name looks like a real host name
  if len(name.split('.')) > 1 and useRealDNS:
    try:
      return gethostbyname_ex(name)[2][0]
    except Exception, e:
      _DummyDNSLog("Error: Failed to resolve '%s' using real DNS because '%s'."
                   % (name, e))
      useRealDNS = False

  _DummyDNSInitialize()
  mycontext['dummy_dns_lock'].acquire()
  
  # find in cache
  cache = mycontext['dummy_dns_cache']
  try:
    retip = cache[name]
    _DummyDNSLog("Lookup: %s -> %s (cached)" % (name, retip))
    mycontext['dummy_dns_lock'].release()
    return retip
  except KeyError, e:
    pass

  # find in DHT
  lookup_results = advertise_lookup(name)
  if (not lookup_results) or (lookup_results and lookup_results[0] == ''):
    # not found in DHT
    if create:
      # create a record (esp used in waitforconn)
      myip = getmyip()
      lookup_results = [myip]
    else:
      # use the real DNS 
      _DummyDNSLog("Error: Unable to resolve '%s' with DummyDNS. Now try real DNS." % name)
      try:
        if useRealDNS:
          lookup_results = [gethostbyname_ex(name)[2][0]]
        else:
          raise Exception('Not using real DNS')
      except Exception, e:
        mycontext['dummy_dns_lock'].release()
        raise DummyDNSException("DummyDNS: Unable to resolve '%s' because '%s'." 
                                % (name, e))

  # add to cache
  retip = lookup_results[0]
  cache[name] = retip
  mycontext['wakeup'] = create
  mycontext['dummy_dns_lock'].release()

  _DummyDNSLog("Lookup: %s -> %s" % (name, retip))
  return retip

#end include DummyDNS.repy
#begin include ShimLogger.repy

SHIM_LOGGER_FILE = 'shims.log'

class ShimLogger:

  def __init__(self, shimname=''):
    self._shimname = shimname
    self._initialize_logger()


  def _initialize_logger(self):
    if not mycontext.has_key('shim_logger_lock'):
      mycontext['shim_logger_lock'] = getlock()
      self.log("\n" * 3)


  def log(self, logstr):
    mycontext['shim_logger_lock'].acquire()
    try:
      logfile = open(SHIM_LOGGER_FILE, 'a')
      logfile.write(str(self._shimname) + ': ' + logstr + '\n')
      logfile.close()
    except Exception, e:
      # Silently drops all exceptions
      pass
    finally:
      mycontext['shim_logger_lock'].release()

#end include ShimLogger.repy


# Include all shims in the world

#begin include BaseShim.repy


# Base class for all shims that simply calls the next shim in the stack.
class BaseShim:


  # Private static variables that subclass should not override or modify.
  mycontext['ShimInstanceCountDict'] = {}
  mycontext['ShimInstanceCountLock'] = getlock()

  # TODO Legacy. For debugging and backward compatibility only.
  name = 'BaseShim'
  do_not_advertise = False





  # ===========================================================================
  # Public methods that directly interface with the application. 
  #
  # Do not modify any of these methods.
  # ===========================================================================

  def openconn(self, host, port, localhost=None, localport=None, timeout=5):
    socket = self._shim_openconn(host, port, localhost, localport, timeout)
    newsocket = ShimSocketWrapper(socket, self)
    return newsocket



  # Helper method for waitforconn
  def _waitforconn_shim_callback_wrapper(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    selfcopy = self.copy()
    (rip, rport, sock, th, lh) = selfcopy._shim_listener_callback(remoteip, remoteport, socket, thiscommhandle, listencommhandle)
    newsocket = ShimSocketWrapper(sock, selfcopy)

    self._waitforconn_shim_callback(rip, rport, newsocket, th, lh)
 


  def waitforconn(self, host, port, callback):
    self._waitforconn_shim_callback = callback
    return self._shim_waitforconn(host, port, self._waitforconn_shim_callback_wrapper)



  def recvmess(self, host, port, callback):
    return self._shim_recvmess(host, port, callback)


  def sendmess(self, host, port, msg, localhost=None, localport=None):
    return self._shim_sendmess(host, port, msg, localhost, localport)


  def stopcomm(self, handle):
    return self._shim_stopcomm(handle)


  def socket_close(self, socket):
    return self._shim_socket_close(socket)


  def socket_send(self, socket, msg):
    return self._shim_socket_send(socket, msg)



  def socket_recv(self, socket, bytes): 
    return self._shim_socket_recv(socket, bytes)
  



  # ===========================================================================
  # Protected methods that the shim creator may want to override.
  #
  # Note that there are no protected attributes in Python. All attributes are
  # either public or private. The protected methods below (except the
  # constructor) are still public to the application that uses the shim.
  # ===========================================================================

  # Always call the BaseShim's constructor somewhere in the constructor of your
  # subclass
  def __init__(self, next_shim=None, optional_args=None):

    self.shim_stack = ShimStack(next_shim)
    self._optional_args = optional_args

    # If "NO_NOT_ADVERTISE" is a part of the shim's optional arguments, then we
    # won't include this shim when advertising the shim stack.
    if optional_args:
      self.do_not_advertise = "DO_NOT_ADVERTISE" in optional_args

    # Count instance
    mycontext['ShimInstanceCountLock'].acquire()
    instdict = mycontext['ShimInstanceCountDict']
    if instdict.has_key(self.name):
      self._instance_id = instdict[self.name]
      instdict[self.name] += 1
    else:
      self._instance_id = 0
      instdict[self.name] = 1
    mycontext['ShimInstanceCountLock'].release()

 
  def _shim_listener_callback(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    return (remoteip, remoteport, socket, thiscommhandle, listencommhandle)



  def _shim_waitforconn(self, host, port, callback):
    return self.shim_stack.waitforconn(host, port, callback)

  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):
    return self.shim_stack.openconn(host, port, localhost, localport, timeout)

  def _shim_recvmess(self, host, port, callback):
    return self.shim_stack.recvmess(host, port, callback)


  def _shim_sendmess(self, host, port, msg, localhost=None, localport=None):
    return self.shim_stack.sendmess(host, port, msg, localhost, localport)


  def _shim_stopcomm(self, handle):
    return self.shim_stack.stopcomm(handle)



  def _shim_socket_close(self, socket):
    return self.shim_stack.socket_close(socket)



  def _shim_socket_send(self, socket, msg):
    return self.shim_stack.socket_send(socket, msg)



  def _shim_socket_recv(self, socket, bytes): 
    return self.shim_stack.socket_recv(socket, bytes)
  

  # ===========================================================================
  # Public methods that the shim creator must override.
  #
  # Note that there are no protected attributes in Python. All attributes are
  # either public or private. The protected methods below (except the
  # constructor) are still public to the application that uses the shim.
  # ===========================================================================

  # Returns a copy of the current instance. Be sure to set internal states to be
  # copied in the new object. An example would be:
  # 
  # class MyShim(BaseShim):
  #   def copy(self):
  #     mycopy = MyShim()
  #     mycopy._internalstate = self._internalstate
  #     return mycopy
  def copy(self):
    raise Exception("Subclass of BaseShim must implement the copy() method.")


  # Returns the string used for advertisement of this shim and the shim stack
  # below. An example would be:
  #
  # class MyShim(BaseShim):
  #   def get_advertisement_string(self):
  #     return '(MyShim,' + self._some_shared_str + ')' + \
  #             self.shim_stack.get_advertisement_string()
  #
  # If the subclass shim is not meant to be public, then simply return an empyt
  # string concatenated with the advertisemnt string of the rest of the stack.
  def get_advertisement_string(self):
    raise Exception("Subclass of BaseShim must implement the get_advertisement_string() method.")








  # ===========================================================================
  # Methods that should not be overridden by the derived classes
  # ===========================================================================

  def getid(self):
    return self._instance_id


  # TODO Legacy. Used for debugging and backward compatibility..
  # Return only names that are compatible (i.e. required for balancing two
  # shim stacks)
  def get_shims(self, get_all_shims=False, debug=False):

    myname = str(self)

    if debug:
      myname += '[%d]' % self.getid()

    if self.do_not_advertise and (not get_all_shims):
      myname = ''

    # recursive calls to subsequent shims
    if self.shim_stack.top_shim is None:
      return myname
    else:
      return myname + self.shim_stack.top_shim.get_shims(get_all_shims, debug)


  # TODO Legacy. Used for debugging and backward compatibility..
  # Preserved for backward compatibility
  def get_names(self):
    
    if self.shim_stack.top_shim is None:
      name_list = ['']
    else:
      name_list = self.shim_stack.get_names()
    
    new_name_list = []
    for name in name_list:
      name = '('+self.name+')'+name
      new_name_list.append(name)
    return new_name_list


  def __str__(self):
    # convert the arguments to this shim as a list of strings
    args = []
    if self._optional_args:
      for arg in self._optional_args:
        args.append(str(arg))

    myname = '(' + self.name
 
    # append the shim arguments, if any
    if args:
      myname += ","
      myname += ",".join(args)

    myname += ")"

    return "%s[%d]" % (myname, self.getid())


  def __repr__(self):
    return self.__repr__()



# Provides backward compatibility
class EmptyShim(BaseShim):
  pass


#end include BaseShim.repy
#begin include CoordinationShim.repy
#include local_lookup_methods.repy
#begin include advertise.repy
#already included advertise.repy
#end include advertise.repy


# TODO For TCP-based connections only. Coordinating for UDP won't be that hard
# once this is done.
class CoordinationShim(BaseShim):

  name = 'CoordinationShim'

  # We will do a lookup on the DHT for at most the following number of times.
  _lookup_attempts = 4

  # Number of seconds to re-advertise the shim stack to refresh DHT
  _advertise_wait_interval = 60

  # Override
  def copy(self):
    return CoordinationShim()

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('CoordinationShim')


  def get_advertisement_string(self):
    return '(CoordinationShim)' + self.shim_stack.get_advertisement_string()


  # ===========================================================================
  # SERVER METHODS
  # ===========================================================================

  def _shim_listener_callback(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    self._logger.log('listener_callback: new client from %s:%s' % (remoteip, remoteport))
    return (remoteip, remoteport, socket, thiscommhandle, listencommhandle)



  def _shim_waitforconn(self, hostkey, port, callback):

    # Traverse through the stack and build the general stack, which is shared
    # for all incoming connections.
    handle = self.shim_stack.waitforconn(hostkey, port, callback)

    # Now that the stack has been built, we can advertise its content.
    advertise_key = str(hostkey) + "," + str(port) + ",TCP"
    advertise_value = self.shim_stack.get_advertisement_string()

    # We advertise the contents of the shim stack at its first creation.
    # Subsequent changes are on a per-connection basis (using negotiation) and
    # are irrelevant for coordination.
    self._listener_active = True
    settimer(0, self._advertise_thread, [advertise_key, advertise_value])
    self._logger.log('waitforconn: Listening. About to advertise <"%s","%s">' % (advertise_key, advertise_value))

    return handle


  
  def _advertise_thread(self, advertise_key, advertise_value):
    while self._listener_active:
      try:
        # We're prepending an '@' sign to the shim stack string because of a
        # flaw in the advertisement service, which returns a list of an empty
        # string upon unsuccessful lookup. We want to distinguish that case with
        # an empyt stack string.
        advertise_announce(str(advertise_key), "@" + str(advertise_value), 120)
      except Exception, e:
        # Silently drops all errors because the advertisement service can be
        # flaky at times
        pass

      sleep(self._advertise_wait_interval)






  # ===========================================================================
  # NON-SERVER METHODS
  # ===========================================================================


  # Uses a lookup service to coordinate the construction of the client shim
  # stack. Returns a list of available shim stack string representations. If
  # use_cache is set to True, then we are only doing a lookup on a local
  # cache. Otherwise, we will do a lookup remotely. Helper for the openconn
  # operation.
  def _get_shimstack_strings(self, hostkey, port, use_cache=True):
    # Initializes the local cache so we don't have to contact the remote
    # services all the time.
    if mycontext.has_key('shim_stack_string_cache_lock'):
      mycontext['shim_stack_string_cache_lock'].acquire()
    else:
      mycontext['shim_stack_string_cache_lock'] = getlock() 
      mycontext['shim_stack_string_cache_lock'].acquire()
      mycontext['shim_stack_string_cache'] = {}

    lookup_results = []
    lookup_key = str(hostkey)+','+str(port)+',TCP'
    local_lookup_cache = mycontext['shim_stack_string_cache']

    # Search the cache if use_cache is True. If cache returns empty, use the
    # remote lookup service.
    if use_cache and local_lookup_cache.has_key(lookup_key):
      lookup_results = local_lookup_cache[lookup_key][:]
      if lookup_results:
        mycontext['shim_stack_string_cache_lock'].release()
        return lookup_results

    # Contact the remote lookup service
    for count in range(self._lookup_attempts):
      lookup_results = advertise_lookup(lookup_key)
      if len(lookup_results) > 0 and lookup_results[0]:
        break
      sleep(1)

    # Add to local cache.
    if local_lookup_cache.has_key(lookup_key):
      local_lookup_cache[lookup_key] += lookup_results[:]
    else:
      local_lookup_cache[lookup_key] = lookup_results[:]

    # Remove duplicates or else we would be trying the same non-working shim
    # stacks multiple times.
    self._remove_duplicates(local_lookup_cache[lookup_key])

    # Return a copy so that others won't be able to mess with our internal
    # cache.
    lookup_results = local_lookup_cache[lookup_key][:]

    mycontext['shim_stack_string_cache_lock'].release()

    return lookup_results


  def _shim_openconn(self, hostkey, port, localhost=None, localport=None, timeout=5):

    exception_str = ''
    sock = None

    # Indicates whether we have tried using the remote lookup services
    # (e.g. DHT) to locate the shim stack strings of the server.
    tried_using_remote_lookup = False

    # First, obtain the shim stack string from cache, or if not, from the DHT.
    shimstackstr_list = self._get_shimstack_strings(hostkey, port, use_cache=True)

    # Try to do openconn for every possible shim stack string
    while len(shimstackstr_list) > 0:

      try:
        # Remove the preceding @ sign in the shim stack string
        shimstackstr = shimstackstr_list.pop()[1:]
        shim_stack = ShimStack(shimstackstr)
      except Exception, e:
        errmsg = "Unable to parse shim stack string '%s' because '%s'." % (shimstackstr, e)
        self._logger.log("openconn: " + errmsg)
        raise Exception(errmsg)

      try:
        sock = shim_stack.openconn(hostkey,port,localhost,localport,timeout)
      except Exception,e:
        exception_str +=' || Exception: '+str(e)+' for stack '+shimstackstr
      else:
        # Success in openconn. We won't try the rest of the shimstack strings.
        break

      if len(shimstackstr_list) == 0 and not tried_using_remote_lookup:
        # All possible shim stack strings are consumed and we still haven't
        # found a workable one. We want to lookup the shim stack strings using
        # the remote services, instead of the local cache.
        shimstackstr_list = self._get_shimstack_strings(hostkey, port, use_cache=False)
        tried_using_remote_lookup = True

      if len(shimstackstr_list) == 0 and tried_using_remote_lookup:      
        # All possible shim stack strings are consumed. We haven't found a
        # workable one after lookups on both the local cache and the remote
        # services. We raise our arms and shall surrender.
        break

    # end while

    # If all things fail, we will connect without the shim interface. This
    # provides backward compatibility for older servers.
    if sock is None:
      self._logger.log("openconn: Trying to connect to %s:%s without using the shim interface." % (hostkey, port))
      try:
        sock = openconn(DummyDNSLookup(hostkey),port,localhost,localport,timeout)
      except Exception,e:
        exception_str +=' || Unable to connect without using shims becase %s.' % e

    # At this point, we've exhausted all our means.
    if sock is None:
      exception_str = 'CoordinationShim error: ' + exception_str
      self._logger.log("CoordinationShim: " + exception_str)
      raise Exception(exception_str)
    else:
      self.shim_stack = shim_stack
      return sock





  def _shim_stopcomm(self, handle):
    self._listener_active = False
    return self.shim_stack.stopcomm(handle)


  # Remove the duplicates in the input list. The input list is modified. Helper
  # method for self._get_shimstack_strings.
  def _remove_duplicates(self, inlist):
    listindex = 0

    while listindex < len(inlist):
      # If the current item appears in the rest of the list, remove it.
      currentitem = inlist[listindex]
      if currentitem in inlist[listindex+1:]:
        del inlist[listindex]
      else:
        listindex += 1


#end include CoordinationShim.repy
#begin include NatForwardingShim.repy

"""
<Program Name>
  NatForwardingShim.repy

<Started>
  Jan 5, 2010

<Author>
  Eric Kimbrel

<Purpose>
  Provide a NAT (network address translator) forwarding service within the 
  service compostion framework

  When a server does a nat_waitforconn he connects to a nat_forwarder and
  registers.  When a client connects the to the nat_forwarder the nat_forwarder
  uses the control sock to have the server open a new connection.  Traffic
  is then exchanged  via the nat_forwarder


  when completed this library should..

    optionally takes a socket connection to a forwarder on shim construction
    creates a socket connection to a forwarder ( if one is not provided)
    manages re-connection of connection to the forwarder is lost
    advertises the forwarder connection
    listens for connection requests over a control socket
    makes new connections to the forwarder for client communications
    Provides meaningful exceptions when connections are rejected

"""



#begin include session.repy
#already included session.repy
#end include session.repy
#begin include NAT_CONSTANTS.repy
"""
NatForwardingShim.repy and Nat_Forwarder.repy must communicate over the network
through a series of requests and responses.

These requests and response are encoded in constants contained
within this file


"""

# connection types
NAT_SERVER = 'S'
NAT_LEGACY_CLIENT = 'C'
NAT_CLIENT = 'c'
NAT_CHECK_CONN = '?'

# requests
NAT_CONNECTION_ALIVE = 'ALIVE?'
NAT_NEW_CONN = 'CONN'
NAT_INIT = 'INIT'


# responses
NAT_YES = 'YES'   # use for an postive confirmation
NAT_NO = 'NO'     # use for negitive confirmation

NAT_SERVER_NOT_FOUND = 'SERVERNOTFOUND'
NAT_FORWARDER_BUSY = 'BUSY'
NAT_SERVER_ERROR = 'SERVERERROR'


#common advertise keys

NAT_FORWARDER = 'seattle_NAT_FORWARDING_SERVICE_NODE'


#end include NAT_CONSTANTS.repy
#begin include AdvertiseObjects.repy
"""

<Author>
  Eric Kimbrel kimbrl@cs.washington.edu

<Start Date>
  Jan 29 2010

<Purpose>
  Provied 2 objects to make more efficent use of resouces when using advertising
  or looking up values.

  LookupCache: 

  Provide cacheing of lookups to reduce the time spent doing
  lookups by programs that need to lookup the same value frequently.
  The cache is global so any instance of the object will have the same
  values stored in the cache.

  usage:  Call lookup_obj.lookup(key) to perform a lookup of key using
          advertise_lookup with default arguments.  Values will be returned
          from the cache if they are available and not too old.

  AdvertisePipe:

  Stores a list of (key,value) tuples and uses a single thread to advertise
  each tuple in the list.  This prevents a program from using multiple threads
  to repeatedly advertise values.

  usage:  Call ad_obj.add(key,value) to add (key,value) to the list of tuples
          to be advertised.  This call returns an ad_handle which can be used
          with a call to ad_obj.remove(ad_handle) to remove (key,value) from 
          the list.

"""



#begin include advertise.repy
#already included advertise.repy
#end include advertise.repy




class LookupCache():
  # caches lookups in a global data structure


  cache = {} # a dict that will map lookups to results
  lock = getlock()

  def __init__(self,refresh_time=120):
    # refresh_time is the amount of time the we will return results
    # from the cache without doing a new lookup
    self.refresh_time = refresh_time

  
  def lookup(self,key, maxvals=100, lookuptype=['central','opendht','DOR'], \
                            concurrentevents=2, graceperiod=10, timeout=60):    
    """
    <Purpose>
      lookup the values stored at the given key

    <Arguments>
      see advertise.repy
      WARNING optional arguments are passed on to advertise.repy if a new
      advertisement is performed.  If cache values are returned nothing is 
      done with the extra arguments.

    <Returns>
      a list of unique values advertised at the key

    <Excpetions>
      see advertise_lookup from advertise.repy
    """ 
    
    if key not in self.cache:
      # do the initial look up 
      results = advertise_lookup(key, maxvals, lookuptype,concurrentevents,
                              graceperiod, timeout)
      
      if len(results) > 0 and results[0] != '':
        # don't cache results of a failed lookup
        self.cache[key] = {'results':results,'time':getruntime()}

      return results

    else:
      # if the key is in the cache see how old it is
      time_expired = getruntime() - self.cache[key]['time']
      if time_expired > self.refresh_time or time_expired < 0:
        # refresh the cache value if its old or the time doesnt make since
        results = advertise_lookup(key, maxvals, lookuptype,concurrentevents,
                                            graceperiod, timeout)
        if len(results) > 0 and results[0] != '':
          # don't cache failed results
          self.cache[key]['results'] = results
          self.cache[key]['time'] = getruntime()

        return results      


      else:
        # return the cache results without a lookup
        return self.cache[key]['results']






class AdvertisePipe():
  # shares a thread of execution across instances to 
  # advertise key value pairs
  
  advertise_dict = {} # store info to be advertised
  state= {'run':False} # should the add thread be running
  state_lock = getlock()
  ttlv = 240
  redo = 120


  def _advertise_thread(self):
    # add a short sleep so that key,value pairs added 
    # close to the same time will be advertised together
    #without waiting for the next cycle
    sleep(2)   

    # advertise values stored in the advertise_dict
    while self.state['run']:
      
      # get the start time of the advertisement pass
      start = getruntime()

      # advertise each key,value pair that was in the dict
      # at the beggining of this pass
      entry_keys = self.advertise_dict.keys()
      for entry_key in entry_keys:
        try:
          (key,value) = self.advertise_dict[entry_key]
          advertise_announce(key,value,self.ttlv)
        except:
          pass #the key must have been deleted
    
          
  
      # now wait until redo time has expired
      # if run has gone to false we want to stop sleeping and kill the thread
      while getruntime() - start < self.redo and self.state['run']:
        sleep(10)
          


  def add(self,key,value):
    """
    <Purpose>
      add the key,value pair to the advertise pipe

    <Arguments>
      the key value pair to advertise

    <Returns>
      a handle that can be used to remove the key,value pair

    <Excpetions>
      Possible exception from settimer if the advertise thread 
      can not be started
    """ 
    
    # create a unique handle
    handle = object() 
    self.advertise_dict[handle]=(key,value)
    
    # if the advertise thread is not running start it
    self.state_lock.acquire()
    if not self.state['run']:
      self.state['run'] = True
      settimer(0,self._advertise_thread,[])
    self.state_lock.release()    
    
    # return the handle
    return handle
    

  def remove(self,handle):
   """
    <Purpose>
      removes the key,value pair corresponding to the handle from
      the advertise pipe

    <Arguments>
      a handle returned from AdvertisePipe.add

    <Returns>
      None

    <Excpetions>
      Exception on invalid handle
    """ 
   self.state_lock.acquire()  
   if handle not in self.advertise_dict:
     self.state_lock.release()
     raise Exception('Invalid advertise handle')
   else: 
     del self.advertise_dict[handle]
     if len(self.advertise_dict) == 0:
       self.state['run'] = False
     self.state_lock.release()
    
  

#end include AdvertiseObjects.repy
#begin include NatForwardingLib.repy
"""

<Program Name>
  NatForwardingLib.repy

<Author>
  Eric Kimbrel

<Purpose>


  Provide several functions used by vairos shims to accomplish
  Nat Forwarding

  1. Check connectivty to determine if a host needs to use
     nat forwarding.

  2. Lookup nat forwarders that are currently advertising and
     return a ranked list of them



"""

#begin include NAT_CONSTANTS.repy
#already included NAT_CONSTANTS.repy
#end include NAT_CONSTANTS.repy
#begin include session.repy
#already included session.repy
#end include session.repy
#begin include sockettimeout.repy
#already included sockettimeout.repy
#end include sockettimeout.repy
#begin include AdvertiseObjects.repy
#already included AdvertiseObjects.repy
#end include AdvertiseObjects.repy


class NatConnError(Exception):
  # base class for problem with nat connections
  pass

class NatLookupError(NatConnError):
  # unable to lookup a needed value
  pass





def natforwardinglib_isBidirectional(ip,port):
  # returns True if some kind of forwarding should be used
  # returns False if this host can recieve incomming connections
  #               OR there is an error and we can't decide for sure
  
  host_str = ip+':'+str(port)

  lookup_obj = LookupCache()

  try:
    ip_port_list = natforwardinglib_forwarder_lookup()
  except:
    return False

  for (forwarder_ip,forwarder_port) in ip_port_list:
    try:
      return  _natforwardinglib_do_check(host_str,forwarder_ip,forwarder_port)
    except Exception, e:
      pass

  return False





def _natforwardinglib_do_check(host_str,forwarder_ip,forwarder_port):
  # returns True if some kind of forwarding should be used
  # returns False if this host can recieve incomming connections
  # raises an Exception if an error occurs
  

  #sock = timeout_openconn(forwarder_ip,forwarder_port,timeout=30)
  shim = ShimStackInterface()
  sock = shim.openconn(forwarder_ip, forwarder_port, timeout=30)
  
  # tells the forwrader we want to check behind nat
  sock.send(NAT_CHECK_CONN) 
     
  #send my ip, this should be what the other end sees
  session_sendmessage(sock,host_str)

  msg = session_recvmessage(sock)

  if msg == NAT_YES:
    sock.close()
    return True


  elif msg == NAT_CHECK_CONN:
   
    (ip,port) = host_str.split(':')
    port = int(port)
    try:
      handle = shim.waitforconn(ip,port,_natforwardinglib_listen)
    except Exception, e:
      raise Exception

    # tell the forwarder we are ready for a connection
    session_sendmessage(sock,NAT_YES)

    # check the connection
    msg = session_recvmessage(sock)

    sock.close()
    stopcomm(handle)

    # if NAT_YES return True - to use the forwarder
    # otherwise false
    return (msg == NAT_YES)

  # if we got something weird from the server return false
  else:
    sock.close()
    return False
  




def _natforwardinglib_listen(remote_ip,remote_port,
                                      sock,this_handle,listen_handle):
  # internal call back method for outside forwarder to connect to
  sock.close()





def natforwardinglib_forwarder_lookup():
  # retrns a list of forwarders in the form [(ip,port),...]
  # ordered by the server load on the forwareders
  # 
  # raises exception if no valid forwarder entries are found

  lookup_obj = LookupCache()

  raw_data = lookup_obj.lookup(NAT_FORWARDER)
  if len(raw_data) == 0 or raw_data[0] == '':
    raise NatLookupError("No Nat Forwarders were found")


  # hash the forwarders based on the load they have    
  tuple_list_dict = {}
  for item in raw_data:
    try:
      (ip,port,load) = item.split(':')
      port = int(port)
    except:
      pass  # throw out invalid entries, todo log this?
    else:
      if load not in tuple_list_dict:
        tuple_list_dict[load] = []
      tuple_list_dict[load].append((ip,port))

  if len(tuple_list_dict) < 1:
    raise NatLookupError("No Valid entries were found for nat forwarders")

  # drop all of the tuples into a list ordered by increasing 
  # forwarder load
  ranked_tuple_list = []
  key_list =  tuple_list_dict.keys()
  key_list.sort()
  for key in key_list:
    for tuple in tuple_list_dict[key]:
      ranked_tuple_list.append(tuple)
    
  return ranked_tuple_list

#end include NatForwardingLib.repy




# custom obj used as a comm handle and to keep state 
# for diffent calls to waitforconn
class NatStateObj:
  def __init__(self,host,port,callback):
    self.sock = None
    self.running = True
    self.callback = callback
    self.host = host
    self.port = port
    self.adhandle = None



class NatForwardingShim(BaseShim):
  
  
  advertise_obj = AdvertisePipe()
  lookup_obj = LookupCache()

  name = 'NatForwardingShim'


  ######    CONSTRUCTOR

  def __init__(self,next_shim=None,optional_args=None):
    
    # call the base constructor
    BaseShim.__init__(self,next_shim,optional_args)    

    # Default shim stack used in communication between the internals of this
    # shim and the forwarder. This stack is on the client side of the
    # communication, as we always call openconn on this stack. Thus, we maintain
    # individual instances of the stacks.
    self._forwarder_shim_stack = ShimStackInterface()

    self.state_objs = {}

    # hop_key and hop_port can be used to avoid doing a lookup with
    # openconn, primarily used for testing
    self.hop_key = None
    self.hop_port = None

    # optional args should not be supplied, or should be a hop key and port
    # note: these are done as optional args to conform with ShimStack standards
    if optional_args is not None:
      if len(optional_args) == 2:
       self.hop_key = optional_args[0]
       self.hop_port = int(optional_args[1])
      else:
        raise Exception("Improper optional args passed into NatForwardingShim")
    
    
  # Override
  def copy(self):
    return NatForwardingShim(optional_args=self._optional_args)


  def get_advertisement_string(self):
    args = "," + str(self.hop_key) + "," + str(self.hop_port)
    return '(NatForwardingShim' + args + ')' + self.shim_stack.get_advertisement_string()

  #######  SERVER METHODS  



  def _shim_waitforconn(self,key,port,callback):
    """
    <Purpose>
      Provide a means to register with a nat_forwarder and wait for connections

    <Arguments>
      key: They srv key to register with a nat forwarder, its up to the user
      of this library to come up with a unique value to use as key, and to 
      communicate this key to potential clients.

      port: The port to be used

      localip,localport: see openconn
  
      callback: see waitforconn

    <Exceptions>
      Sock exceptions may occur in event of connection failure, etc
    
    <Side Effects>
      1 thread is consumed to wait for connections over the control socket
      1 thread is consumed to advertise this connection

      every call to waitforconn will use 2 threads, until stopcomm is called

    """
    if port in self.state_objs:
      # if this port alreayd has an active listener just replace the callback
      state_obj = self.state_objs[port]
      state_obj.callback = callback
      return state_obj


    # create a new state object for this listener
    state_obj = NatStateObj(key,port,callback)

    # establish a control socket with a forwarder
    self.establish_control_sock(state_obj) 
    self.state_objs[port] = state_obj

    # start a thread to listen for new requests
    settimer(0,self.nat_waitfor_request,[state_obj])

    # return a handle
    return state_obj




  def establish_control_sock(self,state_obj):
    # connect to a forwarder and establish a control socket
    # this control socket is used to listen for connection requests

    if self.hop_key is not None and self.hop_port is not None:
      control_sock = self._forwarder_shim_stack.openconn(self.hop_key,int(self.hop_port))  
      for_ip = self.hop_key
      for_port = int(self.hop_port)
    
    else:
      # use the lookup mechanism to find a forwarder
      
      forwarder_list = natforwardinglib_forwarder_lookup()
      connected = False      
      
      ex_str =''
      for (for_ip,for_port) in forwarder_list:
        try:
          control_sock = self._forwarder_shim_stack.openconn(for_ip,for_port)

        except Exception,e:
          ex_str = ex_str+' '+str(e)
        else:
          connected = True
          break
      
      if not connected:
        raise NatConnError("Could not establish control socket with any of "
                     +str(len(forwarder_list))+" forwarders: "+ex_str)   


      # remember the forwarder info for advertisement later
      self.hop_key = for_ip
      self.hop_port = int(for_port)

    #register the with the forwarder
    control_sock.send(NAT_SERVER) 
    session_sendmessage(control_sock,NAT_INIT)
    session_sendmessage(control_sock,str(state_obj.host)) 
    session_sendmessage(control_sock,str(state_obj.port))

  
    # see if the connection was established
    response = session_recvmessage(control_sock)
    if response != NAT_YES:
      raise Exception, 'NAT node refused connection'

    # create an add key and add value for new clients
    ad_key = state_obj.host+'$'+str(state_obj.port)+'$TCP'
    ad_value = self.name+'$'+for_ip+'$'+str(for_port)
    ad_handle = self.advertise_obj.add(ad_key,ad_value)
    
    # create an add key and add value for legacy clients
    legacy_key = "__NAT_SRV__"+state_obj.host
    legacy_value = for_ip+"*"+str(for_port)
    legacy_ad_handle = self.advertise_obj.add(legacy_key,legacy_value)
    
    
    state_obj.adhandle = (ad_handle,legacy_ad_handle)
    state_obj.sock = control_sock




  def establish_comms_sock(self,control_sock):
    # upon recieve a connection request make a new connection
    # to the forwarder to facilliate the communication
    # raises an exception if failure occurs

    # read the connection request over the control socket
    remote_key = session_recvmessage(control_sock)
    remote_port = session_recvmessage(control_sock)
    forwarder_ip = session_recvmessage(control_sock)
    forwarder_port = session_recvmessage(control_sock)

    

    # create the new connection
    new_sock = self._forwarder_shim_stack.openconn(forwarder_ip,int(forwarder_port))
    new_sock.send(NAT_SERVER)
    session_sendmessage(new_sock,NAT_NEW_CONN)
    session_sendmessage(new_sock,remote_key)
    session_sendmessage(new_sock,remote_port) 
    
    # verify the connection is established
    response = session_recvmessage(new_sock)
    if response != NAT_YES:
      new_sock.close() # this connection failed
    else:
      # confirm the connection over the control sock 
      session_sendmessage(control_sock,NAT_YES)
      
      # wait for the forwarder to verify that the socket is ready
      # to pass up to the users fuction
      response = session_recvmessage(control_sock)
      
      # return the connection along with the identity of the clt
      if response == NAT_YES: return (remote_key,remote_port,new_sock)
      else: raise Exception("Establish comms failed")
     


  def _shim_stopcomm(self,handle):  
    """
    acts just like a stopcomm

    """

    if not isinstance(handle,NatStateObj):
      raise Exception("Bad handle passed to NatFOrwardingSHim.stopcomm ")
    (adhandle,legacyadhandle) = handle.adhandle
    self.advertise_obj.remove(adhandle)
    self.advertise_obj.remove(legacyadhandle) 
    handle.running = False
    handle.sock.close()
    
    # remove this port fromt the list of active state objects
    del self.state_objs[handle.port]
    
    return True




  
  def nat_waitfor_request(self,state_obj):
    # wait for requsts for new connections over a control socket

    while state_obj.running:
      # do this until stopcomm is called 
      try:
        request = NAT_CONNECTION_ALIVE
       
        # respond to forwarder checks to see if this connection is still
        # active, if we've lost the control sock we will detect it here
        # and can reconnection
        while request == NAT_CONNECTION_ALIVE:
          try:
            request = session_recvmessage(state_obj.sock)
            if request != NAT_CONNECTION_ALIVE: break
            session_sendmessage(state_obj.sock,NAT_YES)  
          except:
            # error over the control socket, establish a new one
            if state_obj.running:
              state_obj.sock.close()
              
              (adhandle,legacyadhandle) = state_obj.adhandle
              self.advertise_obj.remove(adhandle)
              self.advertise_obj.remove(legacyadhandle) 
              
              self.establish_control_sock(state_obj)

            else:
              raise # if stop has been called don't re-establish

        # take a request to make a new connection 
        if request != NAT_NEW_CONN:
          raise Exception("in establish comms sock with request: "+request)  
       
        # try to establish the new connection
        try:
          (remote_key,remote_port,comms_sock) = self.establish_comms_sock(state_obj.sock)
        except:
          pass #todo log this? there was a failure setting up a new connection
        else:
          # new connection complete, send socket to callback func
         
          # WARNING, i just return the socket as the listen handle, TODO,
          # make sure this works
          settimer(0,state_obj.callback,[remote_key,remote_port,comms_sock,comms_sock,state_obj])    
     
      except Exception, e:
        if state_obj.running:
          #stopcomm has not been called and the connection failed
          raise Exception('ERROR OCCURED IN nat_watifor_request '+str(e))      
     
       



  ############ CLIENT METHODS


  def _shim_openconn(self,id,port,localip=None,localport=None,timeout=5):
    """
    <Purpose>
      creates a "virtual" connection to the desired host but connecting
      to a forwarder that will exchange traffic between the host and a
      socklikeobj returned by this function

    <Retruns>
      a socket like object

    <Exceptions>
      see openconn
      Exception if Forwarder rejects connection   

    <Warning> TODO: Does not correctly adhere to timeout semantics

    """  

    if self.hop_key is not None and self.hop_port is not None:
      # If a hop key and port have been specified, use them.
      base_sock = self._forwarder_shim_stack.openconn(self.hop_key,self.hop_port,localip,localport,timeout+5)
      self.establish_client_server_conn(base_sock,id,port)
      return base_sock

    else:

      #find the host with a lookup
      host_list = self.lookup_host(id,port)

      exception_str = ''
      for (forip,forport) in host_list:
        try:
          base_sock = self._forwarder_shim_stack.openconn(forip,forport,localip,
                                                          localport,timeout+9)
          self.establish_client_server_conn(base_sock,id,port)
        except Exception,e:
          exception_str = exception_str+',  '+str(e)
        else:
           return base_sock

      raise NatConnError("Failed to get connection: "+exception_str)
      



  def establish_client_server_conn(self,base_sock,id,port):
    #used by opennconn to establish connection

    # specify this is a client connection, and what server we want
    try:
      base_sock.send(NAT_CLIENT)
      session_sendmessage(base_sock,str(id)) 
      session_sendmessage(base_sock,str(port))
    except Exception,e:
      raise NatConnError("Error initializing socket connection: "+str(e))    

    # see if the connection was established
    response =  session_recvmessage(base_sock)
    if response != NAT_YES:
      base_sock.close()
      if response == NAT_SERVER_NOT_FOUND:
        raise NatConnError('The Host requested was not found at the forwarder')
      elif response == NAT_FORWARDER_BUSY:
        raise NatConnError('The Host requested has reach its client capacity')
      elif response == NAT_SERVER_ERROR:
        raise NatConnError('The Host requested suffered an unexpected error during connection')
      else:
        raise NatConnError("Unknown nat failure: "+response)

    #if the connection is established we can return the socket
    return base_sock



  ####   ADVERTISE / LOOKUP METHODS


      


  def lookup_host(self,host,port):
    # returns a list of tuples (forwarderip,forwarderport)
    raw_list = self.lookup_obj.lookup(host+'$'+str(port)+'$TCP')
    if raw_list is None or len(raw_list) == 0:
      raise NatLookupError('No lookup results for: '+host+':'+str(port))

 

    tuple_list = []
    for item in raw_list:
      try:
        (name,ip,port) = item.split('$')
        if name == self.name:
          tuple_list.append((ip,int(port)))
      except:
        pass

    if len(tuple_list) == 0:
      raise NatLookupError('No valid lookup results for: '+host+':'+str(port))
    else:
      return tuple_list




#end include NatForwardingShim.repy
#begin include NatDeciderShim.repy
"""

<Program Name>
  NatDeciderShim.repy

<Author>
 Danny Yuxing Huang (yh1@williams.edu)

<Purpose> 

  Decider shim for the Nat Forwarding Shim. When run in a server, it determines
  if the server is behind a NAT. If it is, then the decider pushes the
  NatForwardingShim onto the shim stack. This shim is not advertised.

"""

#begin include NatForwardingLib.repy
#already included NatForwardingLib.repy
#end include NatForwardingLib.repy

class NatDeciderShim(BaseShim):
  
  # TODO Retained for debug
  name = 'NatDeciderShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('NatDeciderShim')


  def copy(self):
    return NatDeciderShim()


  # This shim is not advertised.
  def get_advertisement_string(self):
    return self.shim_stack.get_advertisement_string()




  def waitforconn(self, host, port, callback):
    self._logger.log("waitforconn: Check if we're behind NAT")
    # If server is behind the NAT, then behind_nat = True.
    behind_nat = natforwardinglib_isBidirectional(getmyip(), port)

    if behind_nat:
      self.shim_stack.push(NatForwardingShim())
      self._logger.log("waitforconn: We are behind NAT.")

    return self.shim_stack.waitforconn(host, port, callback)
  


#end include NatDeciderShim.repy
#begin include SimpleEncryptionShim.repy

class SimpleEncryptionShim(BaseShim):

  name = 'SimpleEncryptionShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._ascii_shift = 1
    if optional_args:
      self._ascii_shift = int(optional_args[0])

  # override
  def copy(self):
    newshim = SimpleEncryptionShim(optional_args=[self._ascii_shift])
    return newshim

  # override
  def get_advertisement_string(self):
    return '(SimpleEncryptionShim,' + str(self._ascii_shift) + ')' + \
        self.shim_stack.get_advertisement_string()

  # Increases the ascii value of every character of the input string by
  # _ascii_shift.
  def _encrypt(self, string):
    cypher = ""
    for char in string:
      cypher += chr((ord(char) + self._ascii_shift) % 256)
    #print "ENCRYPT - %s - from '%s' to '%s'" % (self.name, string, cypher)
    return cypher

  # Does the reverse of _encrypt(), i.e. decreases the ascii values by
  # _ascii_shift.
  def _decrypt(self, cypher):
    string = ""
    for char in cypher:
      string += chr((ord(char) - self._ascii_shift) % 256)
    #print "DECRYPT - %s - from '%s' to '%s'" % (self.name, cypher, string)
    return string






  def _shim_socket_send(self, socket, msg):
    #print "'%s'._shim_socket_send: rawstr = %s" % (self.name, msg)
    return self.shim_stack.socket_send(socket, self._encrypt(msg))


  def _shim_socket_recv(self, socket, bytes): 
    rawstr = self.shim_stack.socket_recv(socket, bytes)
    #print "'%s'._shim_socket_recv: rawstr = %s" % (self.name, rawstr)
    return self._decrypt(rawstr)
  
  



#end include SimpleEncryptionShim.repy
#begin include LogShim.repy

class LogShim(EmptyShim):

  name = 'LogShim'

  def __init__(self, next_shim=None, optional_args=None):
    EmptyShim.__init__(self, next_shim, optional_args)

    self._lock = getlock()
    self._logfile = 'temp_log_%s.txt' % str(randomfloat())[2:]
    self._sockdict = {}
    self._addlog('__init__')


  def copy(self):
    return LogShim()


  def get_advertisement_string(self):
    # We don't want to advertise this shim
    return self.shim_stack.get_advertisement_string()


  # Private method that adds a valid entry to the loglist
  def _addlog(self, operation, sourceip=None, sourceport=None, destip=None, destport=None, socket=None):

    logentry = ' * '
    logentry += '%s at %s ' % (operation, getruntime())
    logentry += 'from %s:%s to %s:%s ' % (sourceip, sourceport, destip, destport)
    logentry += 'stack: %s ' % (self.shim_stack)
    if sock:
      logentry += 'socket: %s' % socket
    logentry += '\n\n'

    # append to logfile
    self._lock.acquire()
    fileobj = open(self._logfile, 'a')
    fileobj.write(logentry)
    fileobj.close()
    self._lock.release()



  # Wrapper for the callback function in waitforconn()
  def _log_waitforconn_callback(self, remoteip, remoteport, sock, th, lh):
    self._addlog('waitforconn_callback', 
                 sourceip=self._waitforconn_sourceip,
                 sourceport=self._waitforconn_sourceport,
                 destip=remoteip, destport=remoteport,
                 socket=sock)

    self._lock.acquire()
    self._sockdict[sock] = [self._waitforconn_sourceip,
                            self._waitforconn_sourceport,
                            remoteip, remoteport]
    self._lock.release()

    self._waitforconn_callback(remoteip, remoteport, sock, th, lh)



  def _shim_waitforconn(self,host,port,callback):
    self._waitforconn_callback = callback
    self._addlog('waitforconn', sourceip=host, sourceport=port)

    self._waitforconn_sourceip = host
    self._waitforconn_sourceport = port

    return self.shim_stack.waitforconn(host,port,self._log_waitforconn_callback)



  def _shim_openconn(self,host,port,localhost=None,localport=None,timeout=5):
    self._addlog('openconn', sourceip=localhost, sourceport=localport, destip=host, destport=port)
    return self.shim_stack.openconn(host,port,localhost,localport,timeout)



  # Wrapper for the callback function in recvmess()
  def _log_recvmess_callback(self, remoteip, remoteport, msg, handle):
    self._addlog('recvmess_callback', 
                 sourceip = self._recvmess_sourceip,
                 sourceport = self._recvmess_sourceport,
                 destip=remoteip, destport=remoteport)

    self._recvmess_callback(remoteip, remoteport, msg, handle)



  def _shim_recvmess(self,host,port,callback):
    self._recvmess_callback = callback
    # This is not logged, because this method is usually placed within a loop.
    #self._addlog('recvmess', sourceip=host, sourceport=port)

    self._recvmess_sourceip = host
    self._recvmess_sourceport = port

    return self.shim_stack.recvmess(host, port, self._log_recvmess_callback)



  def _shim_sendmess(self,host,port,msg,localhost=None,localport=None):
    self._addlog('sendmess', sourceip=localhost, sourceport=localport, destip=host, destport=port)
    return self.shim_stack.sendmess(host,port,msg,localhost,localport)



  def _shim_stopcomm(self,handle):
    self._addlog('stopcomm')
    return self.shim_stack.stopcomm(handle)


  def _shim_socket_send(self, socket, msg):
    self._addlog('socket_send')
    return self.shim_stack.socket_send(socket, msg)

  def _shim_socket_recv(self, socket, bytes):
    self._addlog('socket_recv')
    return self.shim_stack.socket_recv(socket, bytes)

  def _shim_socket_close(self, socket):
    self._addlog('socket_close')
    return self.shim_stack.socket_close(socket)


#end include LogShim.repy
#begin include RSAShim.repy
#begin include session.repy
#already included session.repy
#end include session.repy

class RSAShim(BaseShim):

  name = 'RSAShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('RSAShim')
    self._sharedKey = None

    # The following is true in new instances of this shim, when new incoming
    # connections are accepted and a new stack is cloned in the server.
    if optional_args:
      self._sharedKey = optional_args[0]


  def copy(self):
    #newshim = RSAShim(optional_args=[self._sharedKey])
    newshim = RSAShim()
    return newshim


  def get_advertisement_string(self):
    return '(RSAShim)' + self.shim_stack.get_advertisement_string()



  # Server accept()
  def _shim_listener_callback(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    self._logger.log("listener callback: instance id = [%d]" % self.getid())
    (pubKey, privKey) = self._get_RSA_keys()

    # send public key
    try:
      session_sendmessage(socket, "pubKey@@@" + pubKey)
    except Exception, err:
      self._logger.log("listener callback: Unable to send public key because " + str(err))
      raise Exception(err)

    self._logger.log("listener callback: sent public key " + pubKey)

    # Receive shared random key, encrypted with public key
    try:
      handshakestr = self._RSA_decrypt(privKey, session_recvmessage(socket))
    except Exception, err:
      self._logger.log("listener callback: Unable to receive shared key because " + str(err))
      raise Exception(err)

    try:
      (greeting, sharedKey) = handshakestr.split("***")
    except:
      raise Exception("Corrupt handshake: %s" % handshakestr)

    if greeting == "sharedKey":
      pass
    else:
      raise Exception("Wrong greeting: %s" % greeting)

    self._sharedKey = sharedKey
    self._logger.log("listener callback: received shared key " + str(sharedKey))

    # TODO for debug only. This displays the shared key in the string
    # representation of the shim when used in client.
    self._optional_args = [self._sharedKey]

    return (remoteip, remoteport, socket, thiscommhandle, listencommhandle)


  def _zzcallback_wrapper(self, rip, rport, sock, th, lh):
    self._zzcallback(rip, rport, sock, th, lh)


  def _shim_waitforconn(self, host, port, callback):
    self._zzcallback = callback
    return self.shim_stack.waitforconn(host, port, self._zzcallback_wrapper)


  # Client connect()
  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):
    sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
    self._logger.log('openconn: connection established with %s:%s' % (host, port))

    try:
      handshakestr = session_recvmessage(sock)
    except Exception, err:
      self._logger.log("openconn: Unable to receive public key because " + str(err))
      raise Exception(err)

    try:
      (greeting, pubKey) = handshakestr.split("@@@")
    except:
      raise Exception("Corrupt handshake: %s" % handshakstr)

    if greeting == "pubKey":
      self._pubKey = pubKey
    else:
      raise Exception("Wrong greeting: %s" % greeting)

    self._logger.log('openconn: received public key ' + str(pubKey))

    # Send shared random key to server, encrypted with public key
    self._sharedKey = str(int(randomfloat()*999999) % 256)

    try:
      session_sendmessage(sock, 
                          self._RSA_encrypt(pubKey, "sharedKey***" + self._sharedKey))
    except Exception, err:
      self._logger.log("openconn: Unable to send shared key because " + str(err))
      raise Exception(err)

    self._logger.log('openconn: sent shared key ' + str(self._sharedKey))

    # TODO for debug only. This displays the shared key in the string
    # representation of the shim when used in client.
    self._optional_args = [self._sharedKey]

    return sock



  def _shim_socket_send(self, socket, msg):
    return self.shim_stack.socket_send(socket, 
                                       self._RN_encrypt(self._sharedKey, msg))


  def _shim_socket_recv(self, socket, bytes): 
    return self._RN_decrypt(self._sharedKey, 
                            self.shim_stack.socket_recv(socket, bytes))
  







  # ===========================================================================
  # Fake encryption methods for better performance during debug
  #

  def _get_RSA_keys(self):
    randi = int(randomfloat()*999999)
    return (str(randi), str(1+randi))

  # Fake key matcher for performance in testing
  def _match_keys(self, pubKey, privKey):
    return int(pubKey)+1 == int(privKey)

  # Encrypt with pub key
  def _RSA_encrypt(self, pubKey, msg):
    return pubKey + "@#$#@" + msg

  # Decrypt with priv key
  def _RSA_decrypt(self, privKey, cypher):
    try:
      (pubKey, msg) = cypher.split("@#$#@")
    except:
      raise Exception("Corrupt cypher text: %s" % cypher)

    if not self._match_keys(pubKey, privKey):
      raise Exception("Wrong keys in _RSA_decrypt. cyper: %s. privKey: %s." % (cypher, privKey))

    return msg

  # Encrypt with shared random key RN
  def _RN_encrypt(self, RN, msg):
    cypher = ''
    for char in msg:
      cypher += chr((ord(char) + int(RN)) % 256)
    return cypher

  # Decrypt with shared random key RN
  def _RN_decrypt(self, RN, cypher):
    msg = ''
    for char in cypher:
      msg += chr((ord(char) - int(RN)) % 256)
    return msg

  #
  # ===========================================================================

#end include RSAShim.repy
#begin include NatBranchingShim.repy


# A wrapper for listener handles with their corresponding shim stacks.
class NatBranchingShimHandle:
  def __init__(self, handle_stack_map):
    # A dict that maps handle to shim stack. We use the object's built-in hash
    # function, which calculates the hash value based on its memory address.
    self.handle_stack_map = handle_stack_map

  def get_map(self):
    return self.handle_stack_map

  def get_stack(self, handle):
    try:
      return self.handle_stack_map[handle]
    except KeyError:
      raise Exception('NatBranchShimHandle.getstack: invalid handle "%s"' % handle)



class NatBranchingShim(BaseShim):

  name = 'NatBranchingShim'

  def __init__(self, next_shim=None, optional_args=None):
    self._listen_handle = None
    self._logger = ShimLogger('NatBranchingShim')
    BaseShim.__init__(self, next_shim, optional_args)




  def copy(self):
    mycopy = NatBranchingShim()
    mycopy._listen_handle = self._listen_handle
    return mycopy


  def get_advertisement_string(self):
    return '(NatBranchingShim)' + self.shim_stack.get_advertisement_string()

  
  # Server listener callback
  def _shim_listener_callback(self, rip, rport, sock, th, lh):
    # busy-waiting until handle is ready
    while not self._listen_handle:
      sleep(0.5)

    return (rip, rport, sock, th, self._listen_handle)


  # Create two separate shim stacks. Return a wrapper of both handles when both
  # shim stacks return.
  def _shim_waitforconn(self, host, port, callback):

    # Build both shims
    noopstack = self.shim_stack.copy()
    natstack = self.shim_stack.copy()
    natstack.push(NatForwardingShim())

    # Create callback wrapper so that the callback function receives our
    # customized listen handle
    self._branch_waitforconn_cb = callback

    # create handle
    self._logger.log('waitforconn: Constructing noop shim stack.')
    noophandle = noopstack.waitforconn(host, port, callback)
    self._logger.log('waitforconn: Constructing NAT shim stack.')
    nathandle = natstack.waitforconn(host, port, callback)
    handle_stack_map = {noophandle: noopstack, nathandle: natstack}
    self._listen_handle = NatBranchingShimHandle(handle_stack_map)

    return self._listen_handle



  # Stop both listeners.
  def _shim_stopcomm(self, listen_handle):
    # check handle
    if not isinstance(listen_handle, NatBranchingShimHandle):
      # TODO Should return false here
      raise Exception('Incorrect listen_handle type.') 

    result = True
    for handle in listen_handle.get_map().keys():
      stack = listen_handle.get_map()[handle]
      ret = stack.stopcomm(handle)
      result = result and ret

    return result
    
 
    

  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):
    # Let us try direct connection first
    try:
 
      # debug only
      # if not mycontext.has_key('branch_client_count'):
      #   mycontext['branch_client_count'] = 0
      # mycontext['branch_client_count'] += 1
      # if mycontext['branch_client_count'] % 2 == 0 and True:
      #   raise Exception('Testing: Try using Nat.')

      self._logger.log("openconn: Trying direct connection.")
      sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
      self._logger.log("openconn: Direct connection works.")
      return sock

    except Exception, e:
      self._logger.log("openconn: Direct connection failed because '%s'." % e)
      self._logger.log("openconn: Trying Nat.")
      self.shim_stack.push(NatForwardingShim())
      sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
      self._logger.log("openconn: NAT works.")
      return sock

#end include NatBranchingShim.repy
#begin include RSABranchingShim.repy


# A wrapper for listener handles with their corresponding shim stacks.
class RSABranchingShimHandle:
  def __init__(self, handle_stack_map):
    # A dict that maps handle to shim stack. We use the object's built-in hash
    # function, which calculates the hash value based on its memory address.
    self.handle_stack_map = handle_stack_map

  def get_map(self):
    return self.handle_stack_map

  def get_stack(self, handle):
    try:
      return self.handle_stack_map[handle]
    except KeyError:
      raise Exception('RSABranchShimHandle.getstack: invalid handle "%s"' % handle)



class RSABranchingShim(BaseShim):

  name = 'RSABranchingShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._listen_handle = None



  def copy(self):
    mycopy = RSABranchingShim()
    return mycopy


  # The coordinator recognizes '[(ShimA)||(ShimB)]' as a branch statement and
  # will automatically expand it appropriately. The alternative port number is
  # enclosed in curly braces.
  def get_advertisement_string(self):
    return '(RSABranchingShim)[(RSAShim){' + \
        str(self._rsaport) + '}||]' + self.shim_stack.get_advertisement_string()

  
  # Server listener callback
  def _branch_waitforconn_cb_wrapper(self, rip, rport, sock, th, lh):
    # busy-waiting until handle is ready
    while not self._listen_handle:
      sleep(0.5)

    # rebuild stack below this shim
    shimstack = self._listen_handle.get_stack(lh)
    socketptr = sock
    while shimstack.top_shim is not None:
      socketptr._shim = shimstack.top_shim.copy()
      socketptr = socketptr._socket
      shimstack = shimstack.top_shim.shim_stack

    # Now that the socket contains a copy of the shim stack below, we can pass
    # the socket to the callback.
    self._branch_waitforconn_cb(rip, rport, sock, th, self._listen_handle)


  # Create two separate shim stacks. Return a wrapper of both handles when both
  # shim stacks return.
  def _shim_waitforconn(self, host, port, callback):

    # Build both shims
    noopstack = self.shim_stack.copy()
    rsastack = self.shim_stack.copy()
    rsastack.push(RSAShim())

    # Create callback wrapper so that the callback function receives our
    # customized listen handle
    self._branch_waitforconn_cb = callback

    # create handle
    noophandle = noopstack.waitforconn(host, port, self._branch_waitforconn_cb_wrapper)
    debugprint("Built noopstack: '%s'" % noopstack)
    self._rsaport = getFreePort()
    rsahandle = rsastack.waitforconn(host, self._rsaport, self._branch_waitforconn_cb_wrapper)
    debugprint("Built rsastack: '%s'" % rsastack)
    handle_stack_map = {noophandle: noopstack, rsahandle: rsastack}
    self._listen_handle = RSABranchingShimHandle(handle_stack_map)

    return self._listen_handle



  # Stop both listeners.
  def _shim_stopcomm(self, listen_handle):
    # check handle
    if not isinstance(listen_handle, RSABranchingShimHandle):
      # TODO Should return false here
      raise Exception('Incorrect listen_handle type.') 

    result = True
    for handle in listen_handle.get_map().keys():
      stack = listen_handle.get_map()[handle]
      ret = stack.stopcomm(handle)
      result = result and ret

    return result
    
 
    

  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):

    has_rsa = isinstance(self.shim_stack.top_shim, RSAShim)

    # TODO debug only. This determines whether this client uses the rsa shim
    # begin

    # if my local ip ends with an even number, then use rsa
    if localhost is None:
      raise Exception('Must specify local IP for debug')

    if int(localhost[len(localhost)-1]) % 2 == 0:
      debug_want_rsa = True
    else:
      debug_want_rsa = False

    if ((debug_want_rsa and (not has_rsa)) or 
        ((not debug_want_rsa) and has_rsa)):
      raise ShimExceptionStackRejected

    if debug_want_rsa:
      debugprint("openconn: Using RSA.")
    else:
      debugprint("openconn: NOT using RSA.")

    # end

    sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
    return sock



#end include RSABranchingShim.repy
#begin include ReverseShim.repy
# A 'subtractive' shim!

#begin include session.repy
#already included session.repy
#end include session.repy


class ReverseShim(BaseShim):


  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)

  def copy(self):
    return ReverseShim()

  def get_advertisement_string(self):
    return '(ReverseShim)' + self.shim_stack.get_advertisement_string()


  # Server's listen
  def _shim_waitforconn(self, hostkey, port, callback):
    self._server_cb = callback
    return self.shim_stack.waitforconn(hostkey, port, self._server_cb_wrapper)


  # Server's listener callback
  def _server_cb_wrapper(self, rip, rport, sock, th, lh):
    debugprint('callback: sock: %s' % sock)

    # obtain client's listener details
    clientip = session_recvmessage(sock)
    clientport = int(session_recvmessage(sock))

    # Pop the nat shim from the copy of the current stack. Important: We do not
    # want to mess with the contents of the current stack!
    shim_stack = self.shim_stack.copy()
    popped = shim_stack.pop()

    # Wait for the client's listener to be ready
    control_msg = session_recvmessage(sock)
    if control_msg == 'client is listening':
      debugprint('Attempt to connect to client %s:%s' % (clientip, clientport))
      callback_sock = shim_stack.openconn(clientip, clientport)
      debugprint('callback: connected, returning sock %s' % callback_sock)

    else:
      raise Exception("Invalid control_msg: '%s'." % control_msg)

    # return new socket to callback
    self._server_cb(rip, rport, callback_sock, th, lh)



  # Client's openconn.
  #
  # Upon connection, send server my ip and port, pop the stack and then I start
  # listening.
  def _shim_openconn(self, hostkey, port, localhost=None, localport=None, timeout=5):
    sock = self.shim_stack.openconn(hostkey, port, localhost, localport, timeout)

    # TODO send my public ip and port, randomly assigned for now
    mylistenip = getRandomIP() # Returns 127.x.x.x
    mylistenport = 12345
    session_sendmessage(sock, mylistenip)
    session_sendmessage(sock, str(mylistenport))

    # Remove the nat shim below me. Again, always make a copy of the stack!
    shim_stack = self.shim_stack.copy()
    shim_stack.pop()

    # start listening!
    self._comm_socket = None
    self._client_listener = shim_stack.waitforconn(mylistenip, mylistenport, self._client_cb_wrapper)
    debugprint('openconn: start listening')

    session_sendmessage(sock, 'client is listening')

    # wait for the server to callback so we have a socket!
    while not self._comm_socket:
      sleep(1)

    debugprint('openconn: got server response, sock = %s' % self._comm_socket)
    return self._comm_socket


  # Client's listener callback
  def _client_cb_wrapper(self, rip, rport, sock, th, lh):
    self._comm_socket = sock

#end include ReverseShim.repy
#begin include NoopShim.repy

class NoopShim(BaseShim):

  def copy(self):
    return NoopShim()


#end include NoopShim.repy




# Register all shims in the world

register_shim('BaseShim', BaseShim)
register_shim('CoordinationShim', CoordinationShim)
register_shim('NatForwardingShim', NatForwardingShim)
register_shim('NatDeciderShim', NatDeciderShim)
register_shim('SimpleEncryptionShim', SimpleEncryptionShim)
register_shim('LogShim', LogShim)
register_shim('RSAShim', RSAShim)
register_shim('NatBranchingShim', NatBranchingShim)
register_shim('RSABranchingShim', RSABranchingShim)
register_shim('ReverseShim', ReverseShim)
register_shim('NoopShim', NoopShim)



# =============================================================================
# TODO for debugging
#

#begin include random.repy 
#already included random.repy 
#end include random.repy 
debugging = True

def debugprint(string):
  if debugging:
    print "zzzz NatBranchingShim: " + str(string)



mycontext['debug_free_ports'] = [12346, 12347]
# For the purpose of debugging only
def getFreePort():
  try:
    return mycontext['debug_free_ports'].pop()
  except IndexError:
    raise Exception('No more free ports')

def getRandomIP():
  ip = '127'
  for section in range(3):
    randint = random_int_below(256)
    ip += '.' + str(randint)
  return ip
  

#
# =============================================================================




class ShimStackInterface:

  def __init__(self, stack_str='', autoCoordinationShim=True):
    self._stack_str = stack_str

    if autoCoordinationShim:
      if stack_str.find('CoordinationShim') < 0:
        self._stack_str = '(CoordinationShim)' + self._stack_str

    # Maps handle to stack. Although handle does not have a hash function
    # defined, it is in fact hashed by its memory address. Thus, the keys in our
    # map always reference to unique handles in the memory.
    self._handle_dict = {}

    self._logger = ShimLogger('')


  def waitforconn(self, host, port, callback):
    shimstack = ShimStack(self._stack_str)

    try:
      handle = shimstack.waitforconn(host, port, callback)
    except Exception, err:
      self._logger.log('waitforconn: Uncaught exception: ' + str(err))
      raise Exception(err)

    self._logger.log('waitforconn on %s:%s' % (host, port))
    self._handle_dict[handle] = shimstack
    return handle


  def stopcomm(self, handle):
    try:
      shimstack = self._handle_dict[handle]
    except KeyError,e:
      raise KeyError(e)
      return False

    try:
      ret = shimstack.stopcomm(handle)
    except Exception, err:
      self._logger.log('stopcomm: Uncaught exception: ' + str(err))
      raise Exception(err)

    return ret
 

  def openconn(self,host,port,localhost=None,localport=None,timeout=5):
    shimstack = ShimStack(self._stack_str)

    try:
      socket = shimstack.openconn(host,port,localhost,localport,timeout)
    except Exception, err:
      self._logger.log('openconn: on %s:%s uncaught exception: %s' % (host, port, err))
      raise Exception(err)

    self._logger.log('openconn: success on %s:%s' % (host, port))

    return socket


  def sendmess(self,host,port,msg,localhost=None,localport=None):
    shimstack = ShimStack(self._stack_str)
    return shimstack.sendmess(host,port,msg,localhost,localport)

 

  def recvmess(self, host, port, callback):
    shimstack = ShimStack(self._stack_str)
    handle = shimstack.recvmess(host, port, callback)
    self._handle_dict[handle] = shimstack
    return handle




