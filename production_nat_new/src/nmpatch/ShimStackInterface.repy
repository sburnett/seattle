"""

Main entry point for all applications that use shim. Provides a wrapper for the
shim stack object for easy instantiation. Also catches any exceptions that are
not consistant with the API semantics. Provides logging capabilities.


"""


class ShimSocketWrapper:

  mycontext['ShimSocketWrapperLock'] = getlock()
  mycontext['ShimSocketWrapperInstanceCounter'] = 0

  def __init__(self, socket, shim):
    if shim is None:
      raise Exception("Null reference to shim provided at constructor of ShimSocketWrapper.")

    self._socket = socket
    self._shim = shim

    mycontext['ShimSocketWrapperLock'].acquire()
    self._id = mycontext['ShimSocketWrapperInstanceCounter']
    mycontext['ShimSocketWrapperInstanceCounter'] += 1
    mycontext['ShimSocketWrapperLock'].release()


  def close(self):
    return self._shim.socket_close(self._socket)


  def recv(self, bytes):
    return self._shim.socket_recv(self._socket, bytes)


  def send(self, message):
    return self._shim.socket_send(self._socket, message)


  def willblock(self):
    return self._socket.willblock()


  def getid(self):
    return self._id

  


  def __str__(self):
    return ("(@ %d Shim: %s. Socket: %s)" % 
            (self.getid(), self._shim, self._socket))

"""

<Program Name>
  ShimStack.repy

<Author>
  Eric Kimbrel, kimbrl@cs.washington.edu

<Date Started>
  Jun 2009

<Purpose>
  Provide a wrapper for network shims with conveient methods for composing
  shims together into a stack
 

"""




_SHIMSTACK_LAYER_DICT = {}



def register_shim(shim_name, shim_class, is_private_shim=False):
  _SHIMSTACK_LAYER_DICT[shim_name] = {'class': shim_class, 
                                      'is_private_shim': is_private_shim}

                      

def shimstack_reg_layer(layer_name,layer_info_dict):
  """
  <Purpose>
    Allows layers to register their information inside of the service
    comp framework

  <Arguments>
    layer_name:
      the name of the layer being registered

    layer_info_dict:
      a dictionary of the form {'class':LayerClass,'type':'LayerType'}

  <Exceptions>
    Exception if a previously registered name is registered

  <Side Effects>
     None

  <Returns>
    None
  """

  if layer_name in _SHIMSTACK_LAYER_DICT:
    raise Exception('Attempt to register previously existing h-layer' +str(layer_name_))
  _SHIMSTACK_LAYER_DICT[layer_name] = layer_info_dict




class ShimStack:


  mycontext['ShimStackInstanceCount'] = 0
  mycontext['ShimStackInstanceCountLock'] = getlock()


  def __init__(self,shim_stack_string=None):
    if shim_stack_string is not None: 
      self.top_shim = self.make_stack(shim_stack_string)
    else:
      self.top_shim = None

    mycontext['ShimStackInstanceCountLock'].acquire()
    self._instance_id = mycontext['ShimStackInstanceCount']
    mycontext['ShimStackInstanceCount'] += 1
    mycontext['ShimStackInstanceCountLock'].release()


  def getid(self):
    return self._instance_id

  
  def push(self,shim):
    shim.shim_stack = ShimStack()
    shim.shim_stack.top_shim = self.top_shim
    
    self.top_shim = shim
    
      

  def pop(self):
    shim = self.top_shim
    if shim is None:
      raise Exception('You cannot pop an empty shim stack.')
    self.top_shim = self.top_shim.shim_stack.top_shim
    shim.shim_stack = None 
    return shim


  def get_names(self):
    return self.top_shim.get_names()


  def copy(self):
    if self.top_shim is None:
      return ShimStack()

    stackcopy = self.top_shim.shim_stack.copy()
    stackcopy.push(self.top_shim.copy())
    return stackcopy

  def get_advertisement_string(self):
    if self.top_shim is None:
      return ""
    else:
      return self.top_shim.get_advertisement_string()


  def get_shims(self, get_all_shims=False):
    if self.top_shim is None:
      return ""
    else:
      return self.top_shim.get_shims(get_all_shims)


  def __repr__(self):
    return self.__str__()


  def __str__(self):
    return "Stack #%d: %s" % (self.getid(), self.get_shims(True))


  def make_stack(self,shim_stack_str):



    temp_str = shim_stack_str.replace('(','')
    stack_list = temp_str.split(')')
    del stack_list[len(stack_list)-1]

  
    top = None # the top of this stack
    previous = None
    for comma_seperated_str in stack_list:
     
      shim_list = comma_seperated_str.split(',')
    
      shim_name = shim_list[0]
    

      shim_args = shim_list[1:]
      if len(shim_args) == 0:
        shim_args = None

    
    
      new_shim = _SHIMSTACK_LAYER_DICT[shim_name]['class'](None,shim_args)

    
      if top == None: top = new_shim
    
      if previous !=None:
        while previous.shim_stack.top_shim is not None:
          previous = previous.shim_stack.top_shim
        previous.shim_stack.top_shim = new_shim
      
      previous = new_shim

    return top 

  




  def _shim_stack_waitforconn_callback_wrapper(self,sock,rip,rport,th,lh):
    self._shim_stack_waitforconn_callback(sock,rip,rport,th,lh)


  def waitforconn(self,host,port,callback):
    self._shim_stack_waitforconn_callback = callback

    if self.top_shim is None:
      self._shim_stack_waitforconn_callback = callback
      return waitforconn(DummyDNSLookup(host,True), port, self._shim_stack_waitforconn_callback_wrapper)

    else:
      return self.top_shim.waitforconn(host,port,self._shim_stack_waitforconn_callback_wrapper)


  def openconn(self,host,port,localhost=None,localport=None,timeout=5):
    if self.top_shim is None:
      return openconn(DummyDNSLookup(host),port,localhost,localport,timeout)

    else:
      return self.top_shim.openconn(host,port,localhost,localport,timeout)



  def recvmess(self,host,port,callback):
    if self.top_shim is None:
      return recvmess(host, port, callback)
    else:
      return self.top_shim.recvmess(host,port,callback)


  def sendmess(self,host,port,msg,localhost=None,localport=None):
    if self.top_shim is None:
      return sendmess(host,port,msg,localhost,localport)
    else:
      return self.top_shim.sendmess(host,port,msg,localhost,localport)

  def stopcomm(self,handle):
    if self.top_shim is None:
      return stopcomm(handle)
    else:
      return self.top_shim.stopcomm(handle)

  def socket_close(self, socket):
    return socket.close()


  def socket_send(self, socket, msg):
    return socket.send(msg)


  def socket_recv(self, socket, bytes):
    return socket.recv(bytes)













class ShimException(Exception):
  pass


class ShimExceptionStackRejected(ShimException):
  pass

"""
Author: Justin Cappos

Start Date: October 14, 2008

Description:
A stub that allows different announcement types.   I'd make this smarter, but
the user won't configure it, right?


Raises an AdvertiseError exception if there is a problem advertising with either service

"""

""" 
Author: Justin Cappos

Module: A simple library of list commands that allow the programmer
        to do list composition operations

Start date: November 11th, 2008

This is a really simple module, only broken out to avoid duplicating 
functionality.

This was adopted from previous code in seash.   

I really should be using sets instead I think.   These are merely for 
convenience when you already have lists.

"""


def listops_difference(list_a,list_b):
  """
   <Purpose>
      Return a list that has all of the items in list_a that are not in list_b
      Duplicates are removed from the output list

   <Arguments>
      list_a, list_b:
        The lists to operate on

   <Exceptions>
      TypeError if list_a or list_b is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing list_a - list_b
  """

  retlist = []
  for item in list_a:
    if item not in list_b:
      retlist.append(item)

  return listops_uniq(retlist)


def listops_union(list_a,list_b):
  """
   <Purpose>
      Return a list that has all of the items in list_a or in list_b.   
      Duplicates are removed from the output list

   <Arguments>
      list_a, list_b:
        The lists to operate on

   <Exceptions>
      TypeError if list_a or list_b is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing list_a union list_b
  """

  retlist = list_a[:]
  for item in list_b: 
    if item not in list_a:
      retlist.append(item)

  return listops_uniq(retlist)


def listops_intersect(list_a,list_b):
  """
   <Purpose>
      Return a list that has all of the items in both list_a and list_b.   
      Duplicates are removed from the output list

   <Arguments>
      list_a, list_b:
        The lists to operate on

   <Exceptions>
      TypeError if list_a or list_b is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing list_a intersect list_b
  """

  retlist = []
  for item in list_a:
    if item in list_b:
      retlist.append(item)

  return listops_uniq(retlist)
      

def listops_uniq(list_a):
  """
   <Purpose>
      Return a list that has no duplicate items

   <Arguments>
      list_a
        The list to operate on

   <Exceptions>
      TypeError if list_a is not a list.

   <Side Effects>
      None.

   <Returns>
      A list containing the unique items in list_a
  """
  retlist = []
  for item in list_a:
    if item not in retlist:
      retlist.append(item)

  return retlist



"""
Author: Justin Cappos

Start Date: July 8, 2008

Description:
Advertises availability to openDHT...

This code is partially adapted from the example openDHT code.

"""

""" 
<Program Name>
  random.repy

<Author>
  Justin Cappos: random_sample

  Modified by Anthony Honstain
    random_nbit_int and random_long_to_bytes is modified from 
    Python Cryptography Toolkit and was part of pycrypto which 
    is maintained by Dwayne C. Litzenberger
    
    random_range, random_randint, and random_int_below are modified 
    from the Python 2.6.1 random.py module. Which was:
    Translated by Guido van Rossum from C source provided by
    Adrian Baddeley.  Adapted by Raymond Hettinger for use with
    the Mersenne Twister  and os.urandom() core generators.  

<Purpose>
  Random routines (similar to random module in Python)
  
  
<Updates needed when emulmisc.py adds randombytes function>
  TODO-
    random_nbit_int currently uses random_randombytes as a source 
    of random bytes, this is not a permanent fix (the extraction 
    of random bytes from the float is not portable). The change will
    likely be made to random_randombytes (since calls os.urandom will
    likely be restricted to a limited number of bytes).  
  TODO - 
    random_randombytes will remained but serve as a helper function
    to collect the required number of bytes. Calls to randombytes
    will be restricted to a set number of bytes at a time, since
    allowing an arbitrary request to os.urandom would circumvent 
    performance restrictions. 
  TODO - 
    _random_long_to_bytes will no longer be needed.  
      
"""

""" Justin Cappos -- substitute for a few python math routines"""

def math_ceil(x):
  xint = int(x)
  
  if x > 0 and x != xint:
    xint = xint + 1

  return float(xint)



def math_floor(x):
  xint = int(x)
  
  if x < 0 and x != xint:
    xint = xint - 1

  return float(xint)



math_e = 2.7182818284590451
math_pi = 3.1415926535897931

def math_log(X, base=math_e, epsilon=1e-16):
  if X <= 0:
    raise ValueError, "log function domain error"

  integer = 0
  if X < 1 and base < 1:
    raise ValueError, "math domain error"
  while X < 1:
    integer -= 1
    X *= base
  while X >= base:
    integer += 1
    X /= base
  partial = 0.5               # partial = 1/2 
  X *= X                      # We perform a squaring
  decimal = 0.0
  while partial > epsilon:
    if X >= base:             # If X >= base then a_k is 1 
      decimal += partial      # Insert partial to the front of the list
      X = X / base            # Since a_k is 1, we divide the number by the base
    partial *= 0.5            # partial = partial / 2
    X *= X                    # We perform the squaring again
  return (integer + decimal)



def random_randombytes(num_bytes, random_float=None):
  """
   <Purpose>
     Return a string of length num_bytes, made of random bytes 
     suitable for cryptographic use (because randomfloat draws
     from a os provided random source).
      
     *WARNING* If python implements float as a C single precision
     floating point number instead of a double precision then
     there will not be 53 bits of data in the coefficient.

   <Arguments>
     num_bytes:
               The number of bytes to request from os.urandom. 
               Must be a positive integer value.
     random_float:
                  Should not be used, available only for testing
                  so that predetermined floats can be provided.
    
   <Exceptions>
     None

   <Side Effects>
     This function results in one or more calls to randomfloat 
     which uses a OS source of random data which is metered.

   <Returns>
     A string of num_bytes random bytes suitable for cryptographic use.
  """
  if random_float is None: 
    random_float = randomfloat()
  
  randombytes = ''
  
  for byte in range(num_bytes/6 + 1):
    
    randomint = int(random_float * (2**53)) 
    randomint = randomint >> 5  
    
    sixbytes = _random_long_to_bytes(randomint)
    
    if len(sixbytes) < 6: 
      sixbytes = '\x00'*(6-len(sixbytes)) + sixbytes 
    randombytes += sixbytes
  
  return randombytes[6 - num_bytes % 6:]
  
  
  
def _random_long_to_bytes(long_int):
  """
  <Purpose>
    Convert a long integer to a byte string.   
    Used by random_randombytes to convert integers recovered
    from random floats into its byte representation.
    Used by random_randombytes, random_randombytes is responsible
    for padding any required binary zeroes that are lost in the
    conversion process.     
  """

  long_int = long(long_int)
  byte_string = ''
  temp_int = 0
  
  if long_int == 0:
    return '\000'
  
  while long_int > 0:
    tmp_int = long_int & 0xFF
    byte_string = "%s%s" % (chr(tmp_int), byte_string)
    long_int = long_int >> 8
      
  return byte_string



def random_nbit_int(num_bits):  
  """
  <Purpose>
    Returns an random integer that was constructed with
    num_bits many random bits. The result will be an
    integer [0, 2**(num_bits) - 1] inclusive.
     
    For Example:
     If a 10bit number is needed, random_nbit_int(10).
     Min should be greater or equal to 0
     Max should be less than or equal to 1023

    TODO-
      This function currently uses random_randombytes as a source 
      of random bytes, this is not a permanent fix (the extraction 
      of random bytes from the float is not portable). The change will
      likely be made to random_randombytes (since calls os.urandom will
      likely be restricted to a limited number of bytes).

  <Arguments>
    num_bits:
             The number of random bits to be used for construction
             of the random integer to be returned.

  <Exceptions>
    TypeError if non-integer values for num_bits.
      Will accept floats of the type 1.0, 2.0, ...
    
    ValueError if the num_bits is negative or 0.

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of random data which is metered.

  <Returns>
    Returns a random integer between [0, 2**(num_bits) - 1] inclusive.
  
  <Walkthrough of functions operation>
    This will be a step by step walk through of the key operations
    defined in this function, with the largest possible
    10 bit integer returned.
    
    num_bits = 10
    
    randstring = random_randombytes(10/8)  for our example we
    will suppose that the byte returned was '\xff' (which is the
    same as chr(255)).
    
    odd_bits = 10 % 8 = 2
    Once again we assume that random_randombytes(1) returns the
    maximum possible, which is '\xff'  
    chr = ord('\xff') >> (8 - odd_bits)
    -> chr = 255 >> (8 - 2)
    -> chr = 255 >> 6 = 3   Note 3 is the largest 2 bit number
    chr(3) is appended to randstring resulting in
    randstring = '\x03\xff' 
    
    value = 0
    length = 2
    
    STEP 1 (i = 0):
      value = value << 8 
      -> value = 0
      value = value + ord(randstring[0])
      -> value = 3
    
    STEP 2 (i = 1):
      value = value << 8
      -> value = 768
      value = value + ord(randstring[1])
      -> value = 1023
    
    return 1023
    This is the maximum possible 10 bit integer.
  """
  if num_bits <= 0:
    raise ValueError('number of bits must be greater than zero')
  if num_bits != int(num_bits):
    raise TypeError('number of bits should be an integer')
  
  randstring = random_randombytes(num_bits/8)

  odd_bits = num_bits % 8
  if odd_bits != 0:
    char = ord(random_randombytes(1)) >> (8 - odd_bits)
    randstring = chr(char) + randstring
  
  result = 0L
  length = len(randstring)
  for i in range(0, length):
    result = (result << 8) 
    result = result + ord(randstring[i]) 
  
  assert(result < (2 ** num_bits))
  assert(result >= 0)

  return result



def random_int_below(upper_bound):
  """
  <Purpose>
    Returns an random integer in the range [0,upper_bound)
    
    Handles the case where upper_bound has more bits than returned
    by a single call to the underlying generator.
     
    For Example:
     For a 10bit number, random_int_below(10).
     results would be an element in of the set 0,1,2,..,9.
     
    NOTE: This function is a port from the random.py file in 
    python 2.6.2. For large numbers I have experienced inconsistencies
    when using a naive logarithm function to determine the
    size of a number in bits.  

  <Arguments>
    upper_bound:
           The random integer returned will be in [0, upper_bound).
           Results will be integers less than this argument.

  <Exceptions>
    TypeError if non-integer values for upper_bound.
    ValueError if the upper_bound is negative or 0.

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of random data which is metered.

  <Returns>
    Returns a random integer between [0, upper_bound).
  
  """
  
  try:
    upper_bound = int(upper_bound)
  except ValueError:
    raise TypeError('number should be an integer')
  
  if upper_bound <= 0:
    raise ValueError('number must be greater than zero')
  
    
  if upper_bound == 1:
    return 0
  
  k = int(1.00001 + math_log(upper_bound - 1, 2.0))   # 2**k > n-1 > 2**(k-2)
  r = random_nbit_int(k)
  while r >= upper_bound:
    r = random_nbit_int(k)
  return r

 

def random_randrange(start, stop=None, step=1):
  """
  <Purpose>
    Choose a random item from range(start, stop[, step]).
    
  <Arguments>
    start:
      The random integer returned will be greater than
      or equal to start. 
  
    stop:
      The random integer returned will be less than stop.
      Results will be integers less than this argument.

    step:
      Determines which elements from the range will be considered.
     
  <Exceptions>
    ValueError:
      Non-integer for start or stop argument
      Empty range, if start < 0 and stop is None
      Empty range
      Zero or non-integer step for range

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of randomdata which is metered.
  
  <Returns>
    Random item from (start, stop[, step]) 'exclusive'
    
  <Notes on port>
    This fixes the problem with randint() which includes the
    endpoint; in Python this is usually not what you want.
    
    Anthony -I removed these since they do not apply
      int=int, default=None, maxwidth=1L<<BPF
      Do not supply the 'int', 'default', and 'maxwidth' arguments.
  """
  maxwidth = 1L<<53

  istart = int(start)
  if istart != start:
    raise ValueError, "non-integer arg 1 for randrange()"
  if stop is None:
    if istart > 0:
      if istart >= maxwidth:
        return random_int_below(istart)
      return int(randomfloat() * istart)
    raise ValueError, "empty range for randrange()"

  istop = int(stop)
  if istop != stop:
    raise ValueError, "non-integer stop for randrange()"
  width = istop - istart
  if step == 1 and width > 0:

    if width >= maxwidth:
      return int(istart + random_int_below(width))
    return int(istart + int(randomfloat()*width))
  if step == 1:
    raise ValueError, "empty range for randrange() (%d,%d, %d)" % (istart, istop, width)

  istep = int(step)
  if istep != step:
    raise ValueError, "non-integer step for randrange()"
  if istep > 0:
    n = (width + istep - 1) // istep
  elif istep < 0:
    n = (width + istep + 1) // istep
  else:
    raise ValueError, "zero step for randrange()"

  if n <= 0:
    raise ValueError, "empty range for randrange()"

  if n >= maxwidth:
    return istart + istep*random_int_below(n)
  return istart + istep*int(randomfloat() * n)



def random_randint(lower_bound, upper_bound):
  """
  <Purpose>
    Return random integer in range [lower_bound, upper_bound], 
    including both end points.
    
  <Arguments>
    upper_bound:
      The random integer returned will be less than upper_bound.
    lower_bound:
      The random integer returned will be greater than
      or equal to the lower_bound.

  <Exceptions>
    None

  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of randomdata which is metered.
  
  <Returns>
    Random integer from [lower_bound, upper_bound] 'inclusive'  
  """
  return random_randrange(lower_bound, upper_bound+1)



def random_sample(population, k):
  """
  <Purpose>
    To return a list containing a random sample from the population.
    
  <Arguments>
    population:
               The elements to be sampled from.
    k: 
      The number of elements to sample
      
  <Exceptions>
    ValueError is sampler larger than population.
    
  <Side Effects>
    This function results in one or more calls to randomfloat 
    which uses a OS source of randomdata which is metered.
    
  <Returns>
    A list of len(k) with random elements from the population.
    
  """
  
  newpopulation = population[:]
  if len(population) < k:
    raise ValueError, "sample larger than population"

  retlist = []
  populationsize = len(population)-1

  for num in range(k):
    pos = random_randint(0,populationsize-num)
    retlist.append(newpopulation[pos])
    del newpopulation[pos]

  return retlist


"""A sample implementation of SHA-1 in pure Python.

   Adapted by Justin Cappos from the version at: http://codespeak.net/pypy/dist/pypy/lib/sha.py

   Framework adapted from Dinu Gherman's MD5 implementation by
   J. Hall`en and L. Creighton. SHA-1 implementation based directly on
   the text of the NIST standard FIPS PUB 180-1.

date    = '2004-11-17'
version = 0.91 # Modernised by J. Hall`en and L. Creighton for Pypy
"""




def _sha_long2bytesBigEndian(n, thisblocksize=0):
    """Convert a long integer to a byte string.

    If optional blocksize is given and greater than zero, pad the front
    of the byte string with binary zeros so that the length is a multiple
    of blocksize.
    """

    s = ''
    while n > 0:
        s = chr(n & 0xff) + s
        n = n >> 8

    for i in range(len(s)):
        if s[i] <> '\000':
            break
    else:
        s = '\000'
        i = 0

    s = s[i:]

    if thisblocksize > 0 and len(s) % thisblocksize:
        s = (thisblocksize - len(s) % thisblocksize) * '\000' + s

    return s


def _sha_bytelist2longBigEndian(list):
    "Transform a list of characters into a list of longs."

    imax = len(list)/4
    hl = [0L] * imax

    j = 0
    i = 0
    while i < imax:
        b0 = long(ord(list[j])) << 24
        b1 = long(ord(list[j+1])) << 16
        b2 = long(ord(list[j+2])) << 8
        b3 = long(ord(list[j+3]))
        hl[i] = b0 | b1 | b2 | b3
        i = i+1
        j = j+4

    return hl


def _sha_rotateLeft(x, n):
    "Rotate x (32 bit) left n bits circularly."

    return (x << n) | (x >> (32-n))



sha_K = [
    0x5A827999L, # ( 0 <= t <= 19)
    0x6ED9EBA1L, # (20 <= t <= 39)
    0x8F1BBCDCL, # (40 <= t <= 59)
    0xCA62C1D6L  # (60 <= t <= 79)
    ]

class sha:
    "An implementation of the MD5 hash function in pure Python."

    def __init__(self):
        "Initialisation."
        
        self.length = 0L
        self.count = [0, 0]

        self.inputdata = []

        self.init()


    def init(self):
        "Initialize the message-digest and set all fields to zero."

        self.length = 0L
        self.inputdata = []

        self.H0 = 0x67452301L
        self.H1 = 0xEFCDAB89L
        self.H2 = 0x98BADCFEL
        self.H3 = 0x10325476L
        self.H4 = 0xC3D2E1F0L

    def _transform(self, W):

        for t in range(16, 80):
            W.append(_sha_rotateLeft(
                W[t-3] ^ W[t-8] ^ W[t-14] ^ W[t-16], 1) & 0xffffffffL)

        A = self.H0
        B = self.H1
        C = self.H2
        D = self.H3
        E = self.H4

        """
        This loop was unrolled to gain about 10% in speed
        for t in range(0, 80):
            TEMP = _sha_rotateLeft(A, 5) + sha_f[t/20] + E + W[t] + sha_K[t/20]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL
        """

        for t in range(0, 20):
            TEMP = _sha_rotateLeft(A, 5) + ((B & C) | ((~ B) & D)) + E + W[t] + sha_K[0]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL

        for t in range(20, 40):
            TEMP = _sha_rotateLeft(A, 5) + (B ^ C ^ D) + E + W[t] + sha_K[1]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL

        for t in range(40, 60):
            TEMP = _sha_rotateLeft(A, 5) + ((B & C) | (B & D) | (C & D)) + E + W[t] + sha_K[2]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL

        for t in range(60, 80):
            TEMP = _sha_rotateLeft(A, 5) + (B ^ C ^ D)  + E + W[t] + sha_K[3]
            E = D
            D = C
            C = _sha_rotateLeft(B, 30) & 0xffffffffL
            B = A
            A = TEMP & 0xffffffffL


        self.H0 = (self.H0 + A) & 0xffffffffL
        self.H1 = (self.H1 + B) & 0xffffffffL
        self.H2 = (self.H2 + C) & 0xffffffffL
        self.H3 = (self.H3 + D) & 0xffffffffL
        self.H4 = (self.H4 + E) & 0xffffffffL
    


    def update(self, inBuf):
        """Add to the current message.

        Update the md5 object with the string arg. Repeated calls
        are equivalent to a single call with the concatenation of all
        the arguments, i.e. m.update(a); m.update(b) is equivalent
        to m.update(a+b).

        The hash is immediately calculated for all full blocks. The final
        calculation is made in digest(). It will calculate 1-2 blocks,
        depending on how much padding we have to add. This allows us to
        keep an intermediate value for the hash, so that we only need to
        make minimal recalculation if we call update() to add more data
        to the hashed string.
        """

        leninBuf = long(len(inBuf))

        index = (self.count[1] >> 3) & 0x3FL

        self.count[1] = self.count[1] + (leninBuf << 3)
        if self.count[1] < (leninBuf << 3):
            self.count[0] = self.count[0] + 1
        self.count[0] = self.count[0] + (leninBuf >> 29)

        partLen = 64 - index

        if leninBuf >= partLen:
            self.inputdata[index:] = list(inBuf[:partLen])
            self._transform(_sha_bytelist2longBigEndian(self.inputdata))
            i = partLen
            while i + 63 < leninBuf:
                self._transform(_sha_bytelist2longBigEndian(list(inBuf[i:i+64])))
                i = i + 64
            else:
                self.inputdata = list(inBuf[i:leninBuf])
        else:
            i = 0
            self.inputdata = self.inputdata + list(inBuf)


    def digest(self):
        """Terminate the message-digest computation and return digest.

        Return the digest of the strings passed to the update()
        method so far. This is a 16-byte string which may contain
        non-ASCII characters, including null bytes.
        """

        H0 = self.H0
        H1 = self.H1
        H2 = self.H2
        H3 = self.H3
        H4 = self.H4
        inputdata = [] + self.inputdata
        count = [] + self.count

        index = (self.count[1] >> 3) & 0x3fL

        if index < 56:
            padLen = 56 - index
        else:
            padLen = 120 - index

        padding = ['\200'] + ['\000'] * 63
        self.update(padding[:padLen])

        bits = _sha_bytelist2longBigEndian(self.inputdata[:56]) + count

        self._transform(bits)

        digest = _sha_long2bytesBigEndian(self.H0, 4) + \
                 _sha_long2bytesBigEndian(self.H1, 4) + \
                 _sha_long2bytesBigEndian(self.H2, 4) + \
                 _sha_long2bytesBigEndian(self.H3, 4) + \
                 _sha_long2bytesBigEndian(self.H4, 4)

        self.H0 = H0 
        self.H1 = H1 
        self.H2 = H2
        self.H3 = H3
        self.H4 = H4
        self.inputdata = inputdata 
        self.count = count 

        return digest


    def hexdigest(self):
        """Terminate and return digest in HEX form.

        Like digest() except the digest is returned as a string of
        length 32, containing only hexadecimal digits. This may be
        used to exchange the value safely in email or other non-
        binary environments.
        """
        return ''.join(['%02x' % ord(c) for c in self.digest()])

    def copy(self):
        """Return a clone object. (not implemented)

        Return a copy ('clone') of the md5 object. This can be used
        to efficiently compute the digests of strings that share
        a common initial substring.
        """
        raise Exception, "not implemented"




sha_digest_size = sha_digestsize = 20
sha_blocksize = 1

def sha_new(arg=None):
    """Return a new sha crypto object.

    If arg is present, the method call update(arg) is made.
    """

    crypto = sha()
    if arg:
        crypto.update(arg)

    return crypto


def sha_hash(string):
    crypto = sha()
    crypto.update(string)
    return crypto.digest()


def sha_hexhash(string):
    crypto = sha()
    crypto.update(string)
    return crypto.hexdigest()

"""
<Program Name>
  xmlrpc_client.py

<Started>
  May 3, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Implements the client-side XML-RPC protocol.

"""


"""
<Program Name>
  urlparse.repy

<Started>
  May 15, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Provides utilities for parsing URLs, based on the Python 2.6.1 module urlparse.

"""


def urlparse_urlsplit(urlstring, default_scheme="", allow_fragments=True):
  """
  <Purpose>
    Parse a URL into five components, returning a dictionary.  This corresponds
    to the general structure of a URL:
    scheme://netloc/path;parameters?query#fragment.  The parameters are not
    split from the URL and individual componenets are not separated.

    Only absolute server-based URIs are currently supported (all URLs will be
    parsed into the components listed, regardless of the scheme).

  <Arguments>
    default_scheme:
      Optional: defaults to the empty string.  If specified, gives the default
      addressing scheme, to be used only if the URL does not specify one.

    allow_fragments:
      Optional: defaults to True.  If False, fragment identifiers are not
      allowed, even if the URL's addressing scheme normally does support them.

  <Exceptions>
    ValueError on parsing a non-numeric port value.

  <Side Effects>
    None.

  <Returns>
    A dictionary containing:

    Key         Value                               Value if not present
    ============================================================================
    scheme      URL scheme specifier                empty string
    netloc      Network location part               empty string
    path        Hierarchical path                   empty string
    query       Query component                     empty string
    fragment    Fragment identifier                 empty string
    username    User name                           None
    password    Password                            None
    hostname    Host name (lower case)              None
    port        Port number as integer, if present  None

  """

  components = {"scheme": default_scheme, "netloc": "", "path": "", "query": "",
    "fragment": "", "username": None, "password": None, "hostname": None,
    "port": None }

  (lpart, rpart) = _urlparse_splitscheme(urlstring)
  if lpart:
    components["scheme"] = lpart

  if rpart.startswith("//"):
    (lpart, rpart) = _urlparse_splitnetloc(rpart, 2)
    components["netloc"] = lpart

    (components["username"], components["password"], components["hostname"],
      components["port"]) = _urlparse_splitauthority(lpart)

  if allow_fragments:
    (rpart, components["fragment"]) = _urlparse_splitfragment(rpart)


  (components["path"], components["query"]) = _urlparse_splitquery(rpart)

  return components


def _urlparse_splitscheme(url):
  """Parse the scheme portion of the URL"""
  scheme_chars = \
    "abcdefghijklmnopqrstuvwxyz0123456789+-."

  scheme = ""
  rest = url

  spart = url.split(":", 1)
  if len(spart) == 2:

    spart[0] = spart[0].lower()

    if spart[0] and spart[0][0].isalpha():
      for char in spart[0]:
        if char not in scheme_chars:
          break
      (scheme, rest) = spart

  return scheme, rest


def _urlparse_splitnetloc(url, start=0):
  """Parse the netloc portion of the URL"""

  delim = len(url)

  for char in "/?#":
    xdelim = url.find(char, start)
    if xdelim >= 0:
      delim = min(delim, xdelim)

  return url[start:delim], url[delim:]


def _urlparse_splitauthority(netloc):
  """Parse the authority portion of the netloc"""

  authority = netloc.split("@", 1)

  username = None
  password = None
  hostname = None
  port = None

  if len(authority) == 2:

    userinfo = authority[0].split(":", 1)

    hostport = authority[1].split(":", 1)

    if userinfo[0]:
      username = userinfo[0]
    if len(userinfo) == 2:
      password = userinfo[1]

  else:

    hostport = netloc.split(":", 1)

  if hostport[0]:
    hostname = hostport[0]
  if len(hostport) == 2:
    port = int(hostport[1], 10)

  return username, password, hostname, port


def _urlparse_splitquery(url):
  """Parse the query portion of the url"""

  qpart = url.split("?", 1)
  if len(qpart) == 2:
    query = qpart[1]
  else:
    query = ""

  return qpart[0], query


def _urlparse_splitfragment(url):
  """Parse the query portion of the url"""

  fpart = url.split("#", 1)
  if len(fpart) == 2:
    fragment = fpart[1]
  else:
    fragment = ""

  return fpart[0], fragment

"""
<Program Name>
  httpretrieve.repy

<Started>
  August 19, 2009

<Authors>
  Yafete Yemuru
  Conrad Meyer
  
<Purpose>
  Provides a method for retrieving content from web servers using the HTTP
  protocol. The content can be accessed as a file like object, or saved to
  a file or returned as a string.
"""



"""
<Author>
  Justin Cappos, Armon Dadgar
  This is a rewrite of the previous version by Richard Jordan

<Start Date>
  26 Aug 2009

<Description>
  A library that causes sockets to timeout if a recv / send call would
  block for more than an allotted amount of time.

"""


class SocketTimeoutError(Exception):
  """The socket timed out before receiving a response"""


class _timeout_socket():
  """
  <Purpose>
    Provides a socket like object which supports custom timeouts
    for send() and recv().
  """

  def __init__(self,socket,timeout=10, checkintv=0.1):
    """
    <Purpose>
      Initializes a timeout socket object.

    <Arguments>
      socket:
              A socket like object to wrap. Must support send,recv,close, and willblock.

      timeout:
              The default timeout for send() and recv().

      checkintv:
              How often socket operations (send,recv) should check if
              they can run. The smaller the interval the more time is
              spent busy waiting.
    """
    self.socket = socket
    self.timeout = timeout
    self.checkintv = checkintv


  def settimeout(self,timeout=10):
    """
    <Purpose>
      Allows changing the default timeout interval.

    <Arguments>
      timeout:
              The new default timeout interval. Defaults to 10.
              Use 0 for no timeout. Given in seconds.

    """
    self.timeout = timeout
  
  
  def willblock(self):
    """
    See socket.willblock()
    """
    return self.socket.willblock()


  def close(self):
    """
    See socket.close()
    """
    return self.socket.close()


  def recv(self,bytes,timeout=None):
    """
    <Purpose>
      Allows receiving data from the socket object with a custom timeout.

    <Arguments>
      bytes:
          The maximum amount of bytes to read

      timeout:
          (Optional) Defaults to the value given at initialization, or by settimeout.
          If provided, the socket operation will timeout after this amount of time (sec).
          Use 0 for no timeout.

    <Exceptions>
      As with socket.recv(), socket.willblock(). Additionally, SocketTimeoutError is
      raised if the operation times out.

    <Returns>
      The data received from the socket.
    """
    if timeout is None:
      timeout = self.timeout

    starttime = getruntime()

    rblock, wblock = self.socket.willblock()
    while rblock:
      if timeout > 0:
        diff = getruntime() - starttime

        if diff > timeout:
          raise SocketTimeoutError,"recv() timed out!"

      sleep(self.checkintv)

      rblock, wblock = self.socket.willblock()

    return self.socket.recv(bytes)


  def send(self,data,timeout=None):
    """
    <Purpose>
      Allows sending data with the socket object with a custom timeout.

    <Arguments>
      data:
          The data to send

      timeout:
          (Optional) Defaults to the value given at initialization, or by settimeout.
          If provided, the socket operation will timeout after this amount of time (sec).
          Use 0 for no timeout.

    <Exceptions>
      As with socket.send(), socket.willblock(). Additionally, SocketTimeoutError is
      raised if the operation times out.

    <Returns>
      The number of bytes sent.
    """
    if timeout is None:
      timeout = self.timeout

    starttime = getruntime()

    rblock, wblock = self.socket.willblock()
    while wblock:
      if timeout > 0:
        diff = getruntime() - starttime

        if diff > timeout:
          raise SocketTimeoutError,"send() timed out!"

      sleep(self.checkintv)

      rblock, wblock = self.socket.willblock()

    return self.socket.send(data) 




def timeout_openconn(desthost, destport, localip=None, localport=None, timeout=5):
  """
  <Purpose> 
    Wrapper for openconn.   Very, very similar

  <Args>
    Same as Repy openconn

  <Exception>
    Raises the same exceptions as openconn.

  <Side Effects>
    Creates a socket object for the user

  <Returns>
    socket obj on success
  """

  realsocketlikeobject = openconn(desthost, destport, localip, localport, timeout)

  thissocketlikeobject = _timeout_socket(realsocketlikeobject, timeout)
  return thissocketlikeobject





def timeout_waitforconn(localip, localport, function, timeout=5):
  """
  <Purpose> 
    Wrapper for waitforconn.   Essentially does the same thing...

  <Args>
    Same as Repy waitforconn with the addition of a timeout argument.

  <Exceptions> 
    Same as Repy waitforconn

  <Side Effects>
    Sets up event listener which calls function on messages.

  <Returns>
    Handle to listener.
  """

  def _timeout_waitforconn_callback(localip, localport, sockobj, ch, mainch):
    thissocketlikeobject = _timeout_socket(sockobj, timeout)

    return function(localip, localport, thissocketlikeobject, ch, mainch)

  return waitforconn(localip, localport, _timeout_waitforconn_callback)

  
  


def timeout_stopcomm(commhandle):
  """
    Wrapper for stopcomm.   Does the same thing...
  """

  return stopcomm(commhandle)
  
    


def urllib_quote(inputstring, safestring="/"):
  """
  <Purpose>
    Encode an inputstring such that it can be used safely in a URL or XML
    document.

  <Arguments>
    inputstring:
           The string to urlencode.

    safestring (optional):
           Specifies additional characters that should not be quoted --
           defaults to "/".

  <Exceptions>
    TypeError if the inputstring or safestring parameters aren't strings.

  <Side Effects>
    None.

  <Returns>
    Urlencoded version of the passed string.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_quote's inputstring parameter must be a string, not '"+str(type(inputstring))+"'")
  if type(safestring) is not str:
    raise TypeError("urllib_quote's safestring parameter must be a string, not '"+str(type(safestring))+"'")
  

  resultstr = ""


  safeset = set(safestring)

  for char in inputstring:
    asciicode = ord(char)
    if (asciicode >= ord("0") and asciicode <= ord("9")) or \
        (asciicode >= ord("A") and asciicode <= ord("Z")) or \
        (asciicode >= ord("a") and asciicode <= ord("z")) or \
        asciicode == ord("_") or asciicode == ord(".") or \
        asciicode == ord("-") or char in safeset:
      resultstr += char
    else:
      resultstr += "%%%02X" % asciicode

  return resultstr




def urllib_quote_plus(inputstring, safestring=""):
  """
  <Purpose>
    Encode a string to go in the query fragment of a URL.

  <Arguments>
    inputstring:
           The string to urlencode.

    safestring (optional):
           Specifies additional characters that should not be quoted --
           defaults to the empty string.

  <Exceptions>
    TypeError if the inputstring or safestring parameters aren't strings.

  <Side Effects>
    None.

  <Returns>
    Urlencoded version of the passed string.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_quote_plus' inputstring parameter must be a string, not '"+str(type(inputstring))+"'")
  if type(safestring) is not str:
    raise TypeError("urllib_quote_plus' safestring parameter must be a string, not '"+str(type(safestring))+"'")
  

  return urllib_quote(inputstring, safestring + " ").replace(" ", "+")




def urllib_unquote(inputstring):
  """
  <Purpose>
    Unquote a urlencoded string.

  <Arguments>
    inputstring:
           The string to unquote.

  <Exceptions>
    TypeError if the inputstring isn't a string
    ValueError thrown if the last wrapped octet isn't a valid wrapped octet
    (i.e. if the string ends in "%" or "%x" rather than "%xx". Also throws
    ValueError if the nibbles aren't valid hex digits.

  <Side Effects>
    None.

  <Returns>
    The decoded string.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_unquote's inputstring parameter must be a string, not '"+str(type(inputstring))+"'")
  

  resultstr = ""


  while True:
    lastpercentlocation = inputstring.rfind("%")
    if lastpercentlocation < 0:
      break

    wrappedoctetstr = inputstring[lastpercentlocation+1:lastpercentlocation+3]
    if len(wrappedoctetstr) != 2:
      raise ValueError("Quoted string is poorly formed")

    resultstr = \
        chr(int(wrappedoctetstr, 16)) + \
        inputstring[lastpercentlocation+3:] + \
        resultstr
    inputstring = inputstring[:lastpercentlocation]

  resultstr = inputstring + resultstr
  return resultstr




def urllib_unquote_plus(inputstring):
  """
  <Purpose>
    Unquote the urlencoded query fragment of a URL.

  <Arguments>
    inputstring:
           The string to unquote.

  <Exceptions>
    TypeError if the inputstring isn't a string
    ValueError thrown if the last wrapped octet isn't a valid wrapped octet
    (i.e. if the inputstring ends in "%" or "%x" rather than "%xx". Also throws
    ValueError if the nibbles aren't valid hex digits.

  <Side Effects>
    None.

  <Returns>
    The decoded string.
  """
  if type(inputstring) is not str:
    raise TypeError("urllib_unquote_plus' inputstring parameter must be a string, not '"+str(type(inputstring))+"'")

  return urllib_unquote(inputstring.replace("+", " "))




def urllib_quote_parameters(inputdictionary):
  """
  <Purpose>
    Encode a dictionary of (key, value) pairs into an HTTP query string or
    POST body (same form).

  <Arguments>
    dictionary:
           The dictionary to quote.

  <Exceptions>
    TypeError if the inputdictionary isn't a dict.

  <Side Effects>
    None.

  <Returns>
    The quoted dictionary.
  """
  if type(inputdictionary) is not dict:
    raise TypeError("urllib_quote_parameters' inputstringdictionary parameter must be a dict, not '"+str(type(inputstring))+"'")

  quoted_keyvals = []
  for key, val in inputdictionary.items():
    quoted_keyvals.append("%s=%s" % (urllib_quote(key), urllib_quote(val)))

  return "&".join(quoted_keyvals)




def urllib_unquote_parameters(inputstring):
  """
  <Purpose>
    Decode a urlencoded query string or POST body.

  <Arguments>
    inputstring:
           The string to decode.

  <Exceptions>
    TypeError if the inputstring isn't a string
    ValueError if the inputstring is poorly formed.

  <Side Effects>
    None.

  <Returns>
    A dictionary mapping keys to values.
  """

  if type(inputstring) is not str:
    raise TypeError("urllib_unquote_parameters' inputstring parameter must be a string, not '"+str(type(inputstring))+"'")

  keyvalpairs = inputstring.split("&")
  res = {}

  for quotedkeyval in keyvalpairs:
    quotedkey, quotedval = quotedkeyval.split("=")
    key = urllib_unquote_plus(quotedkey)
    val = urllib_unquote_plus(quotedval)
    res[key] = val

  return res




class HttpConnectionError(Exception):
  """
  Error indicating that the web server has unexpectedly dropped the
  connection.
  """




class HttpBrokenServerError(Exception):
  """
  Error indicating that the web server has sent us complete garbage instead
  of something resembling HTTP.
  """




def httpretrieve_open(url, querydata=None, postdata=None,\
    httpheaders=None, proxy=None, timeout=None):
  """
  <Purpose>
     Returns a file-like object that can be used to read the content from
     an HTTP server. Follows 3xx redirects.

  <Arguments>
    url:
           The URL to perform a GET or POST request on.
    postdata (optional):
           A dictionary of form data or a string to POST to the server.
           Passing a non-None value results in a POST request being sent
           to the server.
    querydata (optional):
           A dictionary of form data or a string to send as the query
           string to the server.

           If postdata is omitted, the URL is retrieved with GET. If
           both postdata and querydata are omitted, there is no query
           string sent in the request.

           For both querydata and postdata, strings are sent *unmodified*.
           This means you probably should encode them first, with
           urllib_quote().
    httpheaders (optional):
           A dictionary of supplemental HTTP request headers to add to the
           request.
    proxy (optional):
           A proxy server 2-tuple to bind to: ('host', port).       
    timeout (optional):
           A timeout for establishing a connection to the web server,
           sending headers, and reading the response headers.

           If excluded or None, never times out.

  <Exceptions>
    ValueError if given an invalid URL, or malformed limit or timeout
      values. This is also raised if the user attempts to call a method
      on the file-like object after closing it.

    HttpConnectionError if opening the connection fails, or if the
      connection is closed by the server before we expect.

    SocketTimeoutError if the timeout is exceeded.

    HttpBrokenServerError if the response or the Location response header
      is malformed.

  <Side Effects>
    None

  <Returns>
    Returns a file-like object which can be used to read the body of
    the response from the web server. The protocol version spoken by the
    server, status code, and response headers are available as members of
    the object.
  """

  starttimefloat = getruntime()

  parsedurldict = urlparse_urlsplit(url)
  hoststr = parsedurldict['hostname']
  pathstr = parsedurldict['path']
  portint = parsedurldict.get('port')
  portint = portint or 80

  if parsedurldict['scheme'] != 'http':
    raise ValueError("URL doesn't seem to be for the HTTP protocol.")
  if hoststr is None:
    raise ValueError("Missing hostname.")
  if parsedurldict['query'] is not None and parsedurldict['query'] != "":
    raise ValueError("URL cannot include a query string.")


  try:
    if proxy is not None:
      sockobj = timeout_openconn(proxy[0], proxy[1], timeout=timeout)  
    else:
      sockobj = timeout_openconn(hoststr, portint, timeout=timeout)

  except Exception, e:
    if repr(e).startswith("timeout("):
      raise HttpConnectionError("Socket timed out connecting to host/port.")
    raise

  httprequeststr = _httpretrieve_build_request(hoststr, portint, pathstr, \
      querydata, postdata, httpheaders, proxy)

  _httpretrieve_sendall(sockobj, httprequeststr)


  if timeout is None:
    sockobj.settimeout(0)
  elif getruntime() - starttimefloat >= timeout:
    raise SocketTimeoutError("Timed out")
  else:
    sockobj.settimeout(timeout - (getruntime() - starttimefloat))

  headersstr = ""
  while not headersstr.endswith("\r\n\r\n"):
    try:
      headersstr += sockobj.recv(1)
    except Exception, e:
      if str(e) == "Socket closed":
        break
      else:
        raise

  httpheaderlist = headersstr.split("\r\n")
  while len(httpheaderlist) > 0 and httpheaderlist[-1] == "":
    httpheaderlist = httpheaderlist[:-1]

  statuslinestr, httpheaderlist = httpheaderlist[0], httpheaderlist[1:]

  statuslinelist = statuslinestr.split(' ', 2)

  if len(statuslinelist) < 3:
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (status line missing one or more fields).")

  if not statuslinelist[0].startswith('HTTP'):
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (invalid response protocol in status line).")

  friendlystatusstr = statuslinelist[2]
  try:
    statusint = int(statuslinelist[1])
  except ValueError, e:
    raise HttpBrokenServerError("Server returned garbage for HTTP " + \
        "response (status code isn't integer).")

  httpheaderdict = _httpretrieve_parse_responseheaders(httpheaderlist)

  if statusint in (301, 302, 303, 307):
    sockobj.close()
    try:
      redirecturlstr = httpheaderdict["Location"][0]
    except (KeyError, IndexError), ke:
      pass
    else:
      return httpretrieve_open(redirecturlstr)

  return _httpretrieve_filelikeobject(sockobj, httpheaderdict, \
      (statuslinelist[0], statusint, friendlystatusstr))




def httpretrieve_save_file(url, filename, querydata=None, postdata=None, \
    httpheaders=None, proxy=None, timeout=None):
  """
  <Purpose>
    Perform an HTTP request, and save the content of the response to a
    file.

  <Arguments>
    filename:
           The file name to save the response to.
    Other arguments:
           See documentation for httpretrieve_open().

  <Exceptions>
    This function will raise any exception raised by Repy file objects
    in opening, writing to, and closing the file.

    This function will all also raise any exception raised by
    httpretrieve_open(), for the same reasons.

  <Side Effects>
    Writes the body of the response to 'filename'.

  <Returns>
    None
  """

  outfileobj = open(filename, 'w')
  httpobj = httpretrieve_open(url, querydata=querydata, postdata=postdata, \
      httpheaders=httpheaders, proxy=proxy, timeout=timeout)

  responsechunkstr = None
  while responsechunkstr != '':
    responsechunkstr = httpobj.read(4096)
    outfileobj.write(responsechunkstr)

  outfileobj.close()
  httpobj.close()




def httpretrieve_get_string(url, querydata=None, postdata=None, \
    httpheaders=None, proxy=None, timeout=30):
  """
  <Purpose>
    Performs an HTTP request on the given URL, using POST or GET,
    returning the content of the response as a string. Uses
    httpretrieve_open.

  <Arguments>
    See httpretrieve_open.

  <Exceptions>
    See httpretrieve_open.

  <Side Effects>
    None.

  <Returns>
    Returns the body of the HTTP response (no headers).
  """

  httpobj = httpretrieve_open(url, querydata=querydata, postdata=postdata, \
      httpheaders=httpheaders, proxy=proxy, timeout=timeout)

  try:
    return httpobj.read()
  finally:
    httpobj.close()




class _httpretrieve_filelikeobject:

  def __init__(self, sock, headers, httpstatus):
    self._sockobj = sock

    self._fileobjclosed = False

    self._totalcontentisreceived = False

    self._totalread = 0

    self.headers = headers

    self.httpstatus = httpstatus



  def read(self, limit=None, timeout=None):
    """
    <Purpose>
      Behaves like Python's file.read(), with the potential to raise
      additional informative exceptions.

    <Arguments>
      limit (optional):
            The maximum amount of data to read. If omitted or None, this
            reads all available data.

    <Exceptions>
      See file.read()'s documentation, as well as that of
      httpretrieve_open().

    <Side Effects>
      None.

    <Returns>
      See file.read().
    """

    if self._fileobjclosed:
      raise ValueError("I/O operation on closed file")

    if self._totalcontentisreceived:
      return ''

    lefttoread = None
    if limit is not None:
      lefttoread = limit

      if type(limit) is not int:
        raise TypeError("Expected an integer or None for read() limit")
      elif limit < 0:
        raise ValueError("Expected a non-negative integer for read() limit")

    if timeout is None:
      self._sockobj.settimeout(0)
    else:
      self._sockobj.settimeout(timeout)

    httpcontentstr = ''
    while True:
      try:
        contentchunkstr = self._sockobj.recv(lefttoread or 4096)
      except Exception, e:
        if str(e) == "Socket closed":
          self._totalcontentisreceived = True
          break
        else:
          raise
      
      httpcontentstr += contentchunkstr
      self._totalread += len(contentchunkstr)
      if limit is not None:
        if len(contentchunkstr) == lefttoread:
          break
        else:
          lefttoread -= len(contentchunkstr)
      if contentchunkstr == "":
        self._totalcontentisreceived = True
        break

    return httpcontentstr



  def close(self):
    """
    <Purpose>
      Close the file-like object.

    <Arguments>
      None

    <Exceptions>
      None

    <Side Effects>
      Disconnects from the HTTP server.

    <Returns>
      Nothing
    """
    self._fileobjclosed = True
    self._sockobj.close()




def _httpserver_put_in_headerdict(res, lastheader, lastheader_str):
  if lastheader is not None:
    if lastheader not in res:
      res[lastheader] = []
    res[lastheader].append(lastheader_str.strip())




def _httpretrieve_parse_responseheaders(headerlines):


  lastheaderkeystr = None
  lastheadervaluestr = ""

  resdict = {}
  
  if len(headerlines) == 0:
    return {}

  try:
    for i in range(len(headerlines)):
      if headerlines[i][0] in (" ", "\t") and lastheaderkeystr is not None:
        lastheadervaluestr += headerlines[i]
      else:
        _httpserver_put_in_headerdict(resdict, lastheaderkeystr, lastheadervaluestr)
        lastheaderkeystr, lastheadervaluestr = headerlines[i].split(":", 1)

    _httpserver_put_in_headerdict(resdict, lastheaderkeystr, lastheadervaluestr)

    return resdict

  except IndexError, idx:
    raise HttpBrokenServerError("Server returned garbage for HTTP" + \
        " response. Bad headers.")




def _httpretrieve_build_request(host, port, path, querydata, postdata, \
    httpheaders, proxy):

  if path == "":
    raise ValueError("Invalid path -- empty string.")
  if postdata is not None and type(postdata) not in (str, dict):
    raise TypeError("Postdata should be a dict of form-data or a string")
  if querydata is not None and type(querydata) not in (str, dict):
    raise TypeError("Querydata should be a dict of form-data or a string")
  if httpheaders is not None and type(httpheaders) is not dict:
    raise TypeError("Expected HTTP headers as a dictionary.")

  if type(querydata) is dict:
    querydata = urllib_quote_parameters(querydata)
  elif querydata is None:
    querydata = ""

  if type(postdata) is dict:
    postdata = urllib_quote_parameters(postdata)

  methodstr = "GET"
  if postdata is not None:
    methodstr = "POST"

  resourcestr = querydata
  if querydata != "":
    resourcestr = "?" + resourcestr

  if proxy is not None:
    requeststr = methodstr + ' http://' + host + ':' + str(port) + path + resourcestr + ' HTTP/1.0\r\n'
  else:
    requeststr = methodstr + ' ' + path + resourcestr + ' HTTP/1.0\r\n'
    
  if httpheaders is not None:
    if "Host" not in httpheaders:
      requeststr += "Host: " + host + ':' + str(port) + "\r\n"

    for key, val in httpheaders.items():
      requeststr += key + ": " + val + '\r\n'

  if methodstr == "POST":
    requeststr += 'Content-Length: ' + str(len(postdata)) + '\r\n'

  requeststr += '\r\n'

  if methodstr == "POST":
    requeststr += postdata

  return requeststr




def _httpretrieve_sendall(sockobj, datastr):
  while len(datastr) > 0:
    datastr = datastr[sockobj.send(datastr):]

"""
<Program Name>
  $Id: xmlrpc_common.repy 3260 2009-12-09 18:26:31Z cemeyer $

<Started>
  April 26, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Provides common methods related to XML-RPC.

  Encoding dateTime.iso8601 are not currently supported.

<Changes>

  2009-04-26  Michael Phan-Ba  <mdphanba@gmail.com>

  * Initial release

  2009-05-24  Michael Phan-Ba  <mdphanba@gmail.com>

  * Added change log
  * Fixed base64 name error
  * Set property svn:keyword to "Id" 

"""


"""
<Program Name>
  $Id: base64.repy 2527 2009-07-26 22:48:38Z cemeyer $

<Started>
  April 12, 2009

<Author>
  Michael Phan-Ba

<Purpose>
  Provides data encoding and decoding as specified in RFC 3548. This
  module implements a subset of the Python module base64 interface.

  b32encode(), b32decode(), b16encode(), b16decode(), decode(),
  decodestring(), encode(), and encodestring() are not currently
  implemented.

<Changes>

  2009-04-12  Michael Phan-Ba  <mdphanba@gmail.com>

  * Initial release

  2009-05-23  Michael Phan-Ba  <mdphanba@gmail.com>

  * (b64encode, b64decode, standard_b64encode, standard_b64decode,
    urlsafe_encode, urlsafe_decode): Renamed functions with base64 prefix

  2009-05-24  Michael Phan-Ba  <mdphanba@gmail.com>

  * Set property svn:keyword to "Id" 

"""

BASE64_ALPHABET = \
  "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"

def base64_b64encode(s, altchars=None):
  """
  <Purpose>
    Encode a string using Base64.

  <Arguments>
    s:
      The string to encode.

    altchars:
      An optional string of at least length 2 (additional characters are
      ignored) which specifies an alternative alphabet for the + and /
      characters.  The default is None, for which the standard Base64
      alphabet is used.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The encoded string.

  """
  if altchars is None:
    base64_alphabet = BASE64_ALPHABET
  else:
    base64_alphabet = BASE64_ALPHABET[:62] + altchars

  bytes = []
  for x in s:
    bytes.append(ord(x))

  x6bit_words = []
  index = 0
  while True:

    try:
      x8bits = bytes[index]
    except IndexError:
      break
    else:
      x6bits = x8bits >> 2
      leftover_bits = x8bits & 3
      x6bit_words.append(base64_alphabet[x6bits])

    try:
      x8bits = bytes[index + 1]
    except IndexError:
      x6bits = leftover_bits << 4
      x6bit_words.extend([base64_alphabet[x6bits], "=="])
      break
    else:
      x6bits = (leftover_bits << 4) | (x8bits >> 4)
      leftover_bits = x8bits & 15
      x6bit_words.append(base64_alphabet[x6bits])

    try:
      x8bits = bytes[index + 2]
    except IndexError:
      x6bits = leftover_bits << 2
      x6bit_words.extend([base64_alphabet[x6bits], "="])
      break
    else:
      x6bits = (leftover_bits << 2) | (x8bits >> 6)
      x6bit_words.append(base64_alphabet[x6bits])
      x6bits = x8bits & 63
      x6bit_words.append(base64_alphabet[x6bits])

    index += 3

  return "".join(x6bit_words)

def base64_b64decode(s, altchars=None):
  """
  <Purpose>
    Decode a Base64 encoded string.  The decoder ignores all non
    characters not in the Base64 alphabet for compatibility with the
    Python library.  However, this introduces a security loophole in
    which covert or malicious data may be passed.

  <Arguments>
    s:
      The string to decode.

    altchars:
      An optional string of at least length 2 (additional characters are
      ignored) which specifies an alternative alphabet for the + and /
      characters.  The default is None, for which the standard Base64
      alphabet is used.

  <Exceptions>
    None.

  <Side Effects>
    TypeError on decoding error.

  <Returns>
    The decoded string.

  """
  if altchars is None:
    base64_alphabet = BASE64_ALPHABET
  else:
    base64_alphabet = BASE64_ALPHABET[:62] + altchars

  translate_chars = []
  for x in xrange(256):
    char = chr(x)
    translate_chars.append(char)

  delete_chars = []
  for x in translate_chars:
    if x not in base64_alphabet:
      delete_chars.append(x)
  delete_chars = "".join(delete_chars)

  k = 0
  for v in base64_alphabet:
    translate_chars[ord(v)] = chr(k)
    k += 1
  translate_chars = "".join(translate_chars)

  num_pad = 0
  i = len(s) - 1
  while i >= 0:
    if s[i] == "=":
      num_pad += 1
    else:
      break
    i -= 1

  s = s.translate(translate_chars, delete_chars)

  align = (4 - (len(s) & 3)) & 3
  if align == 3:
    raise TypeError("Incorrectly encoded base64 data (has 6 bits of trailing garbage)")
  if align > num_pad:
    pass

  x6bit_words = []
  for x in s:
    x6bit_words.append(ord(x))
  for x in xrange(align):
    x6bit_words.append(-1)

  bytes = []
  index = 0
  while True:

    try:
      (x6bits1, x6bits2, x6bits3, x6bits4) = x6bit_words[index:index + 4]
    except ValueError:
      break

    bytes.append((x6bits1 << 2) | (x6bits2 >> 4))

    if x6bits3 < 0:
      break

    bytes.append(((x6bits2 & 15) << 4) | (x6bits3 >> 2))

    if x6bits4 < 0:
      break

    bytes.append(((x6bits3 & 3) << 6) | x6bits4)

    index += 4

  return "".join([chr(x) for x in bytes])

def base64_standard_b64encode(s):
  """
  <Purpose>
    Encode a string using the standard Base64 alphabet.

  <Arguments>
    s:
      The string to encode.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The encoded string.

  """
  return base64_b64encode(s)

def base64_standard_b64decode(s):
  """
  <Purpose>
    Decode a Base64 encoded string using the standard Base64 alphabet.

  <Arguments>
    s:
      The string to decode.

  <Exceptions>
    None.

  <Side Effects>
    TypeError on decoding error.

  <Returns>
    The decoded string.

  """
  return base64_b64decode(s)


def base64_urlsafe_b64encode(s):
  """
  <Purpose>
    Encode a string using a URL-safe alphabet, which substitutes -
    instead of + and _ instead of / in the standard Base64 alphabet.

  <Arguments>
    s:
      The string to encode.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The encoded string.

  """
  return base64_b64encode(s, "-_")


def base64_urlsafe_b64decode(s):
  """
  <Purpose>
    Decode a Base64 encoded string using a URL-safe alphabet, which
    substitutes - instead of + and _ instead of / in the standard Base64
    alphabet.

  <Arguments>
    s:
      The string to decode.

  <Exceptions>
    None.

  <Side Effects>
    TypeError on decoding error.

  <Returns>
    The decoded string.

  """
  return base64_b64decode(s, "-_")

"""
<Program Name>
  xmlparse.repy

<Started>
  April 2009

<Author>
  Conrad Meyer <cemeyer@u.washington.edu>

<Purpose>
  Provide a relatively simplistic but usable xml parsing library for
  RePy.
"""

class xmlparse_XMLParseError(Exception):
  """Exception raised when an error is encountered parsing the XML."""
  pass




class xmlparse_XMLTreeNode:
  """
  <Purpose>
    Provide a simple tree structure for XML data.

  <Exceptions>
    None.

  <Example Use>
    node = xmlparse_parse("<Some><xml><data></data></xml></Some>")
  """   


  def __init__(self, tag_name):
    self.tag_name = tag_name
    self.children = None
    self.content = None
    self.attributes = {}


  def __repr__(self):
    """Provide a pretty representation of an XML tree."""

    if self.content is not None:
      return "%s:\"%s\"" % (self.tag_name, self.content)
    else:
      return "%s:%s" % (self.tag_name, str(self.children))


  def to_string(self):
    result = "<" + self.tag_name
    for attribute_name in self.attributes.keys():
      attribute_value_escaped = \
          self.attributes[attribute_name].replace("\"", "\\\"")
      result += " " + attribute_name + "=\"" + attribute_value_escaped + "\""
    
    if self.content is None:
      result += ">"
      for childnode in self.children:
        result += childnode.to_string()
      result += "</" + self.tag_name + ">"
    else:
      if len(self.content) == 0:
        result += "/>"
      else:
        result += ">" + self.content + "</" + self.tag_name + ">"

    return result




def xmlparse_parse(data):
  """
  <Purpose>
    Parses an XML string into an xmlparse_XMLTreeNode containing the root
    item.

  <Arguments>
    data:
           The data to parse.

  <Exceptions>
    xmlparse_XMLParseError if parsing fails.

  <Side Effects>
    None.

  <Returns>
    An xmlparse_XMLTreeNode tree.
  """

  data = data.lstrip()
  if data.startswith("<?xml"):
    data = data[data.find("?>")+2:]
  
  parsed_elements = _xmlparse_parse(data)
  if len(parsed_elements) != 1:
    raise xmlparse_XMLParseError("XML response from server contained more than one root node")

  return parsed_elements[0]




def _xmlparse_read_attributes(string):



  state_EXPECTING_ATTRNAME = 1
  state_READING_ATTRNAME = 2
  state_EXPECTING_ATTRVALUE = 3
  state_READING_ATTRVALUE_SINGLEQUOTE = 4
  state_READING_ATTRVALUE_DOUBLEQUOTE = 5

  current_position = 0
  current_state = 1
  current_attrname = ""
  current_attrvalue = ""
  attributes = {}

  while True:
    if current_position >= len(string):
      raise xmlparse_XMLParseError(
          "Failed to parse element attribute list -- input ran out " + \
              "before we found a closing '>' or '/'")

    current_character = string[current_position]

    if current_state == state_EXPECTING_ATTRNAME:
      if current_character.isspace():
        pass    # We stay in this state
      elif current_character == '>' or current_character == '/':
        return (attributes, string[current_position:])
      else:
        current_attrname += current_character
        current_state = state_READING_ATTRNAME

    elif current_state == state_READING_ATTRNAME:
      if current_character.isspace():
        raise xmlparse_XMLParseError(
            "Failed to parse element attribute list -- attribute " + \
                "ended unexpectedly with a space")
      elif current_character == "=":
        current_state = state_EXPECTING_ATTRVALUE
      else:
        current_attrname += current_character

    elif current_state == state_EXPECTING_ATTRVALUE:
      if current_character == '\'':
        current_state = state_READING_ATTRVALUE_SINGLEQUOTE
      elif current_character == '"':
        current_state = state_READING_ATTRVALUE_DOUBLEQUOTE
      else:
        raise xmlparse_XMLParseError(
            "Failed to parse element attribute list -- attribute " + \
                "values must be quoted")

    elif current_state == state_READING_ATTRVALUE_SINGLEQUOTE:
      if current_character == '\'':
        attributes[current_attrname] = current_attrvalue
        current_state = state_EXPECTING_ATTRNAME
        current_attrname = ""
        current_attrvalue = ""
      else:
        current_attrvalue += current_character

    elif current_state == state_READING_ATTRVALUE_DOUBLEQUOTE:
      if current_character == '"':
        attributes[current_attrname] = current_attrvalue
        current_state = state_EXPECTING_ATTRNAME
        current_attrname = ""
        current_attrvalue = ""
      else:
        current_attrvalue += current_character

    current_position += 1




def _xmlparse_node_from_string(string):

  string = string.lstrip()
  if not string.startswith("<"):
    raise xmlparse_XMLParseError("Error parsing XML -- doesn't " + \
        "start with '<'")

  string = string[1:]

  read_pos = 0
  while True:
    if read_pos >= len(string):
      raise xmlparse_XMLParseError("Error parsing XML -- parser " + \
          "ran out of input trying to read a tag")

    curchar = string[read_pos]
    if curchar.isspace() or curchar == ">" or curchar == "/":
      break

    read_pos += 1

  tag = string[0:read_pos]
  string = string[read_pos:]

  attributes, string = _xmlparse_read_attributes(string)

  empty_element = False
  if string.startswith(">"):
    string = string[1:]
  elif string.startswith("/>"):
    string = string[2:]
    empty_element = True

  xmlnode = xmlparse_XMLTreeNode(tag)
  xmlnode.attributes = attributes

  if empty_element:
    xmlnode.content = ""

  else:
    ending_tag_position = string.rfind("</")
    if ending_tag_position < 0:
      raise xmlparse_XMLParseError("XML parse error -- could not " + \
          "locate closing tag")

    if not string.startswith("</" + tag, ending_tag_position):
      raise xmlparse_XMLParseError("XML parse error -- different " + \
          "opening / closing tags at the same nesting level")

    tag_body = string[:ending_tag_position]
    if tag_body.lstrip().startswith("<"):
      xmlnode.children = _xmlparse_parse(tag_body.lstrip())
    else:
      xmlnode.content = tag_body

  return xmlnode




def _xmlparse_find_next_tag(xmldata):

  read_position = 0
  nested_depth = 0

  original_length = len(xmldata)
  xmldata = xmldata.lstrip()
  length_difference = original_length - len(xmldata)

  while True:
    if xmldata.startswith("</", read_position) or \
        xmldata.startswith("/>", read_position):
      nested_depth -= 1
    elif xmldata.startswith("<", read_position):
      nested_depth += 1

    read_position += 1

    if read_position >= len(xmldata):
      return read_position + length_difference

    if nested_depth == 0:
      nexttagposition = xmldata.find("<", read_position)

      if nexttagposition < 0:
        return original_length
      else:
        return nexttagposition + length_difference




def _xmlparse_parse(xmldata):

  nodelist = []

  while True:
    xmldata = xmldata.strip()

    if xmldata.startswith("<!--"):
      commentendloc = xmldata.find("-->", 4)
      if commentendloc < 0:
        raise xmlparse_XMLParseError("XML parse error -- comment " + \
            "missing close tag ('-->')")
      xmldata = xmldata[commentendloc+3:]
      continue

    nexttagend = _xmlparse_find_next_tag(xmldata)

    thisnode_str = xmldata[0:nexttagend]
    xmldata = xmldata[nexttagend:]

    thisnode = _xmlparse_node_from_string(thisnode_str)
    nodelist.append(thisnode)

    if not xmldata.strip().startswith("<"):
      break

  return nodelist






class xmlrpc_common_Binary(object):
  """
  <Purpose>
    Wrapper class for base64-encoded binary data in XML-RPC requests and
    responses.  This class is used when sending and receiving binary
    data through XML-RPC.

  <Side Effects>
    None.

  <Example Use>
    blob = xmlrpc_common_Binary("\x00\x01\x00")

  """

  def __init__(self, data=""):
    """
    <Purpose>
      Create a new Binary wrapper object for use with the XML-RPC
      libraries.

    <Arguments>
      data:
        The unencoded binary data.

    <Exceptions>
      None.

    """
    self.data = data





class xmlrpc_common_Fault(ValueError):
  """
  <Purpose>
    Exception representing a XML-RPC Fault.  The exception is returned
    by the parsing functions when a XML-RPC server returns a fault.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_Fault("An error occurred", -1)

  """

  def __init__(self, message, code):
    """
    <Purpose>
      Create a new Fault exception.

    <Arguments>
      message:
        A string describing the fault.

      code:
        The integer code associated with the fault.

    <Exceptions>
      None.

    """
    self.strerror = message
    self.code = code
    ValueError.__init__(self, message)





class xmlrpc_common_Timeout(Exception):
  """
  <Purpose>
    Exception representing a normal timeout occuring.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_Timeout()

  """





class xmlrpc_common_XMLParseError(ValueError):
  """
  <Purpose>
    Exception representing an error in parsing XML-RPC data.  The
    exception is thrown when bad XML data is encountered.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_XMLParseError()

  """





class xmlrpc_common_ConnectionError(ValueError):
  """
  <Purpose>
    Exception representing an error in the connection to an XMLRPC server.
    Thrown when the server closes the connection unexpectedly.

  <Side Effects>
    None.

  <Example Use>
    raise xmlrpc_common_ConnectionError()

  """





def xmlrpc_common_call2xml(method_name, params):
  """
  <Purpose>
    Build a XML-RPC method call to send to a XML-RPC server.

  <Arguments>
    method_name:
      The method name.

    params:
      A sequence type of XML-RPC parameters.  A dictionary may also be
      passed, but the keys are ignored.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC method call string.

  """
  xml_string = ['<?xml version="1.0"?>',
    "<methodCall><methodName>%s</methodName>" % method_name,
    _xmlrpc_common_params2xml(params),
    "</methodCall>"]

  return "".join(xml_string)


def xmlrpc_common_response2xml(param):
  """
  <Purpose>
    Build a XML-RPC method response to send to a XML-RPC client.  This
    is the XML document that represents the return values or fault from
    a XML-RPC call.

  <Arguments>
    param:
      The value to be returned.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC method response string.

  """
  xml_string = ['<?xml version="1.0"?><methodResponse>',
    _xmlrpc_common_params2xml((param,)),
    "</methodResponse>"]

  return "".join(xml_string)


def xmlrpc_common_fault2xml(message, code):
  """
  <Purpose>
    Build a XML-RPC fault response to send to a XML-RPC client.  A fault
    response can occur from a server failure, an incorrectly generated
    XML request, or bad program arguments.

  <Arguments>
    message:
      A string describing the fault.

    code:
      The integer code associated with the fault.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC fault response string.

  """
  struct = {"faultCode": code, "faultString": message}
  xml_string = ['<?xml version="1.0"?><methodResponse><fault>',
    _xmlrpc_common_value2xml(struct),
    "</fault></methodResponse>"]

  return "".join(xml_string)


def _xmlrpc_common_params2xml(params):
  """
  <Purpose>
    Translate Python parameter values to XML-RPC for use in building a
    XML-RPC request or response.

  <Arguments>
    params:
      A sequence type of XML-RPC parameters.  A dictionary may also be
      passed, but the keys are ignored.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC parameters string.

  """
  if params is None or params is ():
    return ""

  xml_string = ["<params>"]

  for param in params:
    xml_string.append("<param>%s</param>" % _xmlrpc_common_value2xml(param))

  xml_string.append("</params>")

  return "".join(xml_string)


def _xmlrpc_common_value2xml(obj):
  """
  <Purpose>
    Translate a Python value to XML-RPC for use in building the params
    portion of a request or response.

  <Arguments>
    obj:
      The Python object to convert.

  <Exceptions>
    None.

  <Side Effects>
    None.

  <Returns>
    The XML-RPC value string.

  """
  object_type = type(obj)

  xml_string = ["<value>"]

  if obj is None:
    xml_string.append("<nil/>")

  elif object_type is bool:
    xml_string.append("<boolean>%d</boolean>" % int(obj))

  elif object_type in (int, long):
    xml_string.append("<int>%d</int>" % obj)

  elif object_type is float:
    xml_string.append("<double>%f</double>" % obj)

  elif object_type in (str, unicode, basestring):
    xml_string.append("<string>%s</string>" % obj)

  elif object_type in (list, tuple, xrange, set, frozenset):
    xml_string.append("<array><data>")
    for value in obj:
      xml_string.append(_xmlrpc_common_value2xml(value))
    xml_string.append("</data></array>")

  elif object_type is dict:
    xml_string.append("<struct>")
    for key, value in obj.iteritems():
      xml_string.append("<member><name>%s</name>" % key)
      xml_string.append(_xmlrpc_common_value2xml(value))
      xml_string.append("</member>")
    xml_string.append("</struct>")

  elif object_type is xmlrpc_common_Binary:
    xml_string.append("<base64>%s</base64>" % base64_standard_b64encode(obj.data))

  else:
    raise ValueError("Marshaller: Unsupported type '%s'" % type(obj))

  xml_string.append("</value>")

  return "".join(xml_string)


def xmlrpc_common_call2python(xml):
  """
  <Purpose>
    Convert a XML-RPC method call to its Python equivalent.

    The request from a XML-RPC client is parsed into native Python
    types so that the server may use the data to execute a method, as
    appropriate.

  <Arguments>
    xml:
      The XML-RPC string to convert.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.
    xmlparse_XMLParseError on a general XML parse error.

  <Side Effects>
    None.

  <Returns>
    A tuple containing (1) the method name and (2) a list of the
    parameters.

  """
  xml_node = xmlparse_parse(xml)

  if xml_node.tag_name != "methodCall":
    message = "Unexpected root node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)
  elif xml_node.children is None:
    raise xmlrpc_common_XMLParseError("No parameters found")
  elif len(xml_node.children) > 2:
    raise xmlrpc_common_XMLParseError("Too many children for 'methodCall'")

  try:
    method_name_node = xml_node.children[0]
    if method_name_node.tag_name != "methodName":
      message = "Unexpected XML node: %s" % method_name_node.tag_name
      raise xmlrpc_common_XMLParseError(message)
    method_name = method_name_node.content
  except IndexError:
    raise xmlrpc_common_XMLParseError("No method name found")

  try:
    params = _xmlrpc_common_params2python(xml_node.children[1])
  except IndexError:
    return (method_name, ())

  if not params:
    raise xmlrpc_common_XMLParseError("No parameters found")

  return (method_name, params)


def xmlrpc_common_response2python(xml):
  """
  <Purpose>
    Convert a XML-RPC method response to its Python equivalent.

    The response from a XML-RPC server is parsed into native Python
    types so that the client may use the data as appropriate.

  <Arguments>
    xml:
      The XML-RPC string to convert.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.
    xmlparse_XMLParseError on a general XML parse error.

  <Side Effects>
    None.

  <Returns>
    The method results or a xmlrpc_common_Fault on reading a fault.

  """
  xml_node = xmlparse_parse(xml)

  if xml_node.tag_name != "methodResponse":
    message = "Unexpected root node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)
  elif xml_node.children is None:
    raise xmlrpc_common_XMLParseError("No parameters found")
  elif len(xml_node.children) > 1:
    raise xmlrpc_common_XMLParseError("Too many children for 'methodCall'")

  fault_node = xml_node.children[0]
  if fault_node.tag_name == "fault":
    if fault_node.children is None:
      raise xmlrpc_common_XMLParseError("No children found for 'fault'")
    elif len(fault_node.children) != 1:
      raise xmlrpc_common_XMLParseError("Too many children for 'fault'")
    params = _xmlrpc_common_value2python(fault_node.children[0])
    try:
      return xmlrpc_common_Fault(params["faultString"], params["faultCode"])
    except KeyError:
      raise xmlrpc_common_XMLParseError("Invalid fault object")

  try:
    params = _xmlrpc_common_params2python(xml_node.children[0])
  except KeyError:
    raise xmlrpc_common_XMLParseError("No parameters found")

  if len(params) != 1:
    raise xmlrpc_common_XMLParseError("Too many children for 'params'")

  return params[0]


def _xmlrpc_common_params2python(xml_node):
  """
  <Purpose>
    Convert XML-RPC params the Python equivalent.

    The parameters portion of a XML-RPC request or response is parsed
    into Python equivalents so that the method request and response
    parsing functions can return the relevant data.

  <Arguments>
    xml_node:
      The XML node to consider.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.

  <Side Effects>
    None.

  <Returns>
    The method results.

  """
  if xml_node.tag_name != "params":
    message = "Unexpected XML node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)

  if xml_node.children is None or len(xml_node.children) < 1:
    return []

  params = []

  for param_node in xml_node.children:
    if param_node.tag_name != "param":
      message = "Unexpected XML node: %s" % param_node.tag_name
      raise xmlrpc_common_XMLParseError(message)
    elif param_node.children is None:
      raise xmlrpc_common_XMLParseError("Unexpected empty param node")
    elif len(param_node.children) > 1:
      raise xmlrpc_common_XMLParseError("Too many children for 'param'")
    params.append(_xmlrpc_common_value2python(param_node.children[0]))

  return params


def _xmlrpc_common_value2python(xml_node):
  """
  <Purpose>
    Convert a XML-RPC value the Python equivalent.

    A XML-RPC value is converted to its Python equivalent for use in the
    parameters parser.

  <Arguments>
    xml_node:
      The XML node to consider.

  <Exceptions>
    xmlrpc_common_XMLParseError on a XML-RPC structural parse error.

  <Side Effects>
    None.

  <Returns>
    The method results.

  """

  if xml_node.tag_name not in ("value",):
    message = "Unexpected XML node: %s" % xml_node.tag_name
    raise xmlrpc_common_XMLParseError(message)

  elif xml_node.children is not None and len(xml_node.children) > 1:
    raise xmlrpc_common_XMLParseError("Too many children for 'value'")

  value_node = xml_node

  tag = "string"
  if xml_node.children is not None:
    value_node = xml_node.children[0]
    tag = value_node.tag_name

  value = value_node.content

  if tag == "nil":
    return None

  elif tag == "boolean":
    return bool(int(value))

  elif tag in ("i4", "int"):
    return int(value)

  elif tag == "double":
    return float(value)

  elif tag == "string":
    return value

  elif tag == "array":
    if len(value_node.children) > 1:
      raise xmlrpc_common_XMLParseError("Too many children for 'array'")
    data_node = value_node.children[0]
    result = []
    if data_node.children:
      for item_node in data_node.children:
        result.append(_xmlrpc_common_value2python(item_node))
    return result

  elif tag == "struct":
    result = {}

    for member_node in value_node.children:
      if len(member_node.children) != 2:
        message = "Incorrect number of children for 'member'"
        raise xmlrpc_common_XMLParseError(message)

      key = member_node.children[0].content
      value = _xmlrpc_common_value2python(member_node.children[1])

      result[key] = value

    return result

  elif tag == "base64":
    return xmlrpc_common_Binary(base64_standard_b64decode(value_node.content))

  else:
    message = "Demarshaller: Unsupported value type: %s" % value_node.tag_name
    raise xmlrpc_common_XMLParseError(message)



class xmlrpc_client_Client(object):
  """
  <Purpose>
    XML-RPC client implementation.

  <Side Effects>
    None.

  <Example Use>
    client = xmlrpc_client_Client("http://phpxmlrpc.sourceforge.net/server.php")
    print client.send_request("examples.getStateName", (1,))

  """


  USER_AGENT = "seattlelib/1.0.0"


  def __init__(self, url):
    """
    <Purpose>
      Create a new XML-RPC Client object to do RPC calls to the given
      server.

    <Arguments>
      url:
        A url containing the hostname, port, and path of the xmlrpc
        server. For example, "http://phpxmlrpc.soureforge.net/server.php".

    <Exceptions>
      None.

    """

    if not isinstance(url, (str, unicode)):
      raise ValueError("Invalid argument: url must be a URL string")

    urlcomponents = urlparse_urlsplit(url, "http", False)

    self.server_host = urlcomponents["hostname"]
    self.server_port = urlcomponents["port"] or 80
    self.server_path = urlcomponents["path"] or "/"
    if urlcomponents["query"]:
      self.server_path += "?" + urlcomponents["query"]

    if not self.server_host:
      raise ValueError("Invalid argument: url must have a valid host")


  def send_request(self, method_name, params, timeout=None):
    """
    <Purpose>
      Send a XML-RPC request to a XML-RPC server to do a RPC call.

    <Arguments>
      method_name:
        The method name.

      params:
        The method parameters.

    <Exceptions>
      socket.error on socket errors, including server timeouts.
      xmlrpc_common_Fault on a XML-RPC response fault.
      xmlrpc_common_XMLParseError on a XML-RPC structural parse error.
      xmlparse_XMLParseError on a general XML parse error.
      xmlrpc_common_ConnectionError on unexpected disconnects.
      xmlrpc_common_Timeout if the time limit is exceeded.

    <Side Effects>
      None.

    <Returns>
      The XML-RPC method return values.

    """

    starttime = getruntime()

    request_xml = xmlrpc_common_call2xml(method_name, params)

    response = httpretrieve_get_string("http://%s:%s%s" % (self.server_host, \
        self.server_port, self.server_path), postdata=request_xml, \
        timeout=timeout, httpheaders={\
        "User-Agent": self.USER_AGENT, "Content-Type": "text/xml"})

    if timeout is not None and getruntime() - starttime > timeout:
      raise xmlrpc_common_Timeout()

    response_value = xmlrpc_common_response2python(response)

    if isinstance(response_value, xmlrpc_common_Fault):
      raise response_value

    return response_value

""" 
Author: Justin Cappos

Module: A parallelization module.   It performs actions in parallel to make it
        easy for a user to call a function with a list of tasks.

Start date: November 11th, 2008

This module is adapted from code in seash which had similar functionality.

NOTE (for the programmer using this module).   It's really important to 
write concurrency safe code for the functions they provide us.  It will not 
work to write:

def foo(...):
  mycontext['count'] = mycontext['count'] + 1

YOU MUST PUT A LOCK AROUND SUCH ACCESSES.

"""


""" 
Author: Justin Cappos

Module: A simple library that provides a unique ID for each call

Start date: November 11th, 2008

This is a really, really simple module, only broken out to avoid duplicating 
functionality.

NOTE: This will give unique ids PER FILE.   If you have multiple python 
modules that include this, they will have the potential to generate the
same ID.

"""

uniqueid_idlist = [0]
uniqueid_idlock = getlock()

def uniqueid_getid():
  """
   <Purpose>
      Return a unique ID in a threadsafe way

   <Arguments>
      None

   <Exceptions>
      None

   <Side Effects>
      None.

   <Returns>
      The ID (an integer)
  """

  uniqueid_idlock.acquire()

  myid = uniqueid_idlist[0]
  uniqueid_idlist[0] = uniqueid_idlist[0] + 1

  uniqueid_idlock.release()

  return myid






class ParallelizeError(Exception):
  """An error occurred when operating on a parallelized task"""


parallelize_info_dict = {}



def parallelize_closefunction(parallelizehandle):
  """
   <Purpose>
      Clean up the state created after calling parallelize_initfunction.

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          

   <Exceptions>
      None

   <Side Effects>
      Will try to abort future functions if possible

   <Returns>
      True if the parallelizehandle was recognized or False if the handle is
      invalid or already closed.
  """

  try:
    del parallelize_info_dict[parallelizehandle]
  except KeyError:
    return False
  else:
    return True

    



def parallelize_abortfunction(parallelizehandle):
  """
   <Purpose>
      Cause pending events for a function to abort.   Events will finish 
      processing their current event.

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          

   <Exceptions>
      ParallelizeError is raised if the handle is unrecognized

   <Side Effects>
      None

   <Returns>
      True if the function was not previously aborting and is now, or False if 
      the function was already set to abort before the call.
  """

  
  try:
    if parallelize_info_dict[parallelizehandle]['abort'] == False:
      parallelize_info_dict[parallelizehandle]['abort'] = True
      return True
    else:
      return False
  except KeyError:
    raise ParallelizeError("Cannot abort the parallel execution of a non-existent handle:"+str(parallelizehandle))



def parallelize_isfunctionfinished(parallelizehandle):
  """
   <Purpose>
      Indicate if a function is finished

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          

   <Exceptions>
      ParallelizeError is raised if the handle is unrecognized

   <Side Effects>
      None

   <Returns>
      True if the function has finished, False if it is still has events running
  """

  
  try:
    if parallelize_info_dict[parallelizehandle]['runninglist']:
      return False
    else:
      return True
  except KeyError:
    raise ParallelizeError("Cannot get status for the parallel execution of a non-existent handle:"+str(parallelizehandle))





def parallelize_getresults(parallelizehandle):
  """
   <Purpose>
      Get information about a parallelized function

   <Arguments>
      parallelizehandle:
         The handle returned by parallelize_initfunction
          
   <Exceptions>
      ParallelizeError is raised if the handle is unrecognized

   <Side Effects>
      None

   <Returns>
      A dictionary with the results.   The format is
        {'exception':list of tuples with (target, exception string), 
         'aborted':list of targets, 'returned':list of tuples with (target, 
         return value)}
  """

  
  try:
    return parallelize_info_dict[parallelizehandle]['result'].copy()
  except KeyError:
    raise ParallelizeError("Cannot get results for the parallel execution of a non-existent handle:"+str(parallelizehandle))



      



      


def parallelize_initfunction(targetlist, callerfunc,concurrentevents=5, *extrafuncargs):
  """
   <Purpose>
      Call a function with each argument in a list in parallel

   <Arguments>
      targetlist:
          The list of arguments the function should be called with.   Each
          argument is passed once to the function.   Items may appear in the
          list multiple times

      callerfunc:
          The function to call
 
      concurrentevents:
          The number of events to issue concurrently (default 5).   No more 
          than len(targetlist) events will be concurrently started.

      extrafuncargs:
          Extra arguments the function should be called with (every function
          is passed the same extra args).

   <Exceptions>
      ParallelizeError is raised if there isn't at least one free event.   
      However, if there aren't at least concurrentevents number of free events,
      this is not an error (instead this is reflected in parallelize_getstatus)
      in the status information.

   <Side Effects>
      Starts events, etc.

   <Returns>
      A handle used for status information, etc.
  """

  parallelizehandle = uniqueid_getid()

  handleinfo = {}
  handleinfo['abort'] = False
  handleinfo['callfunc'] = callerfunc
  handleinfo['callargs'] = extrafuncargs
  handleinfo['targetlist'] = targetlist[:]
  handleinfo['availabletargetpositions'] = range(len(handleinfo['targetlist']))
  handleinfo['result'] = {'exception':[],'returned':[],'aborted':[]}
  handleinfo['runninglist'] = []

  
  parallelize_info_dict[parallelizehandle] = handleinfo

  threads_to_start = min(concurrentevents, len(handleinfo['targetlist']))

  for workercount in range(threads_to_start):
    parallelize_info_dict[parallelizehandle]['runninglist'].append(workercount)
    try:
      settimer(0.0, parallelize_execute_function, (parallelizehandle,workercount))
    except:
      parallelize_info_dict[parallelizehandle]['runninglist'].remove(workercount)
      if not parallelize_info_dict[parallelizehandle]['runninglist']:
        parallelize_closefunction(parallelizehandle)
        raise Exception, "No events available!"
      break
  
  return parallelizehandle
    


def parallelize_execute_function(handle, myid):

  try:

    while True:
      thetargetlist = parallelize_info_dict[handle]['targetlist']
      try:
        mytarget = thetargetlist.pop()
      except IndexError:
        return

      if parallelize_info_dict[handle]['abort']:
        parallelize_info_dict[handle]['result']['aborted'].append(mytarget)

      else:

        callfunc = parallelize_info_dict[handle]['callfunc']
        callargs = parallelize_info_dict[handle]['callargs']

        try:
          retvalue = callfunc(mytarget,*callargs)
        except Exception, e:
          parallelize_info_dict[handle]['result']['exception'].append((mytarget,str(e)))
        else:
          parallelize_info_dict[handle]['result']['returned'].append((mytarget,retvalue))


  except KeyError:
    return

  except Exception, e:
    print 'Internal Error: Exception in parallelize_execute_function',e

  finally:
    try:
      parallelize_info_dict[handle]['runninglist'].remove(myid)
    except (ValueError, KeyError):
      pass
    

    




openDHTadvertise_context = {}
openDHTadvertise_context["proxylist"] = []
openDHTadvertise_context["currentproxy"] = None
openDHTadvertise_context["serverlist"] = []
openDHTadvertise_context["serverlistlock"] = getlock()

def openDHTadvertise_announce(key, value, ttlval, concurrentevents=5, proxiestocheck=5, timeout=None):
  """
  <Purpose>
    Announce a (key, value) pair to openDHT.

  <Arguments>
    key:
            The new key the value should be stored under.

    value:
            The value to associate with the given key.

    ttlval:
            The length of time (in seconds) to persist this key <-> value
            association in DHT.

    concurrentevents:
            The number of concurrent events to use when checking for
            functional openDHT proxies. Defaults to 5.

    proxiestocheck:
            The number of openDHT proxies to check. Defaults to 5.

  <Exceptions>
    Exception if the xmlrpc server behaves erratically.

  <Side Effects>
    The key <-> value association gets stored in openDHT for a while.

  <Returns>
    None.
  """

  value = str(value)[:]

  ttl = int(ttlval)

  if timeout is None:
    timeout = 10.0

  while True:
    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] == []:
      openDHTadvertise_context["proxylist"] = openDHTadvertise_get_proxy_list( \
          concurrentevents=concurrentevents, maxnumberofattempts=proxiestocheck)
      if openDHTadvertise_context["proxylist"] == []:
        return False


    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] != []:
      openDHTadvertise_context["currentproxy"] = openDHTadvertise_context["proxylist"][0]
      del openDHTadvertise_context["proxylist"][0]


    pxy = xmlrpc_client_Client(openDHTadvertise_context["currentproxy"])
    keytosend = xmlrpc_common_Binary(sha_new(str(key)).digest())
    valtosend = xmlrpc_common_Binary(value)

    try:
      pxy.send_request("put", (keytosend, valtosend, ttl, "put.py"), timeout=timeout)
      break
    except (xmlrpc_common_ConnectionError, xmlrpc_common_Timeout):
      openDHTadvertise_context["currentproxy"] = None

  return True




def openDHTadvertise_lookup(key, maxvals=100, concurrentevents=5, proxiestocheck=5, timeout=None):
  """
  <Purpose>
    Retrieve a stored value from openDHT.

  <Arguments>
    key:
            The key the value is stored under.

    maxvals:
            The maximum number of values stored under this key to
            return to the caller.

    concurrentevents:
            The number of concurrent events to use when checking for
            functional openDHT proxies. Defaults to 5.

    proxiestocheck:
            The number of openDHT proxies to check. Defaults to 5.

  <Exceptions>
    Exception if the xmlrpc server behaves erratically.

  <Side Effects>
    None.

  <Returns>
    The value stored in openDHT at key.
  """

  if timeout is None:
    timeout = 10.0

  while True:
    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] == []:
      openDHTadvertise_context["proxylist"] = openDHTadvertise_get_proxy_list( \
          concurrentevents=concurrentevents, maxnumberofattempts=proxiestocheck)
      if openDHTadvertise_context["proxylist"] == []:
        raise Exception, "Lookup failed"


    if openDHTadvertise_context["currentproxy"] == None and openDHTadvertise_context["proxylist"] != []:
      openDHTadvertise_context["currentproxy"] = openDHTadvertise_context["proxylist"][0]
      del openDHTadvertise_context["proxylist"][0]


    pxy = xmlrpc_client_Client(openDHTadvertise_context["currentproxy"])
    maxvalhash = int(maxvals)
    pm = xmlrpc_common_Binary("")
    keyhash = xmlrpc_common_Binary(sha_new(str(key)).digest())


    listofitems = []
    while openDHTadvertise_context["currentproxy"]:
      try:
        vals, pm = pxy.send_request("get", (keyhash, maxvalhash, pm, "get.py"), timeout=timeout)

        for item in vals:
          listofitems.append(item.data)

        if pm.data == "":
          return listofitems

      except (xmlrpc_common_ConnectionError, xmlrpc_common_Timeout):
        openDHTadvertise_context["currentproxy"] = None




def openDHTadvertise_checkserver(servername):
  for junkcount in range(3):
    s = openconn(servername, 5851, timeout=2.0)
    s.close()

  openDHTadvertise_context["serverlistlock"].acquire()
  try:
    openDHTadvertise_context["serverlist"].append(servername)
  finally:
    openDHTadvertise_context["serverlistlock"].release()




def openDHTadvertise_get_proxy_list(maxnumberofattempts=5, concurrentevents=5):
  """
  <Purpose>
    Gets a list of active openDHT proxies.

  <Arguments>
    maxnumberofattemps:
            Maximum number of servers to attempt to connect to.

    concurrentevents:
            Maximum number of events to use.

  <Exceptions>
    Exception if there are no servers in the server list.

  <Side Effects>
    Tries to connect to several proxies to see if they are online.

  <Returns>
    A list of openDHT approxies that appear to be up.
  """

  socket = openconn('www.cs.washington.edu', 80)
  try: 
    socket.send("GET /homes/arvind/servers.txt HTTP/1.0\r\nHost: www.cs.washington.edu\r\n\r\n")
  
    body = ""
    while True:
      try:
        newdata = socket.recv(4096)
      except:
        break
      if len(newdata) == 0:
        break   # Server finished sending us the response.
      body += newdata
  finally:
    socket.close()

  try:
    socket.close()
  except:
    pass

  headers, payload = body.split("\r\n\r\n", 1)
  lines = payload.split("\n")
  lines = lines[1:]
  servers = []
  for line in lines:
    if line.strip() == "":
      continue
    servers.append(line.split()[2])

  if len(servers) == 0:
    raise Exception, "No servers in server list"

  numberofattempts = min(len(servers), maxnumberofattempts)
  serverstocheck = random_sample(servers, numberofattempts)

  openDHTadvertise_context["serverlist"] = []

  parhandle = parallelize_initfunction(serverstocheck, openDHTadvertise_checkserver, concurrentevents=concurrentevents)

  while not parallelize_isfunctionfinished(parhandle):
    sleep(0.2)

  parallelize_closefunction(parhandle)


  retlist = []
  for serverip in openDHTadvertise_context["serverlist"]:
    retlist.append("http://"+serverip+":5851/")


  return retlist

""" 
Author: Justin Cappos

Start Date: July 8, 2008

Description:
Advertisements to a central server (similar to openDHT)


"""


class SessionEOF(Exception):
  pass

sessionmaxdigits = 20

def session_recvmessage(socketobj):

  messagesizestring = ''
  for junkcount in range(sessionmaxdigits):
    currentbyte = socketobj.recv(1)

    if currentbyte == '\n':
      break
    
    if currentbyte not in '0123456789' and messagesizestring != '' and currentbyte != '-':
      raise ValueError, "Bad message size"
     
    messagesizestring = messagesizestring + currentbyte

  else:
    raise ValueError, "Bad message size"

  messagesize = int(messagesizestring)
  
  if messagesize == 0:
    return ''

  if messagesize == -1:
    raise SessionEOF, "Connection Closed"

  if messagesize < 0:
    raise ValueError, "Bad message size"

  data = ''
  while len(data) < messagesize:
    chunk =  socketobj.recv(messagesize-len(data))
    if chunk == '': 
      raise SessionEOF, "Connection Closed"
    data = data + chunk

  return data

def session_sendhelper(socketobj,data):
  sentlength = 0
  while sentlength < len(data):
    thissent = socketobj.send(data[sentlength:])
    sentlength = sentlength + thissent



def session_sendmessage(socketobj,data):
  header = str(len(data)) + '\n'
  session_sendhelper(socketobj,header)

  session_sendhelper(socketobj,data)




"""
Author: Justin Cappos


Start date: October 9th, 2009

Purpose: A simple library that serializes and deserializes built-in repy types.
This includes strings, integers, floats, booleans, None, complex, tuples, 
lists, sets, frozensets, and dictionaries.

There are no plans for including objects.

Note: that all items are treated as separate references.   This means things
like 'a = []; a.append(a)' will result in an infinite loop.   If you have
'b = []; c = (b,b)' then 'c[0] is c[1]' is True.   After deserialization 
'c[0] is c[1]' is False.

I can add support or detection of this if desired.
"""




def serialize_serializedata(data):
  """
   <Purpose>
      Convert a data item of any type into a string such that we can 
      deserialize it later.

   <Arguments>
      data: the thing to seriailize.   Can be of essentially any type except
            objects.

   <Exceptions>
      TypeError if the type of 'data' isn't allowed

   <Side Effects>
      None.

   <Returns>
      A string suitable for deserialization.
  """


  if type(data) == type(None):
    return 'N'

  elif type(data) == type(True):
    if data == True:
      return 'BT'
    else:
      return 'BF'

  elif type(data) is int or type(data) is long:
    datastr = str(data) 
    return 'I'+datastr


  elif type(data) is float:
    datastr = str(data) 
    return 'F'+datastr


  elif type(data) is complex:
    datastr = str(data) 
    if datastr[0] == '(' and datastr[-1] == ')':
      datastr = datastr[1:-1]
    return 'C'+datastr



  elif type(data) is str:
    return 'S'+data


  elif type(data) is list or type(data) is tuple or type(data) is set or type(data) is frozenset:
    if type(data) is list:
      mystr = 'L'
    elif type(data) is tuple:
      mystr = 'T'
    elif type(data) is set:
      mystr = 's'
    elif type(data) is frozenset:
      mystr = 'f'
    else:
      raise Exception("InternalError: not a known type after checking")

    for item in data:
      thisitem = serialize_serializedata(item)
      mystr = mystr + str(len(thisitem))+":"+thisitem

    mystr = mystr + '0:'

    return mystr


  elif type(data) is dict:
    mystr = 'D'

    keysstr = serialize_serializedata(data.keys())
    mystr = mystr + str(len(keysstr))+":"+keysstr
    
    valuestr = serialize_serializedata(data.values())
    mystr = mystr + valuestr

    return mystr


  else:
    raise TypeError("Unknown type '"+str(type(data))+"' for data :"+str(data))



def serialize_deserializedata(datastr):
  """
   <Purpose>
      Convert a serialized data string back into its original types.

   <Arguments>
      datastr: the string to deseriailize.

   <Exceptions>
      ValueError if the string is corrupted
      TypeError if the type of 'data' isn't allowed

   <Side Effects>
      None.

   <Returns>
      Items of the original type
  """

  if type(datastr) != str:
    raise TypeError("Cannot deserialize non-string of type '"+str(type(datastr))+"'")
  typeindicator = datastr[0]
  restofstring = datastr[1:]


  if typeindicator == 'N':
    if restofstring != '':
      raise ValueError("Malformed None string '"+restofstring+"'")
    return None

  elif typeindicator == 'B':
    if restofstring == 'T':
      return True
    elif restofstring == 'F':
      return False
    raise ValueError("Malformed Boolean string '"+restofstring+"'")

  elif typeindicator == 'I':
    try:
      return int(restofstring) 
    except ValueError:
      raise ValueError("Malformed Integer string '"+restofstring+"'")


  elif typeindicator == 'F':
    try:
      return float(restofstring) 
    except ValueError:
      raise ValueError("Malformed Float string '"+restofstring+"'")

  elif typeindicator == 'C':
    try:
      return complex(restofstring) 
    except ValueError:
      raise ValueError("Malformed Complex string '"+restofstring+"'")



  elif typeindicator == 'S':
    return restofstring

  elif typeindicator == 'L' or typeindicator == 'T' or typeindicator == 's' or typeindicator == 'f':

    thislist = []

    data = restofstring
    while data != '0:':
      lengthstr, restofdata = data.split(':', 1)
      length = int(lengthstr)

      thisitemdata = restofdata[:length]
      thisitem = serialize_deserializedata(thisitemdata)
      thislist.append(thisitem)

      data = restofdata[length:]

    if typeindicator == 'L':
      return thislist
    elif typeindicator == 'T':
      return tuple(thislist)
    elif typeindicator == 's':
      return set(thislist)
    elif typeindicator == 'f':
      return frozenset(thislist)
    else:
      raise Exception("InternalError: not a known type after checking")


  elif typeindicator == 'D':

    lengthstr, restofdata = restofstring.split(':', 1)
    length = int(lengthstr)

    keysdata = restofdata[:length]
    keys = serialize_deserializedata(keysdata)

    values = serialize_deserializedata(restofdata[length:])

    if type(keys) != list or type(values) != list or len(keys) != len(values):
      raise ValueError("Malformed Dict string '"+restofstring+"'")
    
    thisdict = {}
    for position in xrange(len(keys)):
      thisdict[keys[position]] = values[position]
    
    return thisdict




  else:
    raise ValueError("Unknown typeindicator '"+str(typeindicator)+"' for data :"+str(restofstring))






servername = "satya.cs.washington.edu"
serverport = 10102



class CentralAdvertiseError(Exception):
  """Error when advertising a value to the central advertise service."""

def centralizedadvertise_announce(key, value, ttlval):
  """
   <Purpose>
     Announce a key / value pair into the CHT.

   <Arguments>
     key: the key to put the value under. This will be converted to a string.

     value: the value to store at the key. This is also converted to a string.

     ttlval: the amount of time until the value expires.   Must be an integer

   <Exceptions>
     TypeError if ttlval is of the wrong type.

     ValueError if ttlval is not positive 

     CentralAdvertiseError is raised the server response is corrupted

     Various network and timeout exceptions are raised by timeout_openconn
     and session_sendmessage / session_recvmessage

   <Side Effects>
     The CHT will store the key / value pair.

   <Returns>
     None
  """
  key = str(key)
  value = str(value)

  if not type(ttlval) is int and not type(ttlval) is long:
    raise TypeError("Invalid type '"+str(type(ttlval))+"' for ttlval.")

  if ttlval < 1:
    raise ValueError("The argument ttlval must be positive, not '"+str(ttlval)+"'")

  
  datatosend = ('PUT',key,value,ttlval)
  datastringtosend = serialize_serializedata(datatosend)

  
  sockobj = timeout_openconn(servername,serverport, timeout=10)
  try:
    session_sendmessage(sockobj, datastringtosend)
    rawresponse = session_recvmessage(sockobj)
  finally:
    sockobj.close()
  
  try:
    response = serialize_deserializedata(rawresponse)
    if response != 'OK':
      raise CentralAdvertiseError("Centralized announce failed with '"+response+"'")
  except ValueError, e:
    raise CentralAdvertiseError("Received unknown response from server '"+rawresponse+"'")
      



def centralizedadvertise_lookup(key, maxvals=100):
  """
   <Purpose>
     Returns a list of valid values stored under a key

   <Arguments>
     key: the key to put the value under. This will be converted to a string.

     maxvals: the maximum number of values to return.   Must be an integer

   <Exceptions>
     TypeError if maxvals is of the wrong type.

     ValueError if maxvals is not a positive number

     CentralAdvertiseError is raised the server response is corrupted

     Various network and timeout exceptions are raised by timeout_openconn
     and session_sendmessage / session_recvmessage

   <Side Effects>
     None

   <Returns>
     The list of values
  """

  key = str(key)

  if not type(maxvals) is int and not type(maxvals) is long:
    raise TypeError("Invalid type '"+str(type(maxvals))+"' for ttlval.")

  if maxvals < 1:
    raise ValueError("The argument ttlval must be positive, not '"+str(ttlval)+"'")

  messagetosend = ('GET',key,maxvals)
  messagestringtosend = serialize_serializedata(messagetosend)


  sockobj = timeout_openconn(servername,serverport, timeout=10)
  try:
    session_sendmessage(sockobj, messagestringtosend)
    rawreceiveddata = session_recvmessage(sockobj)
  finally:
    sockobj.close()


  try:
    responsetuple = serialize_deserializedata(rawreceiveddata)
  except ValueError, e:
    raise CentralAdvertiseError("Received unknown response from server '"+rawresponse+"'")

  
  if not type(responsetuple) is tuple:
    raise CentralAdvertiseError("Received data is not a tuple '"+rawresponse+"'")

  if len(responsetuple) != 2:
    raise CentralAdvertiseError("Response tuple did not have exactly two elements '"+rawresponse+"'")
  if responsetuple[0] != 'OK':
    raise CentralAdvertiseError("Central server returns error '"+str(responsetuple)+"'")

  
  if not type(responsetuple[1]) is list:
    raise CentralAdvertiseError("Received item is not a list '"+rawresponse+"'")

  for responseitem in responsetuple[1]:
    if not type(responseitem) is str:
      raise CentralAdvertiseError("Received item '"+str(responseitem)+"' is not a string in '"+rawresponse+"'")


  return responsetuple[1]
      

"""
Author: Conrad Meyer

Start Date: Wed Dec 9 2009

Description:
Advertisements to the Digital Object Registry run by CNRI.

"""








DORadvertise_FORM_LOCATION = "http://geni.doregistry.org/SeattleGENI/HashTable"




class DORadvertise_XMLError(Exception):
  """
  Exception raised when the XML recieved from the Digital Object Registry
  server does not match the structure we expect.
  """
  pass




class DORadvertise_BadRequest(Exception):
  """
  Exception raised when the Digital Object Registry interface indigates we
  have made an invalid request.
  """


  def __init__(self, errno, errstring):
    self.errno = errno
    self.errstring = errstring
    Exception.__init__(self, "Bad DOR request (%s): '%s'" % (str(errno), errstring))




def DORadvertise_announce(key, value, ttlval, timeout=None):
  """
  <Purpose>
    Announce a (key, value) pair to the Digital Object Registry.

  <Arguments>
    key:
            The new key the value should be stored under.

    value:
            The value to associate with the given key.

    ttlval:
            The length of time (in seconds) to persist this key <-> value
            association in DHT.

    timeout:
            The number of seconds to spend on this operation before failing
            early.

  <Exceptions>
    xmlparse_XMLParseError if the xml returned isn't parseable by xmlparse.
    DORadvertise_XMLError if the xml response structure does not correspond
      to what we expect.
    DORadvertise_BadRequest if the response indicates an error.
    Any exception httpretrieve_get_string() throws (including timeout errors).

  <Side Effects>
    The key <-> value association gets stored in openDHT for a while.

  <Returns>
    None.
  """

  post_params = {'command': 'announce', 'key': key, 'value': value,
      'lifetime': str(int(ttlval))}

  _DORadvertise_command(post_params, timeout=timeout)

  return None





def DORadvertise_lookup(key, maxvals=100, timeout=None):
  """
  <Purpose>
    Retrieve a stored value from the Digital Object Registry.

  <Arguments>
    key:
            The key the value is stored under.

    maxvals:
            The maximum number of values stored under this key to
            return to the caller.

    timeout:
            The number of seconds to spend on this operation before failing
            early.   If not specified, the default is set to the default
            timeout value for the http library (30 seconds).

  <Exceptions>
    xmlparse_XMLParseError if the xml returned isn't parseable by xmlparse.
    DORadvertise_XMLError if the xml response structure does not correspond
      to what we expect.
    DORadvertise_BadRequest if the response indicates an error.
    Any exception httpretrieve_get_string() throws (including timeout errors).

  <Side Effects>
    None.

  <Returns>
    The value stored in the Digital Object Registry at key.
  """

  post_params = {'command': 'lookup', 'key': key, 'maxvals': str(maxvals)}

  return _DORadvertise_command(post_params, timeout=timeout)



def _DORadvertise_command(parameters, timeout=None):

  if timeout != None:
    post_result = httpretrieve_get_string(DORadvertise_FORM_LOCATION, \
        postdata=parameters, timeout=timeout, \
        httpheaders={"Content-Type": "application/x-www-form-urlencoded"})
  else:
    post_result = httpretrieve_get_string(DORadvertise_FORM_LOCATION, \
        postdata=parameters, \
        httpheaders={"Content-Type": "application/x-www-form-urlencoded"})


  xmltree = xmlparse_parse(post_result)

  if xmltree.tag_name != "HashTableService":
    raise DORadvertise_XMLError(
        "Root node error. Expected: 'HashTableService', " +
        "got: '%s'" % xmltree.tag_name)

  if xmltree.children is None:
    raise DORadvertise_XMLError("Root node contains no children nodes.")

  error_msg = None
  error = None
  values = None

  numxmlchildren = len(xmltree.children)
  if numxmlchildren not in [2, 3]:
    raise DORadvertise_XMLError("Root XML node contains inappropriate " + \
        "number of child nodes.")

  for xmlchild in xmltree.children:
    if xmlchild.tag_name == "status" and xmlchild.content is not None:
      if error is not None:
        raise DORadvertise_XMLError("XML contains multiple status tags")
      error = int(xmlchild.content.strip())

    elif xmlchild.tag_name == "description":
      if error_msg is not None:
        raise DORadvertise_XMLError("XML contains multiple description tags")
      error_msg = xmlchild.content

    elif xmlchild.tag_name == "values" and xmlchild.children is not None:
      if values is not None:
        raise DORadvertise_XMLError("XML contains multiple values tags")

      values = []
      for valuenode in xmlchild.children:
        if valuenode.tag_name != "value":
          raise DORadvertise_XMLError(
              "Child tag of <values>; expected: '<value>', got: '<%s>'" % \
                  valuenode.tag_name)

        content = valuenode.content
        if content is None:
          content = ""

        values.append(content)

    elif xmlchild.tag_name not in ("status", "description", "values"):
      raise DORadvertise_XMLError("Unexpected tag '" + \
          str(xmlchild.tag_name) + "' while parsing response.")

  if error is not 0:
    raise DORadvertise_BadRequest(error, error_msg)

  if values is None:
    return []

  return values



_advertise_all_services = ("central", "DHT", "DOR")


nodemanager_announce_context = {}
for service in _advertise_all_services:
  nodemanager_announce_context["skip" + service] = 0
  nodemanager_announce_context["previous" + service + "skip"] = 1
nodemanager_announce_context_lock = getlock()


class AdvertiseError(Exception):
  pass




def _try_advertise_announce(args):
  which_service, key, value, ttlval, exceptions, finishedref = args

  if which_service not in _advertise_all_services:
    raise AdvertiseError("Incorrect service type used in internal function _try_advertise_announce.")

  try:
    if which_service == "central":
      centralizedadvertise_announce(key, value, ttlval)
    elif which_service == "DOR":
      DORadvertise_announce(key, value, ttlval)
    else:
      openDHTadvertise_announce(key, value, ttlval)

    finishedref[0] = True     # Signal that at least one service has finished.
    
    nodemanager_announce_context_lock.acquire()
    try:
      nodemanager_announce_context["previous" + which_service + "skip"] = 1
    finally:
      nodemanager_announce_context_lock.release()

  except Exception, e:
    nodemanager_announce_context_lock.acquire()
    try:
      exceptions[0] += 'announce error (type: ' + which_service + '): ' + str(e)
      nodemanager_announce_context["skip" + which_service] = \
          nodemanager_announce_context["previous" + which_service + "skip"] + 1
      nodemanager_announce_context["previous" + which_service + "skip"] = \
          min(nodemanager_announce_context["previous" + which_service + "skip"] * 2, 16)
    finally:
      nodemanager_announce_context_lock.release()





def advertise_announce(key, value, ttlval, concurrentevents=2, \
    graceperiod=10, timeout=60):
  """
  <Purpose>
    Announce (PUT) a value at the given key in the central advertise service,
    openDHT, or both.

  <Arguments>
    key:
            The key to store the value at.

    value:
            The value to store.

    ttlval:
            Time in seconds to persist the associated key<->value pair.
    
    concurrentevents (optional, defaults to 2):
            How many services to announce on in parallel.

    graceperiod (optional, defaults to 10):
            After this many seconds (can be a float or int type), if we have
            successfully announced on at least one service, return.

    timeout (optional, defaults to 60):
            After this many seconds (can be a float or int type), give up.

  <Exceptions>
    AdvertiseError if something goes wrong.

  <Side Effects>
    Spawns as many worker events as concurrentevents specifies, limited by the
    number of services available (currently 2).

  <Returns>
    None.
  """

  key = str(key)
  value = str(value)

  exceptions = [''] # track exceptions that occur and raise them at the end

  parallize_worksets = []
  start_time = getruntime()

  onefinished = [False]

  for service_type in _advertise_all_services:
    if nodemanager_announce_context["skip" + service_type] == 0:
      parallize_worksets.append((service_type, key, value, ttlval, \
          exceptions, onefinished))

    else:
      nodemanager_announce_context_lock.acquire()
      try:
        nodemanager_announce_context["skip" + service_type] = \
            nodemanager_announce_context["skip" + service_type] - 1
      finally:
        nodemanager_announce_context_lock.release()

  ph = parallelize_initfunction(parallize_worksets, _try_advertise_announce, \
      concurrentevents=concurrentevents)

  while not parallelize_isfunctionfinished(ph):
    sleep(0.1)
    if getruntime() - start_time > timeout or \
        (getruntime() - start_time > graceperiod and onefinished[0]):
      parallelize_abortfunction(ph)
      break

  parallelize_closefunction(ph)

  if exceptions[0] != '':
    raise AdvertiseError(str(exceptions))

  return None




def _try_advertise_lookup(args):
  which_service, key, maxvals, finishedref = args

  if which_service not in _advertise_all_services:
    raise AdvertiseError("Incorrect service type used in internal function _try_advertise_lookup.")

  try:
    if which_service == "central":
      results = centralizedadvertise_lookup(key, maxvals)
    elif which_service == "DOR":
      results = DORadvertise_lookup(key, maxvals=maxvals)
    else:
      results = openDHTadvertise_lookup(key, maxvals)

    finishedref[0] = True
    return results
  
  except Exception, e:
    return []




def advertise_lookup(key, maxvals=100, lookuptype=None, \
    concurrentevents=2, graceperiod=10, timeout=60):
  """
  <Purpose>
    Lookup (GET) (a) value(s) stored at the given key in the central advertise
    server, openDHT, or both.

  <Arguments>
    key:
            The key used to lookup values.

    maxvals (optional, defaults to 100):
            Maximum number of values to return.

    lookuptype (optional, defaults to ['central', 'opendht', 'DOR']):
            Which services to employ looking up values.
    
    concurrentevents (optional, defaults to 2):
            How many services to lookup on in parallel.

    graceperiod (optional, defaults to 10):
            After this many seconds (can be a float or int type), return the
            results if one service was reached successfully.

    timeout (optional, defaults to 60):
            After this many seconds (can be a float or int type), give up.

  <Exceptions>
    AdvertiseError if something goes wrong.

  <Side Effects>
    Spawns as many worker events as concurrentevents specifies, limited by the
    number of services in lookuptype.

  <Returns>
    All unique values stored at the key.
  """

  key = str(key)

  if lookuptype is None:
    lookuptype = ['central','opendht','DOR']

  parallel_worksets = []
  start_time = getruntime()

  onefinished = [False]

  for type in lookuptype:
    if type == "central":
      parallel_worksets.append(("central", key, maxvals, onefinished))
    elif type == "DOR":
      parallel_worksets.append(("DOR", key, maxvals, onefinished))
    elif type == "opendht":
      parallel_worksets.append(("DHT", key, maxvals, onefinished))
    else:
      raise AdvertiseError("Incorrect service type '" + type + "' passed to advertise_lookup().")

  ph = parallelize_initfunction(parallel_worksets, _try_advertise_lookup, \
      concurrentevents=concurrentevents)

  while not parallelize_isfunctionfinished(ph):
    sleep(0.1)
    if getruntime() - start_time > timeout or \
        (getruntime() - start_time > graceperiod and onefinished[0]):
      parallelize_abortfunction(ph)
      break

  parallel_results = parallelize_getresults(ph)['returned']
  results = []

  for parallel_result in parallel_results:
    _, return_value = parallel_result
    results += return_value

  parallelize_closefunction(ph)

  return listops_uniq(results)


"""
Temporary naming service to emulate the behaviors of a real DNS server.

"""


class DummyDNSException(Exception):
  pass

def _DummyDNSInitialize():
  if not mycontext.has_key('dummy_dns_lock'):
    mycontext['dummy_dns_lock'] = getlock()
    mycontext['dummy_dns_lock'].acquire()
    mycontext['dummy_dns_cache'] = {}
    mycontext['dummy_dns_log_lock'] = getlock()
    mycontext['dummy_dns_active'] = True
    mycontext['dummy_dns_lock'].release()
    settimer(0, _DummyDNSAdvertiseThread, [])


def _DummyDNSAdvertiseThread():
  if mycontext.has_key('dummy_dns_advertise_thread_started'):
    return
  else:
    mycontext['dummy_dns_advertise_thread_started'] = True
  
  prevCacheStr = ''

  while True:
    mycontext['dummy_dns_lock'].acquire()
    cache = mycontext['dummy_dns_cache'].copy()
    mycontext['dummy_dns_lock'].release()

    if not mycontext['dummy_dns_active']:
      break
    
    for name in cache.keys():
      try:
        advertise_announce(str(name), str(cache[name]), 100)
      except Exception, e:
        pass
      
    if str(cache) == prevCacheStr:
      _DummyDNSLog('')
    else:
      _DummyDNSLog('advertised local cache = %s' % cache)
      prevCacheStr = str(cache)

    for i in range(50):
      sleep(1)

      if not mycontext['dummy_dns_active']:
        break

      try:
        if mycontext['wakeup'] == True:
          mycontext['wakeup'] = False
          break
      except KeyError, e:
        mycontext['wakeup'] = False




def _DummyDNSLog(logstr):
  _DummyDNSInitialize()
  mycontext['dummy_dns_log_lock'].acquire()
  try:
    logfile = open("DummyDNS.log", "a")
    logfile.write("%s\n" % logstr)
  except Exception, e:
    print "DummyDNS: Unable to log: '%s'" % e
  finally:
    logfile.close()
    mycontext['dummy_dns_log_lock'].release()


def is_ip_address(ipstr):
  ip_segment_list = ipstr.split('.')
  if len(ip_segment_list) != 4:
    return False

  for ip_segment_str in ip_segment_list:
    try:
      ip_segment_int = int(ip_segment_str)
    except ValueError, e:
      return False
    if not (0 <= ip_segment_int < 256):
      return False

  return True

  

def DummyDNSStop():
  mycontext['dummy_dns_active'] = False



def DummyDNSLookup(name, create=False):
  """
  Looks up a name and returns the IP address. If 'create' is True, then my
  current IP will be added to the host record if the corresponding name cannot
  be resolved.

  """
  useRealDNS = True

  if is_ip_address(name):
    return name

  if len(name.split('.')) > 1 and useRealDNS:
    try:
      return gethostbyname_ex(name)[2][0]
    except Exception, e:
      _DummyDNSLog("Error: Failed to resolve '%s' using real DNS because '%s'."
                   % (name, e))
      useRealDNS = False

  _DummyDNSInitialize()
  mycontext['dummy_dns_lock'].acquire()
  
  cache = mycontext['dummy_dns_cache']
  try:
    retip = cache[name]
    _DummyDNSLog("Lookup: %s -> %s (cached)" % (name, retip))
    mycontext['dummy_dns_lock'].release()
    return retip
  except KeyError, e:
    pass

  lookup_results = advertise_lookup(name)
  if (not lookup_results) or (lookup_results and lookup_results[0] == ''):
    if create:
      myip = getmyip()
      lookup_results = [myip]
    else:
      _DummyDNSLog("Error: Unable to resolve '%s' with DummyDNS. Now try real DNS." % name)
      try:
        if useRealDNS:
          lookup_results = [gethostbyname_ex(name)[2][0]]
        else:
          raise Exception('Not using real DNS')
      except Exception, e:
        mycontext['dummy_dns_lock'].release()
        raise DummyDNSException("DummyDNS: Unable to resolve '%s' because '%s'." 
                                % (name, e))

  retip = lookup_results[0]
  cache[name] = retip
  mycontext['wakeup'] = create
  mycontext['dummy_dns_lock'].release()

  _DummyDNSLog("Lookup: %s -> %s" % (name, retip))
  return retip


SHIM_LOGGER_FILE = 'shims.log'

class ShimLogger:

  def __init__(self, shimname=''):
    self._shimname = shimname
    self._initialize_logger()


  def _initialize_logger(self):
    if not mycontext.has_key('shim_logger_lock'):
      mycontext['shim_logger_lock'] = getlock()
      self.log("\n" * 3)


  def log(self, logstr):
    mycontext['shim_logger_lock'].acquire()
    try:
      logfile = open(SHIM_LOGGER_FILE, 'a')
      logfile.write(str(self._shimname) + ': ' + logstr + '\n')
      logfile.close()
    except Exception, e:
      pass
    finally:
      mycontext['shim_logger_lock'].release()






class BaseShim:


  mycontext['ShimInstanceCountDict'] = {}
  mycontext['ShimInstanceCountLock'] = getlock()

  name = 'BaseShim'
  do_not_advertise = False






  def openconn(self, host, port, localhost=None, localport=None, timeout=5):
    socket = self._shim_openconn(host, port, localhost, localport, timeout)
    newsocket = ShimSocketWrapper(socket, self)
    return newsocket



  def _waitforconn_shim_callback_wrapper(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    selfcopy = self.copy()
    (rip, rport, sock, th, lh) = selfcopy._shim_listener_callback(remoteip, remoteport, socket, thiscommhandle, listencommhandle)
    newsocket = ShimSocketWrapper(sock, selfcopy)

    self._waitforconn_shim_callback(rip, rport, newsocket, th, lh)
 


  def waitforconn(self, host, port, callback):
    self._waitforconn_shim_callback = callback
    return self._shim_waitforconn(host, port, self._waitforconn_shim_callback_wrapper)



  def recvmess(self, host, port, callback):
    return self._shim_recvmess(host, port, callback)


  def sendmess(self, host, port, msg, localhost=None, localport=None):
    return self._shim_sendmess(host, port, msg, localhost, localport)


  def stopcomm(self, handle):
    return self._shim_stopcomm(handle)


  def socket_close(self, socket):
    return self._shim_socket_close(socket)


  def socket_send(self, socket, msg):
    return self._shim_socket_send(socket, msg)



  def socket_recv(self, socket, bytes): 
    return self._shim_socket_recv(socket, bytes)
  




  def __init__(self, next_shim=None, optional_args=None):

    self.shim_stack = ShimStack(next_shim)
    self._optional_args = optional_args

    if optional_args:
      self.do_not_advertise = "DO_NOT_ADVERTISE" in optional_args

    mycontext['ShimInstanceCountLock'].acquire()
    instdict = mycontext['ShimInstanceCountDict']
    if instdict.has_key(self.name):
      self._instance_id = instdict[self.name]
      instdict[self.name] += 1
    else:
      self._instance_id = 0
      instdict[self.name] = 1
    mycontext['ShimInstanceCountLock'].release()

 
  def _shim_listener_callback(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    return (remoteip, remoteport, socket, thiscommhandle, listencommhandle)



  def _shim_waitforconn(self, host, port, callback):
    return self.shim_stack.waitforconn(host, port, callback)

  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):
    return self.shim_stack.openconn(host, port, localhost, localport, timeout)

  def _shim_recvmess(self, host, port, callback):
    return self.shim_stack.recvmess(host, port, callback)


  def _shim_sendmess(self, host, port, msg, localhost=None, localport=None):
    return self.shim_stack.sendmess(host, port, msg, localhost, localport)


  def _shim_stopcomm(self, handle):
    return self.shim_stack.stopcomm(handle)



  def _shim_socket_close(self, socket):
    return self.shim_stack.socket_close(socket)



  def _shim_socket_send(self, socket, msg):
    return self.shim_stack.socket_send(socket, msg)



  def _shim_socket_recv(self, socket, bytes): 
    return self.shim_stack.socket_recv(socket, bytes)
  


  def copy(self):
    raise Exception("Subclass of BaseShim must implement the copy() method.")


  def get_advertisement_string(self):
    raise Exception("Subclass of BaseShim must implement the get_advertisement_string() method.")









  def getid(self):
    return self._instance_id


  def get_shims(self, get_all_shims=False, debug=False):

    myname = str(self)

    if debug:
      myname += '[%d]' % self.getid()

    if self.do_not_advertise and (not get_all_shims):
      myname = ''

    if self.shim_stack.top_shim is None:
      return myname
    else:
      return myname + self.shim_stack.top_shim.get_shims(get_all_shims, debug)


  def get_names(self):
    
    if self.shim_stack.top_shim is None:
      name_list = ['']
    else:
      name_list = self.shim_stack.get_names()
    
    new_name_list = []
    for name in name_list:
      name = '('+self.name+')'+name
      new_name_list.append(name)
    return new_name_list


  def __str__(self):
    args = []
    if self._optional_args:
      for arg in self._optional_args:
        args.append(str(arg))

    myname = '(' + self.name
 
    if args:
      myname += ","
      myname += ",".join(args)

    myname += ")"

    return "%s[%d]" % (myname, self.getid())


  def __repr__(self):
    return str(self)



class EmptyShim(BaseShim):
  pass




class CoordinationShim(BaseShim):

  name = 'CoordinationShim'

  _lookup_attempts = 4

  _advertise_wait_interval = 60

  def copy(self):
    return CoordinationShim()

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('CoordinationShim')


  def get_advertisement_string(self):
    return '(CoordinationShim)' + self.shim_stack.get_advertisement_string()



  def _shim_listener_callback(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    self._logger.log('listener_callback: new client from %s:%s' % (remoteip, remoteport))
    return (remoteip, remoteport, socket, thiscommhandle, listencommhandle)



  def _shim_waitforconn(self, hostkey, port, callback):

    handle = self.shim_stack.waitforconn(hostkey, port, callback)

    advertise_key = str(hostkey) + "," + str(port) + ",TCP"
    advertise_value = self.shim_stack.get_advertisement_string()

    self._listener_active = True
    settimer(0, self._advertise_thread, [advertise_key, advertise_value])
    self._logger.log('waitforconn: Listening. About to advertise <"%s","%s">' % (advertise_key, advertise_value))

    return handle


  
  def _advertise_thread(self, advertise_key, advertise_value):
    while self._listener_active:
      try:
        advertise_announce(str(advertise_key), "@" + str(advertise_value), 120)
      except Exception, e:
        pass

      sleep(self._advertise_wait_interval)








  def _get_shimstack_strings(self, hostkey, port, use_cache=True):
    if mycontext.has_key('shim_stack_string_cache_lock'):
      mycontext['shim_stack_string_cache_lock'].acquire()
    else:
      mycontext['shim_stack_string_cache_lock'] = getlock() 
      mycontext['shim_stack_string_cache_lock'].acquire()
      mycontext['shim_stack_string_cache'] = {}

    lookup_results = []
    lookup_key = str(hostkey)+','+str(port)+',TCP'
    local_lookup_cache = mycontext['shim_stack_string_cache']

    if use_cache and local_lookup_cache.has_key(lookup_key):
      lookup_results = local_lookup_cache[lookup_key][:]
      if lookup_results:
        mycontext['shim_stack_string_cache_lock'].release()
        return lookup_results

    for count in range(self._lookup_attempts):
      lookup_results = advertise_lookup(lookup_key)
      if len(lookup_results) > 0 and lookup_results[0]:
        break
      sleep(1)

    if local_lookup_cache.has_key(lookup_key):
      local_lookup_cache[lookup_key] += lookup_results[:]
    else:
      local_lookup_cache[lookup_key] = lookup_results[:]

    self._remove_duplicates(local_lookup_cache[lookup_key])

    lookup_results = local_lookup_cache[lookup_key][:]

    mycontext['shim_stack_string_cache_lock'].release()

    return lookup_results


  def _shim_openconn(self, hostkey, port, localhost=None, localport=None, timeout=5):

    exception_str = ''
    sock = None

    tried_using_remote_lookup = False

    shimstackstr_list = self._get_shimstack_strings(hostkey, port, use_cache=True)

    while len(shimstackstr_list) > 0:

      try:
        shimstackstr = shimstackstr_list.pop()[1:]
        shim_stack = ShimStack(shimstackstr)
      except Exception, e:
        errmsg = "Unable to parse shim stack string '%s' because '%s'." % (shimstackstr, e)
        self._logger.log("openconn: " + errmsg)
        raise Exception(errmsg)

      try:
        sock = shim_stack.openconn(hostkey,port,localhost,localport,timeout)
      except Exception,e:
        exception_str +=' || Exception: '+str(e)+' for stack '+shimstackstr
      else:
        break

      if len(shimstackstr_list) == 0 and not tried_using_remote_lookup:
        shimstackstr_list = self._get_shimstack_strings(hostkey, port, use_cache=False)
        tried_using_remote_lookup = True

      if len(shimstackstr_list) == 0 and tried_using_remote_lookup:      
        break


    if sock is None:
      self._logger.log("openconn: Trying to connect to %s:%s without using the shim interface." % (hostkey, port))
      try:
        sock = openconn(DummyDNSLookup(hostkey),port,localhost,localport,timeout)
      except Exception,e:
        exception_str +=' || Unable to connect without using shims becase %s.' % e

    if sock is None:
      exception_str = 'CoordinationShim error: ' + exception_str
      self._logger.log("CoordinationShim: " + exception_str)
      raise Exception(exception_str)
    else:
      self.shim_stack = shim_stack
      return sock





  def _shim_stopcomm(self, handle):
    self._listener_active = False
    return self.shim_stack.stopcomm(handle)


  def _remove_duplicates(self, inlist):
    listindex = 0

    while listindex < len(inlist):
      currentitem = inlist[listindex]
      if currentitem in inlist[listindex+1:]:
        del inlist[listindex]
      else:
        listindex += 1



"""
<Program Name>
  NatForwardingShim.repy

<Started>
  Jan 5, 2010

<Author>
  Eric Kimbrel

<Purpose>
  Provide a NAT (network address translator) forwarding service within the 
  service compostion framework

  When a server does a nat_waitforconn he connects to a nat_forwarder and
  registers.  When a client connects the to the nat_forwarder the nat_forwarder
  uses the control sock to have the server open a new connection.  Traffic
  is then exchanged  via the nat_forwarder


  when completed this library should..

    optionally takes a socket connection to a forwarder on shim construction
    creates a socket connection to a forwarder ( if one is not provided)
    manages re-connection of connection to the forwarder is lost
    advertises the forwarder connection
    listens for connection requests over a control socket
    makes new connections to the forwarder for client communications
    Provides meaningful exceptions when connections are rejected

"""



"""
NatForwardingShim.repy and Nat_Forwarder.repy must communicate over the network
through a series of requests and responses.

These requests and response are encoded in constants contained
within this file


"""

NAT_SERVER = 'S'
NAT_LEGACY_CLIENT = 'C'
NAT_CLIENT = 'c'
NAT_CHECK_CONN = '?'

NAT_CONNECTION_ALIVE = 'ALIVE?'
NAT_NEW_CONN = 'CONN'
NAT_INIT = 'INIT'


NAT_YES = 'YES'   # use for an postive confirmation
NAT_NO = 'NO'     # use for negitive confirmation

NAT_SERVER_NOT_FOUND = 'SERVERNOTFOUND'
NAT_FORWARDER_BUSY = 'BUSY'
NAT_SERVER_ERROR = 'SERVERERROR'



NAT_FORWARDER = 'seattle_NAT_FORWARDING_SERVICE_NODE'


"""

<Author>
  Eric Kimbrel kimbrl@cs.washington.edu

<Start Date>
  Jan 29 2010

<Purpose>
  Provied 2 objects to make more efficent use of resouces when using advertising
  or looking up values.

  LookupCache: 

  Provide cacheing of lookups to reduce the time spent doing
  lookups by programs that need to lookup the same value frequently.
  The cache is global so any instance of the object will have the same
  values stored in the cache.

  usage:  Call lookup_obj.lookup(key) to perform a lookup of key using
          advertise_lookup with default arguments.  Values will be returned
          from the cache if they are available and not too old.

  AdvertisePipe:

  Stores a list of (key,value) tuples and uses a single thread to advertise
  each tuple in the list.  This prevents a program from using multiple threads
  to repeatedly advertise values.

  usage:  Call ad_obj.add(key,value) to add (key,value) to the list of tuples
          to be advertised.  This call returns an ad_handle which can be used
          with a call to ad_obj.remove(ad_handle) to remove (key,value) from 
          the list.

"""







class LookupCache():


  cache = {} # a dict that will map lookups to results
  lock = getlock()

  def __init__(self,refresh_time=120):
    self.refresh_time = refresh_time

  
  def lookup(self,key, maxvals=100, lookuptype=['central','opendht','DOR'], \
                            concurrentevents=2, graceperiod=10, timeout=60):    
    """
    <Purpose>
      lookup the values stored at the given key

    <Arguments>
      see advertise.repy
      WARNING optional arguments are passed on to advertise.repy if a new
      advertisement is performed.  If cache values are returned nothing is 
      done with the extra arguments.

    <Returns>
      a list of unique values advertised at the key

    <Excpetions>
      see advertise_lookup from advertise.repy
    """ 
    
    if key not in self.cache:
      results = advertise_lookup(key, maxvals, lookuptype,concurrentevents,
                              graceperiod, timeout)
      
      if len(results) > 0 and results[0] != '':
        self.cache[key] = {'results':results,'time':getruntime()}

      return results

    else:
      time_expired = getruntime() - self.cache[key]['time']
      if time_expired > self.refresh_time or time_expired < 0:
        results = advertise_lookup(key, maxvals, lookuptype,concurrentevents,
                                            graceperiod, timeout)
        if len(results) > 0 and results[0] != '':
          self.cache[key]['results'] = results
          self.cache[key]['time'] = getruntime()

        return results      


      else:
        return self.cache[key]['results']






class AdvertisePipe():
  
  advertise_dict = {} # store info to be advertised
  state= {'run':False} # should the add thread be running
  state_lock = getlock()
  ttlv = 240
  redo = 120


  def _advertise_thread(self):
    sleep(2)   

    while self.state['run']:
      
      start = getruntime()

      entry_keys = self.advertise_dict.keys()
      for entry_key in entry_keys:
        try:
          (key,value) = self.advertise_dict[entry_key]
          advertise_announce(key,value,self.ttlv)
        except:
          pass #the key must have been deleted
    
          
  
      while getruntime() - start < self.redo and self.state['run']:
        sleep(10)
          


  def add(self,key,value):
    """
    <Purpose>
      add the key,value pair to the advertise pipe

    <Arguments>
      the key value pair to advertise

    <Returns>
      a handle that can be used to remove the key,value pair

    <Excpetions>
      Possible exception from settimer if the advertise thread 
      can not be started
    """ 
    
    handle = object() 
    self.advertise_dict[handle]=(key,value)
    
    self.state_lock.acquire()
    if not self.state['run']:
      self.state['run'] = True
      settimer(0,self._advertise_thread,[])
    self.state_lock.release()    
    
    return handle
    

  def remove(self,handle):
   """
    <Purpose>
      removes the key,value pair corresponding to the handle from
      the advertise pipe

    <Arguments>
      a handle returned from AdvertisePipe.add

    <Returns>
      None

    <Excpetions>
      Exception on invalid handle
    """ 
   self.state_lock.acquire()  
   if handle not in self.advertise_dict:
     self.state_lock.release()
     raise Exception('Invalid advertise handle')
   else: 
     del self.advertise_dict[handle]
     if len(self.advertise_dict) == 0:
       self.state['run'] = False
     self.state_lock.release()
    
  

"""

<Program Name>
  NatForwardingLib.repy

<Author>
  Eric Kimbrel

<Purpose>


  Provide several functions used by vairos shims to accomplish
  Nat Forwarding

  1. Check connectivty to determine if a host needs to use
     nat forwarding.

  2. Lookup nat forwarders that are currently advertising and
     return a ranked list of them



"""



class NatConnError(Exception):
  pass

class NatLookupError(NatConnError):
  pass





def natforwardinglib_isBidirectional(ip,port):
  
  host_str = ip+':'+str(port)

  lookup_obj = LookupCache()

  try:
    ip_port_list = natforwardinglib_forwarder_lookup()
  except:
    return False

  for (forwarder_ip,forwarder_port) in ip_port_list:
    try:
      return  _natforwardinglib_do_check(host_str,forwarder_ip,forwarder_port)
    except Exception, e:
      pass

  return False





def _natforwardinglib_do_check(host_str,forwarder_ip,forwarder_port):
  

  shim = ShimStackInterface()
  sock = shim.openconn(forwarder_ip, forwarder_port, timeout=30)
  
  sock.send(NAT_CHECK_CONN) 
     
  session_sendmessage(sock,host_str)

  msg = session_recvmessage(sock)

  if msg == NAT_YES:
    sock.close()
    return True


  elif msg == NAT_CHECK_CONN:
   
    (ip,port) = host_str.split(':')
    port = int(port)
    try:
      handle = shim.waitforconn(ip,port,_natforwardinglib_listen)
    except Exception, e:
      raise Exception

    session_sendmessage(sock,NAT_YES)

    msg = session_recvmessage(sock)

    sock.close()
    stopcomm(handle)

    return (msg == NAT_YES)

  else:
    sock.close()
    return False
  




def _natforwardinglib_listen(remote_ip,remote_port,
                                      sock,this_handle,listen_handle):
  sock.close()





def natforwardinglib_forwarder_lookup():

  lookup_obj = LookupCache()

  raw_data = lookup_obj.lookup(NAT_FORWARDER)
  if len(raw_data) == 0 or raw_data[0] == '':
    raise NatLookupError("No Nat Forwarders were found")


  tuple_list_dict = {}
  for item in raw_data:
    try:
      (ip,port,load) = item.split(':')
      port = int(port)
    except:
      pass  # throw out invalid entries, todo log this?
    else:
      if load not in tuple_list_dict:
        tuple_list_dict[load] = []
      tuple_list_dict[load].append((ip,port))

  if len(tuple_list_dict) < 1:
    raise NatLookupError("No Valid entries were found for nat forwarders")

  ranked_tuple_list = []
  key_list =  tuple_list_dict.keys()
  key_list.sort()
  for key in key_list:
    for tuple in tuple_list_dict[key]:
      ranked_tuple_list.append(tuple)
    
  return ranked_tuple_list





class NatStateObj:
  def __init__(self,host,port,callback):
    self.sock = None
    self.running = True
    self.callback = callback
    self.host = host
    self.port = port
    self.adhandle = None



class NatForwardingShim(BaseShim):
  
  
  advertise_obj = AdvertisePipe()
  lookup_obj = LookupCache()

  name = 'NatForwardingShim'



  def __init__(self,next_shim=None,optional_args=None):
    
    BaseShim.__init__(self,next_shim,optional_args)    

    self._forwarder_shim_stack = ShimStackInterface()

    self.state_objs = {}

    self.hop_key = None
    self.hop_port = None

    if optional_args is not None:
      if len(optional_args) == 2:
       self.hop_key = optional_args[0]
       self.hop_port = int(optional_args[1])
      else:
        raise Exception("Improper optional args passed into NatForwardingShim")
    
    
  def copy(self):
    return NatForwardingShim(optional_args=self._optional_args)


  def get_advertisement_string(self):
    args = "," + str(self.hop_key) + "," + str(self.hop_port)
    return '(NatForwardingShim' + args + ')' + self.shim_stack.get_advertisement_string()




  def _shim_waitforconn(self,key,port,callback):
    """
    <Purpose>
      Provide a means to register with a nat_forwarder and wait for connections

    <Arguments>
      key: They srv key to register with a nat forwarder, its up to the user
      of this library to come up with a unique value to use as key, and to 
      communicate this key to potential clients.

      port: The port to be used

      localip,localport: see openconn
  
      callback: see waitforconn

    <Exceptions>
      Sock exceptions may occur in event of connection failure, etc
    
    <Side Effects>
      1 thread is consumed to wait for connections over the control socket
      1 thread is consumed to advertise this connection

      every call to waitforconn will use 2 threads, until stopcomm is called

    """
    if port in self.state_objs:
      state_obj = self.state_objs[port]
      state_obj.callback = callback
      return state_obj


    state_obj = NatStateObj(key,port,callback)

    self.establish_control_sock(state_obj) 
    self.state_objs[port] = state_obj

    settimer(0,self.nat_waitfor_request,[state_obj])

    return state_obj




  def establish_control_sock(self,state_obj):

    if self.hop_key is not None and self.hop_port is not None:
      control_sock = self._forwarder_shim_stack.openconn(self.hop_key,int(self.hop_port))  
      for_ip = self.hop_key
      for_port = int(self.hop_port)
    
    else:
      
      forwarder_list = natforwardinglib_forwarder_lookup()
      connected = False      
      
      ex_str =''
      for (for_ip,for_port) in forwarder_list:
        try:
          control_sock = self._forwarder_shim_stack.openconn(for_ip,for_port)

        except Exception,e:
          ex_str = ex_str+' '+str(e)
        else:
          connected = True
          break
      
      if not connected:
        raise NatConnError("Could not establish control socket with any of "
                     +str(len(forwarder_list))+" forwarders: "+ex_str)   


      self.hop_key = for_ip
      self.hop_port = int(for_port)

    control_sock.send(NAT_SERVER) 
    session_sendmessage(control_sock,NAT_INIT)
    session_sendmessage(control_sock,str(state_obj.host)) 
    session_sendmessage(control_sock,str(state_obj.port))

  
    response = session_recvmessage(control_sock)
    if response != NAT_YES:
      raise Exception, 'NAT node refused connection'

    ad_key = state_obj.host+'$'+str(state_obj.port)+'$TCP'
    ad_value = self.name+'$'+for_ip+'$'+str(for_port)
    ad_handle = self.advertise_obj.add(ad_key,ad_value)
    
    legacy_key = "__NAT_SRV__"+state_obj.host
    legacy_value = for_ip+"*"+str(for_port)
    legacy_ad_handle = self.advertise_obj.add(legacy_key,legacy_value)
    
    
    state_obj.adhandle = (ad_handle,legacy_ad_handle)
    state_obj.sock = control_sock




  def establish_comms_sock(self,control_sock):

    remote_key = session_recvmessage(control_sock)
    remote_port = session_recvmessage(control_sock)
    forwarder_ip = session_recvmessage(control_sock)
    forwarder_port = session_recvmessage(control_sock)

    

    new_sock = self._forwarder_shim_stack.openconn(forwarder_ip,int(forwarder_port))
    new_sock.send(NAT_SERVER)
    session_sendmessage(new_sock,NAT_NEW_CONN)
    session_sendmessage(new_sock,remote_key)
    session_sendmessage(new_sock,remote_port) 
    
    response = session_recvmessage(new_sock)
    if response != NAT_YES:
      new_sock.close() # this connection failed
    else:
      session_sendmessage(control_sock,NAT_YES)
      
      response = session_recvmessage(control_sock)
      
      if response == NAT_YES: return (remote_key,remote_port,new_sock)
      else: raise Exception("Establish comms failed")
     


  def _shim_stopcomm(self,handle):  
    """
    acts just like a stopcomm

    """

    if not isinstance(handle,NatStateObj):
      raise Exception("Bad handle passed to NatFOrwardingSHim.stopcomm ")
    (adhandle,legacyadhandle) = handle.adhandle
    self.advertise_obj.remove(adhandle)
    self.advertise_obj.remove(legacyadhandle) 
    handle.running = False
    handle.sock.close()
    
    del self.state_objs[handle.port]
    
    return True




  
  def nat_waitfor_request(self,state_obj):

    while state_obj.running:
      try:
        request = NAT_CONNECTION_ALIVE
       
        while request == NAT_CONNECTION_ALIVE:
          try:
            request = session_recvmessage(state_obj.sock)
            if request != NAT_CONNECTION_ALIVE: break
            session_sendmessage(state_obj.sock,NAT_YES)  
          except:
            if state_obj.running:
              state_obj.sock.close()
              
              (adhandle,legacyadhandle) = state_obj.adhandle
              self.advertise_obj.remove(adhandle)
              self.advertise_obj.remove(legacyadhandle) 
              
              self.establish_control_sock(state_obj)

            else:
              raise # if stop has been called don't re-establish

        if request != NAT_NEW_CONN:
          raise Exception("in establish comms sock with request: "+request)  
       
        try:
          (remote_key,remote_port,comms_sock) = self.establish_comms_sock(state_obj.sock)
        except:
          pass #todo log this? there was a failure setting up a new connection
        else:
         
          settimer(0,state_obj.callback,[remote_key,remote_port,comms_sock,comms_sock,state_obj])    
     
      except Exception, e:
        if state_obj.running:
          raise Exception('ERROR OCCURED IN nat_watifor_request '+str(e))      
     
       





  def _shim_openconn(self,id,port,localip=None,localport=None,timeout=5):
    """
    <Purpose>
      creates a "virtual" connection to the desired host but connecting
      to a forwarder that will exchange traffic between the host and a
      socklikeobj returned by this function

    <Retruns>
      a socket like object

    <Exceptions>
      see openconn
      Exception if Forwarder rejects connection   

    <Warning> TODO: Does not correctly adhere to timeout semantics

    """  

    if self.hop_key is not None and self.hop_port is not None:
      base_sock = self._forwarder_shim_stack.openconn(self.hop_key,self.hop_port,localip,localport,timeout+5)
      self.establish_client_server_conn(base_sock,id,port)
      return base_sock

    else:

      host_list = self.lookup_host(id,port)

      exception_str = ''
      for (forip,forport) in host_list:
        try:
          base_sock = self._forwarder_shim_stack.openconn(forip,forport,localip,
                                                          localport,timeout+9)
          self.establish_client_server_conn(base_sock,id,port)
        except Exception,e:
          exception_str = exception_str+',  '+str(e)
        else:
           return base_sock

      raise NatConnError("Failed to get connection: "+exception_str)
      



  def establish_client_server_conn(self,base_sock,id,port):

    try:
      base_sock.send(NAT_CLIENT)
      session_sendmessage(base_sock,str(id)) 
      session_sendmessage(base_sock,str(port))
    except Exception,e:
      raise NatConnError("Error initializing socket connection: "+str(e))    

    response =  session_recvmessage(base_sock)
    if response != NAT_YES:
      base_sock.close()
      if response == NAT_SERVER_NOT_FOUND:
        raise NatConnError('The Host requested was not found at the forwarder')
      elif response == NAT_FORWARDER_BUSY:
        raise NatConnError('The Host requested has reach its client capacity')
      elif response == NAT_SERVER_ERROR:
        raise NatConnError('The Host requested suffered an unexpected error during connection')
      else:
        raise NatConnError("Unknown nat failure: "+response)

    return base_sock





      


  def lookup_host(self,host,port):
    raw_list = self.lookup_obj.lookup(host+'$'+str(port)+'$TCP')
    if raw_list is None or len(raw_list) == 0:
      raise NatLookupError('No lookup results for: '+host+':'+str(port))

 

    tuple_list = []
    for item in raw_list:
      try:
        (name,ip,port) = item.split('$')
        if name == self.name:
          tuple_list.append((ip,int(port)))
      except:
        pass

    if len(tuple_list) == 0:
      raise NatLookupError('No valid lookup results for: '+host+':'+str(port))
    else:
      return tuple_list




"""

<Program Name>
  NatDeciderShim.repy

<Author>
 Danny Yuxing Huang (yh1@williams.edu)

<Purpose> 

  Decider shim for the Nat Forwarding Shim. When run in a server, it determines
  if the server is behind a NAT. If it is, then the decider pushes the
  NatForwardingShim onto the shim stack. This shim is not advertised.

"""


class NatDeciderShim(BaseShim):
  
  name = 'NatDeciderShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('NatDeciderShim')


  def copy(self):
    return NatDeciderShim()


  def get_advertisement_string(self):
    return self.shim_stack.get_advertisement_string()




  def waitforconn(self, host, port, callback):
    self._logger.log("waitforconn: Check if we're behind NAT")
    behind_nat = natforwardinglib_isBidirectional(getmyip(), port)

    if behind_nat:
      self.shim_stack.push(NatForwardingShim())
      self._logger.log("waitforconn: We are behind NAT.")

    return self.shim_stack.waitforconn(host, port, callback)
  



class SimpleEncryptionShim(BaseShim):

  name = 'SimpleEncryptionShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._ascii_shift = 1
    if optional_args:
      self._ascii_shift = int(optional_args[0])

  def copy(self):
    newshim = SimpleEncryptionShim(optional_args=[self._ascii_shift])
    return newshim

  def get_advertisement_string(self):
    return '(SimpleEncryptionShim,' + str(self._ascii_shift) + ')' + \
        self.shim_stack.get_advertisement_string()

  def _encrypt(self, string):
    cypher = ""
    for char in string:
      cypher += chr((ord(char) + self._ascii_shift) % 256)
    return cypher

  def _decrypt(self, cypher):
    string = ""
    for char in cypher:
      string += chr((ord(char) - self._ascii_shift) % 256)
    return string






  def _shim_socket_send(self, socket, msg):
    return self.shim_stack.socket_send(socket, self._encrypt(msg))


  def _shim_socket_recv(self, socket, bytes): 
    rawstr = self.shim_stack.socket_recv(socket, bytes)
    return self._decrypt(rawstr)
  
  




class LogShim(EmptyShim):

  name = 'LogShim'

  def __init__(self, next_shim=None, optional_args=None):
    EmptyShim.__init__(self, next_shim, optional_args)

    self._lock = getlock()
    self._logfile = 'temp_log_%s.txt' % str(randomfloat())[2:]
    self._sockdict = {}
    self._addlog('__init__')


  def copy(self):
    return LogShim()


  def get_advertisement_string(self):
    return self.shim_stack.get_advertisement_string()


  def _addlog(self, operation, sourceip=None, sourceport=None, destip=None, destport=None, socket=None):

    logentry = ' * '
    logentry += '%s at %s ' % (operation, getruntime())
    logentry += 'from %s:%s to %s:%s ' % (sourceip, sourceport, destip, destport)
    logentry += 'stack: %s ' % (self.shim_stack)
    if sock:
      logentry += 'socket: %s' % socket
    logentry += '\n\n'

    self._lock.acquire()
    fileobj = open(self._logfile, 'a')
    fileobj.write(logentry)
    fileobj.close()
    self._lock.release()



  def _log_waitforconn_callback(self, remoteip, remoteport, sock, th, lh):
    self._addlog('waitforconn_callback', 
                 sourceip=self._waitforconn_sourceip,
                 sourceport=self._waitforconn_sourceport,
                 destip=remoteip, destport=remoteport,
                 socket=sock)

    self._lock.acquire()
    self._sockdict[sock] = [self._waitforconn_sourceip,
                            self._waitforconn_sourceport,
                            remoteip, remoteport]
    self._lock.release()

    self._waitforconn_callback(remoteip, remoteport, sock, th, lh)



  def _shim_waitforconn(self,host,port,callback):
    self._waitforconn_callback = callback
    self._addlog('waitforconn', sourceip=host, sourceport=port)

    self._waitforconn_sourceip = host
    self._waitforconn_sourceport = port

    return self.shim_stack.waitforconn(host,port,self._log_waitforconn_callback)



  def _shim_openconn(self,host,port,localhost=None,localport=None,timeout=5):
    self._addlog('openconn', sourceip=localhost, sourceport=localport, destip=host, destport=port)
    return self.shim_stack.openconn(host,port,localhost,localport,timeout)



  def _log_recvmess_callback(self, remoteip, remoteport, msg, handle):
    self._addlog('recvmess_callback', 
                 sourceip = self._recvmess_sourceip,
                 sourceport = self._recvmess_sourceport,
                 destip=remoteip, destport=remoteport)

    self._recvmess_callback(remoteip, remoteport, msg, handle)



  def _shim_recvmess(self,host,port,callback):
    self._recvmess_callback = callback

    self._recvmess_sourceip = host
    self._recvmess_sourceport = port

    return self.shim_stack.recvmess(host, port, self._log_recvmess_callback)



  def _shim_sendmess(self,host,port,msg,localhost=None,localport=None):
    self._addlog('sendmess', sourceip=localhost, sourceport=localport, destip=host, destport=port)
    return self.shim_stack.sendmess(host,port,msg,localhost,localport)



  def _shim_stopcomm(self,handle):
    self._addlog('stopcomm')
    return self.shim_stack.stopcomm(handle)


  def _shim_socket_send(self, socket, msg):
    self._addlog('socket_send')
    return self.shim_stack.socket_send(socket, msg)

  def _shim_socket_recv(self, socket, bytes):
    self._addlog('socket_recv')
    return self.shim_stack.socket_recv(socket, bytes)

  def _shim_socket_close(self, socket):
    self._addlog('socket_close')
    return self.shim_stack.socket_close(socket)



class RSAShim(BaseShim):

  name = 'RSAShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('RSAShim')
    self._sharedKey = None

    if optional_args:
      self._sharedKey = optional_args[0]


  def copy(self):
    newshim = RSAShim()
    return newshim


  def get_advertisement_string(self):
    return '(RSAShim)' + self.shim_stack.get_advertisement_string()



  def _shim_listener_callback(self, remoteip, remoteport, socket, thiscommhandle, listencommhandle):
    self._logger.log("listener callback: instance id = [%d]" % self.getid())
    (pubKey, privKey) = self._get_RSA_keys()

    try:
      session_sendmessage(socket, "pubKey@@@" + pubKey)
    except Exception, err:
      self._logger.log("listener callback: Unable to send public key because " + str(err))
      raise Exception(err)

    self._logger.log("listener callback: sent public key " + pubKey)

    try:
      handshakestr = self._RSA_decrypt(privKey, session_recvmessage(socket))
    except Exception, err:
      self._logger.log("listener callback: Unable to receive shared key because " + str(err))
      raise Exception(err)

    try:
      (greeting, sharedKey) = handshakestr.split("***")
    except:
      raise Exception("Corrupt handshake: %s" % handshakestr)

    if greeting == "sharedKey":
      pass
    else:
      raise Exception("Wrong greeting: %s" % greeting)

    self._sharedKey = sharedKey
    self._logger.log("listener callback: received shared key " + str(sharedKey))

    self._optional_args = [self._sharedKey]

    return (remoteip, remoteport, socket, thiscommhandle, listencommhandle)


  def _zzcallback_wrapper(self, rip, rport, sock, th, lh):
    self._zzcallback(rip, rport, sock, th, lh)


  def _shim_waitforconn(self, host, port, callback):
    self._zzcallback = callback
    return self.shim_stack.waitforconn(host, port, self._zzcallback_wrapper)


  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):
    sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
    self._logger.log('openconn: connection established with %s:%s' % (host, port))

    try:
      handshakestr = session_recvmessage(sock)
    except Exception, err:
      self._logger.log("openconn: Unable to receive public key because " + str(err))
      raise Exception(err)

    try:
      (greeting, pubKey) = handshakestr.split("@@@")
    except:
      raise Exception("Corrupt handshake: %s" % handshakstr)

    if greeting == "pubKey":
      self._pubKey = pubKey
    else:
      raise Exception("Wrong greeting: %s" % greeting)

    self._logger.log('openconn: received public key ' + str(pubKey))

    self._sharedKey = str(int(randomfloat()*999999) % 256)

    try:
      session_sendmessage(sock, 
                          self._RSA_encrypt(pubKey, "sharedKey***" + self._sharedKey))
    except Exception, err:
      self._logger.log("openconn: Unable to send shared key because " + str(err))
      raise Exception(err)

    self._logger.log('openconn: sent shared key ' + str(self._sharedKey))

    self._optional_args = [self._sharedKey]

    return sock



  def _shim_socket_send(self, socket, msg):
    return self.shim_stack.socket_send(socket, 
                                       self._RN_encrypt(self._sharedKey, msg))


  def _shim_socket_recv(self, socket, bytes): 
    return self._RN_decrypt(self._sharedKey, 
                            self.shim_stack.socket_recv(socket, bytes))
  








  def _get_RSA_keys(self):
    randi = int(randomfloat()*999999)
    return (str(randi), str(1+randi))

  def _match_keys(self, pubKey, privKey):
    return int(pubKey)+1 == int(privKey)

  def _RSA_encrypt(self, pubKey, msg):
    return pubKey + "@#$#@" + msg

  def _RSA_decrypt(self, privKey, cypher):
    try:
      (pubKey, msg) = cypher.split("@#$#@")
    except:
      raise Exception("Corrupt cypher text: %s" % cypher)

    if not self._match_keys(pubKey, privKey):
      raise Exception("Wrong keys in _RSA_decrypt. cyper: %s. privKey: %s." % (cypher, privKey))

    return msg

  def _RN_encrypt(self, RN, msg):
    cypher = ''
    for char in msg:
      cypher += chr((ord(char) + int(RN)) % 256)
    return cypher

  def _RN_decrypt(self, RN, cypher):
    msg = ''
    for char in cypher:
      msg += chr((ord(char) - int(RN)) % 256)
    return msg




class NatBranchingShimHandle:
  def __init__(self, handle_stack_map):
    self.handle_stack_map = handle_stack_map

  def get_map(self):
    return self.handle_stack_map

  def get_stack(self, handle):
    try:
      return self.handle_stack_map[handle]
    except KeyError:
      raise Exception('NatBranchShimHandle.getstack: invalid handle "%s"' % handle)



class NatBranchingShim(BaseShim):

  name = 'NatBranchingShim'

  def __init__(self, next_shim=None, optional_args=None):
    self._listen_handle = None
    self._logger = ShimLogger('NatBranchingShim')
    BaseShim.__init__(self, next_shim, optional_args)




  def copy(self):
    mycopy = NatBranchingShim()
    mycopy._listen_handle = self._listen_handle
    return mycopy


  def get_advertisement_string(self):
    return '(NatBranchingShim)' + self.shim_stack.get_advertisement_string()

  
  def _shim_listener_callback(self, rip, rport, sock, th, lh):
    while not self._listen_handle:
      sleep(0.5)

    return (rip, rport, sock, th, self._listen_handle)


  def _shim_waitforconn(self, host, port, callback):

    noopstack = self.shim_stack.copy()
    natstack = self.shim_stack.copy()
    natstack.push(NatForwardingShim())

    self._branch_waitforconn_cb = callback

    self._logger.log('waitforconn: Constructing noop shim stack.')
    noophandle = noopstack.waitforconn(host, port, callback)
    self._logger.log('waitforconn: Constructing NAT shim stack.')
    nathandle = natstack.waitforconn(host, port, callback)
    handle_stack_map = {noophandle: noopstack, nathandle: natstack}
    self._listen_handle = NatBranchingShimHandle(handle_stack_map)

    return self._listen_handle



  def _shim_stopcomm(self, listen_handle):
    if not isinstance(listen_handle, NatBranchingShimHandle):
      raise Exception('Incorrect listen_handle type.') 

    result = True
    for handle in listen_handle.get_map().keys():
      stack = listen_handle.get_map()[handle]
      ret = stack.stopcomm(handle)
      result = result and ret

    return result
    
 
    

  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):
    try:
 

      self._logger.log("openconn: Trying direct connection.")
      sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
      self._logger.log("openconn: Direct connection works.")
      return sock

    except Exception, e:
      self._logger.log("openconn: Direct connection failed because '%s'." % e)
      self._logger.log("openconn: Trying Nat.")
      self.shim_stack.push(NatForwardingShim())
      sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
      self._logger.log("openconn: NAT works.")
      return sock



class RSABranchingShimHandle:
  def __init__(self, handle_stack_map):
    self.handle_stack_map = handle_stack_map

  def get_map(self):
    return self.handle_stack_map

  def get_stack(self, handle):
    try:
      return self.handle_stack_map[handle]
    except KeyError:
      raise Exception('RSABranchShimHandle.getstack: invalid handle "%s"' % handle)



class RSABranchingShim(BaseShim):

  name = 'RSABranchingShim'

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._listen_handle = None



  def copy(self):
    mycopy = RSABranchingShim()
    return mycopy


  def get_advertisement_string(self):
    return '(RSABranchingShim)[(RSAShim){' + \
        str(self._rsaport) + '}||]' + self.shim_stack.get_advertisement_string()

  
  def _branch_waitforconn_cb_wrapper(self, rip, rport, sock, th, lh):
    while not self._listen_handle:
      sleep(0.5)

    shimstack = self._listen_handle.get_stack(lh)
    socketptr = sock
    while shimstack.top_shim is not None:
      socketptr._shim = shimstack.top_shim.copy()
      socketptr = socketptr._socket
      shimstack = shimstack.top_shim.shim_stack

    self._branch_waitforconn_cb(rip, rport, sock, th, self._listen_handle)


  def _shim_waitforconn(self, host, port, callback):

    noopstack = self.shim_stack.copy()
    rsastack = self.shim_stack.copy()
    rsastack.push(RSAShim())

    self._branch_waitforconn_cb = callback

    noophandle = noopstack.waitforconn(host, port, self._branch_waitforconn_cb_wrapper)
    debugprint("Built noopstack: '%s'" % noopstack)
    self._rsaport = getFreePort()
    rsahandle = rsastack.waitforconn(host, self._rsaport, self._branch_waitforconn_cb_wrapper)
    debugprint("Built rsastack: '%s'" % rsastack)
    handle_stack_map = {noophandle: noopstack, rsahandle: rsastack}
    self._listen_handle = RSABranchingShimHandle(handle_stack_map)

    return self._listen_handle



  def _shim_stopcomm(self, listen_handle):
    if not isinstance(listen_handle, RSABranchingShimHandle):
      raise Exception('Incorrect listen_handle type.') 

    result = True
    for handle in listen_handle.get_map().keys():
      stack = listen_handle.get_map()[handle]
      ret = stack.stopcomm(handle)
      result = result and ret

    return result
    
 
    

  def _shim_openconn(self, host, port, localhost=None, localport=None, timeout=5):

    has_rsa = isinstance(self.shim_stack.top_shim, RSAShim)


    if localhost is None:
      raise Exception('Must specify local IP for debug')

    if int(localhost[len(localhost)-1]) % 2 == 0:
      debug_want_rsa = True
    else:
      debug_want_rsa = False

    if ((debug_want_rsa and (not has_rsa)) or 
        ((not debug_want_rsa) and has_rsa)):
      raise ShimExceptionStackRejected

    if debug_want_rsa:
      debugprint("openconn: Using RSA.")
    else:
      debugprint("openconn: NOT using RSA.")


    sock = self.shim_stack.openconn(host, port, localhost, localport, timeout)
    return sock






class ReverseShim(BaseShim):


  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)

  def copy(self):
    return ReverseShim()

  def get_advertisement_string(self):
    return '(ReverseShim)' + self.shim_stack.get_advertisement_string()


  def _shim_waitforconn(self, hostkey, port, callback):
    self._server_cb = callback
    return self.shim_stack.waitforconn(hostkey, port, self._server_cb_wrapper)


  def _server_cb_wrapper(self, rip, rport, sock, th, lh):
    debugprint('callback: sock: %s' % sock)

    clientip = session_recvmessage(sock)
    clientport = int(session_recvmessage(sock))

    shim_stack = self.shim_stack.copy()
    popped = shim_stack.pop()

    control_msg = session_recvmessage(sock)
    if control_msg == 'client is listening':
      debugprint('Attempt to connect to client %s:%s' % (clientip, clientport))
      callback_sock = shim_stack.openconn(clientip, clientport)
      debugprint('callback: connected, returning sock %s' % callback_sock)

    else:
      raise Exception("Invalid control_msg: '%s'." % control_msg)

    self._server_cb(rip, rport, callback_sock, th, lh)



  def _shim_openconn(self, hostkey, port, localhost=None, localport=None, timeout=5):
    sock = self.shim_stack.openconn(hostkey, port, localhost, localport, timeout)

    mylistenip = getRandomIP() # Returns 127.x.x.x
    mylistenport = 12345
    session_sendmessage(sock, mylistenip)
    session_sendmessage(sock, str(mylistenport))

    shim_stack = self.shim_stack.copy()
    shim_stack.pop()

    self._comm_socket = None
    self._client_listener = shim_stack.waitforconn(mylistenip, mylistenport, self._client_cb_wrapper)
    debugprint('openconn: start listening')

    session_sendmessage(sock, 'client is listening')

    while not self._comm_socket:
      sleep(1)

    debugprint('openconn: got server response, sock = %s' % self._comm_socket)
    return self._comm_socket


  def _client_cb_wrapper(self, rip, rport, sock, th, lh):
    self._comm_socket = sock


class NoopShim(BaseShim):

  def copy(self):
    return NoopShim()



class FECShim(BaseShim):

  name = 'FECShim'

  ip = getmyip()
  send_lock = getlock()
  recv_lock = getlock()
  send_dict = {'package_id':random_nbit_int(10)}


  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('FECShim')

    self.prev_callback = None
    self.recv_dict = {}



  def copy(self):
    return FECShim()


  def get_advertisement_string(self):
    return '(FECShim)' + self.shim_stack.get_advertisement_string()



  def recvmess(self,host,port,callback):
    self.prev_callback = callback
    handle = self.shim_stack.recvmess(host,port,self.fec_callback)
    return ('FEC',handle)



  def fec_callback(self,rip,rport,message,handle):
      
    try:
      (rip,id,count,message) = message.split(':',3)
    except Exception, e:
      raise Exception('Bad message header in FECShim: '+str(e))
    
    if count not in ['0','1','2']: 
      raise Exception('Bad message header in FESCHim: '+count)    

    package_header = rip+':'+id
    
    self.recv_lock.acquire()
    
    if package_header not in self.recv_dict:
      self.recv_dict[package_header] = {'0':None,'1':None,'2':None,'recv':0} 
    
    package_dict = self.recv_dict[package_header]

    if package_dict[count] is not None:
      self.recv_lock.release()
      return
    
    package_dict[count] = message
    package_dict['recv'] += 1
    
    
    if package_dict['recv'] == 1 and count != '2':
      self.recv_lock.release()     
      self.prev_callback(rip,rport,message,handle)

    elif package_dict['recv'] == 2:
      
      if package_dict['2'] is None:
        self.recv_lock.release()
        self.prev_callback(rip,rport,message,handle)
      
      else:

        self.recv_lock.release()
        

        if count != '2':
          recovered_packet = self.str_xor(package_dict['2'],message)
          
        if count == '2':
          if package_dict['1'] is None:
            recovered_packet = self.str_xor(package_dict['0'],message)
          elif package_dict['0'] is None:
            recovered_packet = self.str_xor(package_dict['1'],message)
          else:
            raise Exception("ERROR in FECShim")
          self.prev_callback(rip,rport,recovered_packet,handle)    
          return
        
        while True:
          try:
            self.prev_callback(rip,rport,recovered_packet,handle)    
          except Exception,e:
            if 'events' in str(e): 
              sleep(1) #wait and try
              print 'caught events exception in FECShim'
            else: raise
          else:
            break        
      
        self.prev_callback(rip,rport,message,handle)


    elif package_dict['recv'] == 3:
      del self.recv_dict[package_header]
      self.recv_lock.release()
      return

    elif package_dict['recv'] > 3:
      raise Exception("ERROR IN FECSHIM, recvied: "+str(package_dict['recv'])) 
    



  def sendmess(self,host,port,msg,localhost=None,localport=None):
    
    self.send_lock.acquire()
    

    target = host+':'+str(port)
    if target not in self.send_dict:
      self.send_dict[target] = {'id':self.send_dict['package_id'],'str':None}
      self.send_dict['package_id'] += 1

    if self.send_dict[target]['str'] == None:
      self.send_dict[target]['str'] = msg
      self.send_lock.release()
      
      new_msg = self.ip+':'+str(self.send_dict[target]['id'])+':0:'+msg
      self.shim_stack.sendmess(host,port,new_msg,localhost,localport)
 
    else:
      
      xor = self.str_xor(self.send_dict[target]['str'],msg)
      new_msg = self.ip+':'+str(self.send_dict[target]['id'])+':1:'+msg
      xor = self.ip+':'+str(self.send_dict[target]['id'])+':2:'+xor
      del self.send_dict[target]
      
      self.send_lock.release()
      
      self.shim_stack.sendmess(host,port,new_msg,localhost,localport)
      self.shim_stack.sendmess(host,port,xor,localhost,localport)
      
    return len(msg) 
    
    
  def stopcomm(self,handle):
    try:
      (name,handle) = handle
      if name != 'FEC':  raise Excetpion('Bad name'+str(name))
    except Exception, e:
      raise Exception('Bad handle in FECShim: '+str(e))
    else:
      self.recv_dict = None
      self.shim_stack.stopcomm(handle)

  def str_xor(self,a,b):
    if len(a) > len(b):
      (a,b) = (b,a)
    outstr = ''
    for pos in range(len(a)):
      outstr = outstr + chr( ord(a[pos]) ^ ord(b[pos]))
    outstr = outstr + b[pos+1:]
    return outstr




"""
Compression shim that implements the LZW algorithm.

Written by: Danny Yuxing Huang (yh1@williams.edu)

LZW Algorithm adapted from: http://bjourne.blogspot.com/2007/11/example-of-lzw-algorithm.html

Base 36 conversion: http://en.wikipedia.org/wiki/Base_36#Python_Conversion_Code

"""

class LZWShim(BaseShim):

  def __init__(self, next_shim=None, optional_args=None):
    BaseShim.__init__(self, next_shim, optional_args)
    self._logger = ShimLogger('LZWShim')
  
    self._code_to_str = [chr(i) for i in range(256)]
    self._str_to_code = {}
    for i in range(256):
      self._str_to_code[chr(i)] = i

  def sendmess(self,host,port,longmsg,localhost=None,localport=None):
    shortmsg = self._compress(longmsg)
    shortlength = self.shim_stack.sendmess(host,port,shortmsg,localhost,localport)

    if shortlength == len(shortmsg):
      return len(longmsg)
    else:
      return 0


  def recvmess(self,host,port,callback):
    self._prev_callback = callback
    return self.shim_stack.recvmess(host,port,self._recvmess_callback)


  def _recvmess_callback(self,rip,rport,longmsg,handle):
    shortmsg = self._decompress(longmsg)
    self._prev_callback(rip, rport, shortmsg, handle)




  def _compress(self, longstr):
    """
    Returns an LZW compressed list of the input character sequence.
    """
    timeStart = getruntime()
    output = []
    table = dict(self._str_to_code)

    s = ''
    for ch in longstr:
      it = s + ch
      if it in table:
        s = it
      else:
        output.append(table[s])
        table[it] = len(table)
        s = ch

    output.append(table[s])
    serialized = self._serialize(output)
    timeEnd = getruntime()
    if len(longstr) == 50000:
      print '[%f]'%(timeEnd - timeStart) ,
    return serialized

  def _decompress(self, seq):
    """
    Returns a decompressed string of the LZW compressed input.
    """
    seq = self._deserialize(seq)

    table = self._code_to_str[:]
    prevcode = seq[0]

    output = ""
    output += table[prevcode]

    for code in seq[1:]:
      try:
        entry = table[code]
      except IndexError:
        entry = table[prevcode]
        entry += entry[0]
      output += entry
      table.append(table[prevcode] + entry[0])
      prevcode = code

    return output



  def _base36encode(self, number, alphabet='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'):
    """
    Convert positive integer to a base36 string.
    """
    if not isinstance(number, (int, long)):
      raise TypeError('number must be an integer')
    if number < 0:
      raise ValueError('number must be nonnegative')

    if number == 0:
      return '0'

    base36 = ''
    while number != 0:
      number, i = divmod(number, 36)
      base36 = alphabet[i] + base36

    return base36


  def _base36decode(self, number):
    return int(number,36)


  def _serialize(self, seq):
    ret = ""
    for number in seq:
      numberstr = self._base36encode(number)

      numberstr = chr(ord(numberstr[0]) + 100) + numberstr[1:]

      ret += numberstr

    return ret


  def _deserialize(self, string):
    seq = []
    numberstr = ""
    index = 0

    while index < len(string):

      numberstr += string[index]

      if (index+1 < len(string) and ord(string[index+1]) > 100) or (index+1 == len(string)):

        numberstr = chr(ord(numberstr[0]) - 100) + numberstr[1:]

        number = self._base36decode(numberstr)

        seq.append(number)
        numberstr = ""

      index += 1

    return seq








register_shim('BaseShim', BaseShim)
register_shim('CoordinationShim', CoordinationShim)
register_shim('NatForwardingShim', NatForwardingShim)
register_shim('NatDeciderShim', NatDeciderShim)
register_shim('SimpleEncryptionShim', SimpleEncryptionShim)
register_shim('LogShim', LogShim)
register_shim('RSAShim', RSAShim)
register_shim('NatBranchingShim', NatBranchingShim)
register_shim('RSABranchingShim', RSABranchingShim)
register_shim('ReverseShim', ReverseShim)
register_shim('NoopShim', NoopShim)
register_shim('FECShim', FECShim)
register_shim('LZWShim', LZWShim)




debugging = True

def debugprint(string):
  if debugging:
    print "zzzz NatBranchingShim: " + str(string)



mycontext['debug_free_ports'] = [12346, 12347]
def getFreePort():
  try:
    return mycontext['debug_free_ports'].pop()
  except IndexError:
    raise Exception('No more free ports')

def getRandomIP():
  ip = '127'
  for section in range(3):
    randint = random_int_below(256)
    ip += '.' + str(randint)
  return ip
  





class ShimStackInterface:

  def __init__(self, stack_str='', autoCoordinationShim=True):
    self._stack_str = stack_str

    if autoCoordinationShim:
      if stack_str.find('CoordinationShim') < 0:
        self._stack_str = '(CoordinationShim)' + self._stack_str

    self._handle_dict = {}

    self._logger = ShimLogger('')


  def waitforconn(self, host, port, callback):
    shimstack = ShimStack(self._stack_str)

    try:
      handle = shimstack.waitforconn(host, port, callback)
    except Exception, err:
      self._logger.log('waitforconn: Uncaught exception: ' + str(err))
      raise Exception(err)

    self._logger.log('waitforconn on %s:%s' % (host, port))
    self._handle_dict[handle] = shimstack
    return handle


  def stopcomm(self, handle):
    try:
      shimstack = self._handle_dict[handle]
    except KeyError,e:
      raise KeyError(e)
      return False

    try:
      ret = shimstack.stopcomm(handle)
    except Exception, err:
      self._logger.log('stopcomm: Uncaught exception: ' + str(err))
      raise Exception(err)

    return ret
 

  def openconn(self,host,port,localhost=None,localport=None,timeout=5):
    shimstack = ShimStack(self._stack_str)

    try:
      socket = shimstack.openconn(host,port,localhost,localport,timeout)
    except Exception, err:
      self._logger.log('openconn: on %s:%s uncaught exception: %s' % (host, port, err))
      raise Exception(err)

    self._logger.log('openconn: success on %s:%s' % (host, port))

    return socket


  def sendmess(self,host,port,msg,localhost=None,localport=None):
    shimstack = ShimStack(self._stack_str)
    return shimstack.sendmess(host,port,msg,localhost,localport)

 

  def recvmess(self, host, port, callback):
    shimstack = ShimStack(self._stack_str)
    handle = shimstack.recvmess(host, port, callback)
    self._handle_dict[handle] = shimstack
    return handle




